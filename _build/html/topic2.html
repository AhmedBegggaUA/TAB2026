

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>2. Simulated and Deterministic Annealing &#8212; Técnicas y Algoritmos de Búsqueda IA</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'topic2';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="3. Introduction to the practical part of TAB2026" href="practice_1_1.html" />
    <link rel="prev" title="1. NP-Complete Problems" href="topic1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Técnicas y Algoritmos de Búsqueda IA - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Técnicas y Algoritmos de Búsqueda IA - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    TAB2026
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">NP-Hardness and Graph Matching</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="topic1.html">1. NP-Complete Problems</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">2. Simulated and Deterministic Annealing</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Practice 1</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="practice_1_1.html">3. Introduction to the practical part of TAB2026</a></li>
<li class="toctree-l1"><a class="reference internal" href="practice_1_2.html">4. Graph Construction for Matching</a></li>
<li class="toctree-l1"><a class="reference internal" href="practice_1_3.html">5. Graph Matching</a></li>
<li class="toctree-l1"><a class="reference internal" href="practice_1_4.html">6. Graph Matching with Topological Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="practice_1_5.html">7. SoftAssign</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Ftopic2.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/topic2.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Simulated and Deterministic Annealing</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-common-subgraph">2.1. Maximum Common Subgraph</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-matching">2.2. Graph Matching</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#assignments-and-matchings">2.2.1. Assignments and Matchings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rectangle-rule-cost-function">2.2.2. Rectangle rule: Cost Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#integer-constraints-qap">2.2.3. Integer Constraints: QAP</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulated-annealing">2.3. Simulated Annealing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approximating-qap-with-sa">2.3.1. Approximating QAP with SA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation-of-sa">2.3.2. Interpretation of SA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gibbs-sampling">2.3.3. Gibbs Sampling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-of-sa">2.3.4. Limitations of SA</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#central-clustering">2.4. Central Clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clusters-and-prototypes">2.4.1. Clusters and Prototypes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cost-functions">2.4.2. Cost Functions</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#attractors">2.4.2.1. Attractors</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#independence">2.4.2.2. Independence</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#derivation">2.4.2.3. Derivation</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deterministic-annealing">2.4.3. Deterministic Annealing</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy-and-free-energy">2.4.3.1. Entropy and Free Energy</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-entropy">2.4.3.2. Maximum Entropy</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#softmax-for-graph-matching">2.5. SoftMax for Graph Matching</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#softmaxing">2.5.1. SoftMaxing</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#continuation-methods">2.5.1.1. Continuation Methods</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#softmax-operator">2.5.1.2. SoftMax operator</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#graduated-assignment">2.5.2. Graduated Assignment</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-assignment">2.5.2.1. Linear Assignment</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#softassign">2.5.2.2. SoftAssign</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#cleanup">2.5.2.3. Cleanup</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#appendix">2.6. Appendix</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">2.6.1. Independence</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy">2.6.2. Entropy</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#definition-and-properties">2.6.2.1. Definition and properties</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy-and-coding">2.6.2.2. Entropy and Coding</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#joint-vs-conditional-entropy">2.6.2.3. Joint vs Conditional entropy</a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="simulated-and-deterministic-annealing">
<h1><span class="section-number">2. </span>Simulated and Deterministic Annealing<a class="headerlink" href="#simulated-and-deterministic-annealing" title="Permalink to this heading">#</a></h1>
<section id="maximum-common-subgraph">
<h2><span class="section-number">2.1. </span>Maximum Common Subgraph<a class="headerlink" href="#maximum-common-subgraph" title="Permalink to this heading">#</a></h2>
<p><strong>Motivation</strong>. Chemical compounds exhibit structural patters shared between compounds of the same family. One of these patterns is the circular (hexagonal) structure formed by carbon (C) atoms linked by single or double bonds (see <a class="reference internal" href="#aspirin"><span class="std std-numref">Fig. 2.1</span></a>-Left and Center) where the non-labeled vertices denote C atoms. In this example, the presence of the hexagonal ring in the popular <a class="reference external" href="https://pubchem.ncbi.nlm.nih.gov/compound/Aspirin">Aspirin</a> (<a class="reference internal" href="#aspirin"><span class="std std-numref">Fig. 2.1</span></a>-Right) is well known.</p>
<p>The development of AI pattern matching techniques for detetecting substructures has powered the field of Bioinformatics. Nowadays, the analysis of exponentially growing datasets of proteins such as the Protein Data Bank <a class="reference external" href="https://www.wwpdb.org/">PDB</a> or of chemical compounds such as <a class="reference external" href="https://pubchem.ncbi.nlm.nih.gov/">PubChem</a> is a must in AI.</p>
<figure class="align-center" id="aspirin">
<a class="reference internal image-reference" href="_images/MCS-Aspirin-Photoroom.png"><img alt="_images/MCS-Aspirin-Photoroom.png" src="_images/MCS-Aspirin-Photoroom.png" style="width: 800px; height: 300px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.1 </span><span class="caption-text">Structure of the Aspirin.</span><a class="headerlink" href="#aspirin" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><strong>MCS</strong>. Comparing substructures is not an easy problem. Whereas comparing substrings is polynomial, comparing substrutures is a well-known NP problem called the <span style="color:#f88146">Maximum Common Subgraph</span> or MCS:</p>
<p><em>Given two graphs <span class="math notranslate nohighlight">\(G_1=(V_1,E_1)\)</span>  and <span class="math notranslate nohighlight">\(G_2=(V_2,E_2)\)</span>, what is the graph <span class="math notranslate nohighlight">\(H=(V,E)\)</span> that is <em>common</em> to <span class="math notranslate nohighlight">\(G_1\)</span> and <span class="math notranslate nohighlight">\(G_2\)</span> with the maximum number of nodes</em>?</p>
<p>Herein, <em>common</em> means the following: <span class="math notranslate nohighlight">\(V = V\subseteq V_1\)</span> and <span class="math notranslate nohighlight">\(E\subseteq E_1\)</span> and exists an injective (one-to-one) mapping <span class="math notranslate nohighlight">\(f:V\rightarrow V_2\)</span> such that <span class="math notranslate nohighlight">\((i,j)\in E\)</span> iff <span class="math notranslate nohighlight">\((f(i),f(j))\in E_2\)</span>.</p>
<p>This <span style="color:#f88146"><strong>subsetness flavor</strong></span> clarifies the fact that <span style="color:#f88146"><span class="math notranslate nohighlight">\(\text{MCS}\in \text{NP}\)</span></span>. Actually, MCS does not only search for one common subset but for <em>the subset with the maximum number of nodes</em>.</p>
<p>This is quite clear in the following <em>Breaking Bad</em> problem: <span style="color:#f88146">What is the structural coincidence between Ectasy and Amphetamine?</span>.</p>
<ul class="simple">
<li><p>According to PubChem, <a class="reference external" href="https://pubchem.ncbi.nlm.nih.gov/compound/3_4-Methylenedioxymethamphetamine">Ectasy</a> is derived from the <a class="reference external" href="https://pubchem.ncbi.nlm.nih.gov/compound/Amphetamine">Amphetamine</a>.</p></li>
<li><p>Looking at <a class="reference internal" href="#drugs"><span class="std std-numref">Fig. 2.2</span></a>-Center (Ectasy)
comes from removing an Hidrogen atom from Amphetamine (<a class="reference internal" href="#drugs"><span class="std std-numref">Fig. 2.2</span></a>-Right), adding a carbon and an oxigen-carbon pentagonal cycle.</p></li>
<li><p>The MCS is in <a class="reference internal" href="#drugs"><span class="std std-numref">Fig. 2.2</span></a>-Left.</p></li>
</ul>
<figure class="align-center" id="drugs">
<a class="reference internal image-reference" href="_images/Drugs-Photoroom.png"><img alt="_images/Drugs-Photoroom.png" src="_images/Drugs-Photoroom.png" style="width: 800px; height: 200px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.2 </span><span class="caption-text">Maximal Common Substructure (left) of two design drugs (center and right).</span><a class="headerlink" href="#drugs" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>All the figures have been generated by the <a class="reference external" href="https://www.rdkit.org/">RDKit: Open-Source Cheminformatics Software</a>.</p>
</section>
<section id="graph-matching">
<h2><span class="section-number">2.2. </span>Graph Matching<a class="headerlink" href="#graph-matching" title="Permalink to this heading">#</a></h2>
<p>Solving MCS via a polynomial approximation requires <em>finding the injective function</em> <span class="math notranslate nohighlight">\(f\)</span> between the vertices <span class="math notranslate nohighlight">\(V\)</span> of small graph <span class="math notranslate nohighlight">\(X=(V,E)\)</span> and those <span class="math notranslate nohighlight">\(V'\)</span> of larger graph <span class="math notranslate nohighlight">\(Y=(V',E')\)</span> in polynomial time.</p>
<section id="assignments-and-matchings">
<h3><span class="section-number">2.2.1. </span>Assignments and Matchings<a class="headerlink" href="#assignments-and-matchings" title="Permalink to this heading">#</a></h3>
<p><strong>Node assignments</strong>. Consider the (undirected) graphs:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp;\begin{array}{cll}
\text{Graph}  &amp; \text{Nodes} &amp; \text{Edges}\\
X &amp; V=\{a,b,c\} &amp; E=\{(a,b),(b,c)\}\\
Y &amp; V'=\{1,2,3,4,5\} &amp; E=\{(1,2),(1,3),(1,4),(3,4)\}\\
\end{array}
\end{aligned}
\end{split}\]</div>
<p>As we have <span class="math notranslate nohighlight">\(n=|V'|=5\)</span> and <span class="math notranslate nohighlight">\(r=|V|=3\)</span> we have <span class="math notranslate nohighlight">\(P(n,r)=n\cdot (n-1)\cdot (n-r + 1)\)</span> <strong>r-permutations</strong> i.e. one-to-one functions <span class="math notranslate nohighlight">\(f\)</span> or <span style="color:#f88146"><strong>node assignments</strong></span> that can be potential solutions to the MCS problem. In this case, we have <span class="math notranslate nohighlight">\(P(5,3)=5\cdot 4\cdot 3=60\)</span> different  assignments. Then, <span style="color:#f88146">what assignments provide the MCS between <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span></span>?</p>
<p>For the graphs <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> the size of the MCS is <span class="math notranslate nohighlight">\(2\)</span>, since <span class="math notranslate nohighlight">\(X\)</span> has only two edges and if it is a subgraph of <span class="math notranslate nohighlight">\(Y\)</span> (as it is really is), the size of the MCS has <span class="math notranslate nohighlight">\(|V|=3\)</span> nodes and |E|=2$ edges.</p>
<p>However, this depends on how good is the injective function <span class="math notranslate nohighlight">\(f\)</span>. For the one in <a class="reference internal" href="#matching"><span class="std std-numref">Fig. 2.3</span></a> we have:</p>
<div class="math notranslate nohighlight">
\[
f(a)=1,\; f(b)=2\;\text{and}\; f(c)=3\;.
\]</div>
<p>As we can see, <span class="math notranslate nohighlight">\((a,b)\in E\)</span> and <span class="math notranslate nohighlight">\((1=f(a),2=f(b))\in E'\)</span>. However, for the other edge <span class="math notranslate nohighlight">\((b,c)\in E\)</span> we have that <span class="math notranslate nohighlight">\((2=f(b),3=f(c))\not\in E'\)</span>: As a result <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> <span style="color:#f88146"><strong>do only have one common edge for <span class="math notranslate nohighlight">\(f\)</span></strong></span> (in magenta).</p>
<figure class="align-center" id="matching">
<a class="reference internal image-reference" href="_images/Matching1-Photoroom.png"><img alt="_images/Matching1-Photoroom.png" src="_images/Matching1-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.3 </span><span class="caption-text">non-Maximal Common Substructure.</span><a class="headerlink" href="#matching" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Consider now the assignment:</p>
<div class="math notranslate nohighlight">
\[
f(a)=1,\; f(b)=4\;\text{and}\; f(c)=5\;.
\]</div>
<p>which indeed leads to a MCS:</p>
<figure class="align-center" id="matching2">
<a class="reference internal image-reference" href="_images/Matching2-Photoroom.png"><img alt="_images/Matching2-Photoroom.png" src="_images/Matching2-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.4 </span><span class="caption-text">A Maximal Common Substructure.</span><a class="headerlink" href="#matching2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>However, this MCS assignment <strong>is not unique</strong>. Actually we have <span class="math notranslate nohighlight">\({5 \choose 3}=10\)</span> subgraphs of <span class="math notranslate nohighlight">\(Y\)</span> where we can <em>embed</em> <span class="math notranslate nohighlight">\(X\)</span> but only <span class="math notranslate nohighlight">\(8\)</span> of them lead to MCS assignments. In the above table, we encode each MCS injective function <span class="math notranslate nohighlight">\(f_i\)</span> as a list of <span style="color:#f88146"> <strong>pairwise matchings</strong> <span class="math notranslate nohighlight">\((v\in V, f_i(v)\in V')\)</span></span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp;\begin{array}{cl}
\text{Injection} &amp; \text{MCS Assignment} \\
f_1 &amp; [(a, 1), \mathbf{(b, 4)}, (c, 5)]\\
f_2 &amp; [(a, 2), \mathbf{(b, 1)}, (c, 3)]\\
f_3 &amp; [(a, 2), \mathbf{(b, 1)}, (c, 4)]\\
f_4 &amp; [(a, 3), \mathbf{(b, 1)}, (c, 2)]\\
f_5 &amp; [(a, 3), \mathbf{(b, 1)}, (c, 4)]\\
f_6 &amp; [(a, 4), \mathbf{(b, 1)}, (c, 2)]\\
f_7 &amp; [(a, 4), \mathbf{(b, 1)}, (c, 3)]\\
f_8 &amp; [(a, 5), \mathbf{(b, 4)}, (c, 1)]\\
\end{array}
\end{aligned}
\end{split}\]</div>
<p><strong>Notable vertices</strong>. In the above table, note that MCS assignments usually contain pairwise matchings between nodes with large degrees (notable vertices) in both graphs, namely <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{1}\)</span> or <span class="math notranslate nohighlight">\(\mathbf{4}\)</span> (in bold). These matchings are <span class="math notranslate nohighlight">\(\mathbf{(b,1)}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{(b,4)}\)</span>.</p>
<p>In the following exercise we emphasize the link between the subgraphs of <span class="math notranslate nohighlight">\(Y\)</span> and the MCS assignments, which is a fundamental concept in this topic.
<br></br>
<span style="color:#d94f0b">
<strong>Exercise</strong>. Identify the <span class="math notranslate nohighlight">\({5 \choose 3}=10\)</span> subgraphs of size <span class="math notranslate nohighlight">\(3\)</span> in <span class="math notranslate nohighlight">\(Y\)</span> (indicating both nodes and edges) and:<br />
<strong>a)</strong> Detect the ones which do correspond to a complete  embedding of <span class="math notranslate nohighlight">\(X\)</span> in <span class="math notranslate nohighlight">\(Y\)</span>.<strong>b)</strong> Identify these subgraphs in the <span class="math notranslate nohighlight">\(8\)</span> MCS assigmnets of the above table.
<br></br>
<strong>NOTE</strong>. Express always the edges in <strong>lexicographical order</strong> i.e. <span class="math notranslate nohighlight">\((i,j)\)</span> if <span class="math notranslate nohighlight">\(i&lt;j\)</span>.
<br></br>
Answer. <strong>a)</strong> The subgraphs are the <span class="math notranslate nohighlight">\(10\)</span> combinations of the <span class="math notranslate nohighlight">\(5\)</span> nodes <span class="math notranslate nohighlight">\(V'=\{1,2,3,4,5\}\)</span> in groups of <span class="math notranslate nohighlight">\(3\)</span> nodes (because <span class="math notranslate nohighlight">\(|V|=3\)</span>). However, only those subgraphs wich are connected can lead to a complete embeddding of <span class="math notranslate nohighlight">\(X\)</span> in <span class="math notranslate nohighlight">\(Y\)</span>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
&amp;\begin{array}{cclc}
\text{Subgraph} &amp; \text{Nodes} &amp; \text{Edges} &amp; \text{is Connected?}\\
s_1    &amp; V_1'=(1, 2, 3) &amp; E_1'=\{(1,2),(1,3)\} &amp; \checkmark \\
s_2    &amp; V_2'=(1, 2, 4) &amp; E_2'=\{(1,2),(1,3)\} &amp; \checkmark \\
s_3    &amp; V_3'=(1, 2, 5) &amp; E_3'=\{(1,2)\}&amp;\\
s_4    &amp; V_4'=(1, 3, 4) &amp; E_4'=\{(1,3),(1,4)\}&amp; \checkmark\\
s_5    &amp; V_5'=(1, 3, 5) &amp; E_5'=\{(1,3)\}&amp;\\
s_6    &amp; V_6'=(1, 4, 5) &amp; E_6'=\{(1,4),(1,5)\}&amp; \checkmark\\
s_7    &amp; V_7'=(2, 3, 4) &amp; E_7'=\emptyset &amp;\\
s_8    &amp; V_8'=(2, 3, 5) &amp; E_8'=\emptyset &amp;\\
s_9    &amp; V_9'=(2, 4, 5) &amp; E_9'=\{(4,5)\} &amp;\\
s_{10} &amp; V_{10}'=(3, 4, 5) &amp; E_{10}'=\{(4,5)\} &amp;\\
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<strong>b)</strong> We have that only subgraphs <span class="math notranslate nohighlight">\(s_1\)</span>, <span class="math notranslate nohighlight">\(s_2\)</span>, <span class="math notranslate nohighlight">\(s_4\)</span> and  <span class="math notranslate nohighlight">\(s_6\)</span> can accomodate the full graph <span class="math notranslate nohighlight">\(X\)</span>. In graph theory we say that these subgraphs are <strong>isomorphic</strong> to <span class="math notranslate nohighlight">\(Y\)</span>. Note that each of these subgraphs leads to <span class="math notranslate nohighlight">\(2\)</span> MCS assignments in the injection table above:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
V_1'&amp;=(1,2,3)\rightarrow f_2=[(a,2),(b,1),(c,3)],\; f_4=[(a,3),(b,1),(c,2)]\\
V_2'&amp;=(1,2,4)\rightarrow f_3=[(a,2),(b,1),(c,4)],\; f_6=[(a,4),(b,1),(c,2)]\\
V_4'&amp;=(1,3,4)\rightarrow f_5=[(a,3),(b,1),(c,4)],\; f_7=[(a,4),(b,1),(c,3)]\\
V_6'&amp;=(1,4,5)\rightarrow f_1=[(a,1),(b,4),(c,5)],\; f_5=[(a,5),(b,4),(c,1)]\\
\end{aligned}
\)</span>
</span>
<br></br></p>
</section>
<section id="rectangle-rule-cost-function">
<h3><span class="section-number">2.2.2. </span>Rectangle rule: Cost Function<a class="headerlink" href="#rectangle-rule-cost-function" title="Permalink to this heading">#</a></h3>
<p>So far, solving MCS revolves around the idea of <span style="color:#f88146"><strong>maximizing the number of pairwise matchings</strong></span> between graphs <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<p>For a human, is quite clear to adopt a <em>greedy strategy</em>:</p>
<ol class="arabic simple">
<li><p>Identify notable vertices in <span class="math notranslate nohighlight">\(V\)</span> and <span class="math notranslate nohighlight">\(V'\)</span>.</p></li>
<li><p>For each matching pair between notable nodes:</p></li>
</ol>
<ul class="simple">
<li><p>Extend the matching pairs to neighbors.</p></li>
<li><p>Increment the number of rectables accordingly.</p></li>
</ul>
<p>Machines need a more precise specification. Maximizing the number of rectangles, however, arises from the following procedure:</p>
<p><em>Given <span class="math notranslate nohighlight">\(a\in V\)</span> and <span class="math notranslate nohighlight">\(i\in V'\)</span>, a rectangle appears if:</em></p>
<ol class="arabic simple">
<li><p><em>We match <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(i\)</span></em></p></li>
<li><p><em>We match <span class="math notranslate nohighlight">\(b\)</span> and <span class="math notranslate nohighlight">\(j\)</span>, which are respective neighbors of <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(i\)</span>: <span class="math notranslate nohighlight">\(b\in {\cal N}_a\)</span> and <span class="math notranslate nohighlight">\(j\in {\cal N}_i\)</span>.</em></p></li>
</ol>
<p>In other words, a rectangle happens when we match two nodes and their respective neighbors do also match. This is exacly why we prefer pairwise matchings between notable vertices: because they are more likely to produce more rectangles.</p>
<p>This rationale leads to the <span style="color:#f88146"><strong>second-order flavor</strong></span> of MCS, also known as <span style="color:#f88146"><strong>Graph Matching</strong></span> inside the Pattern Recognition community. Indeed, posing the problem in matricial terms, we have:</p>
<ul class="simple">
<li><p>The adjacency matrices <span class="math notranslate nohighlight">\(\mathbf{X}\in\{0,1\}^{m\times m}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Y}\in\{0,1\}^{n\times n}\)</span> of graphs <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>.</p></li>
<li><p>The unknown <span style="color:#f88146"><strong>matching matrix</strong></span> <span class="math notranslate nohighlight">\(\mathbf{M}\in\{0,1\}^{n\times m}\)</span>, where <span class="math notranslate nohighlight">\(\mathbf{M}_{ia}=1\)</span> means that <span class="math notranslate nohighlight">\(i\in V\)</span> matches <span class="math notranslate nohighlight">\(a\in V'\)</span>.</p></li>
</ul>
<p>Therefore, a rectagle exists if <em>its four sides do exist</em>, i.e. if</p>
<div class="math notranslate nohighlight">
\[
\exists a,b\in V, \exists i,j\in V':\; \mathbf{M}_{ai}\mathbf{M}_{bj}\mathbf{X}_{ab}\mathbf{Y}_{ij}&gt;0\;,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{X}_{ab}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Y}_{ij}\)</span> encode the respective neighboring rules (sides of the rectangle) as we show in <a class="reference internal" href="#rectangle"><span class="std std-numref">Fig. 2.5</span></a>.</p>
<figure class="align-center" id="rectangle">
<a class="reference internal image-reference" href="_images/Rectangle-Photoroom.png"><img alt="_images/Rectangle-Photoroom.png" src="_images/Rectangle-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.5 </span><span class="caption-text">The Rectangle Rule in Graph Matching.</span><a class="headerlink" href="#rectangle" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><strong>Quadratic Cost function</strong>. A function that counts the number of rectangles given by a matching matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is simply:</p>
<div class="math notranslate nohighlight">
\[
F(\mathbf{M}) = \frac{1}{2}\sum_{a\in V}\sum_{i\in V'}\sum_{b\in V}\sum_{j\in V'}\mathbf{M}_{ai}\mathbf{M}_{bj}\mathbf{X}_{ab}\mathbf{Y}_{ij}\;,
\]</div>
<p>where <span class="math notranslate nohighlight">\(1/2\)</span> factor removes rectangles counted twice (see the explanation to follow).</p>
<p>Consider for instance the graphs <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> in the previous section (see <a class="reference internal" href="#matching"><span class="std std-numref">Fig. 2.3</span></a>). Let us count the number of rectangles por a particular matching using the matricial formulation and the above function.</p>
<p>Firstly, we have the adjacency matrices</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbf{X} = 
\begin{array}{l}
a\\
b\\
c\\
\end{array}
\begin{bmatrix}
0 &amp; 1 &amp; 0 \\
1 &amp; 0 &amp; 1 \\
0 &amp; 1 &amp; 0 \\
\end{bmatrix}
\;\; 
\mathbf{Y} = 
\begin{array}{l}
1\\
2\\
3\\
4\\
5\\
\end{array}
\begin{bmatrix}
0 &amp; 1 &amp; 1 &amp; 1 &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
\end{bmatrix}
\end{align}
\end{split}\]</div>
<p>The matching matrix for the assignment in <a class="reference internal" href="#matching2"><span class="std std-numref">Fig. 2.4</span></a> is given by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbf{M} = 
\begin{array}{l}
a\\
b\\
c\\
\end{array}
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
\end{bmatrix}
\;\;\text{where}\;\;
\mathbf{M}^T = 
\begin{array}{l}
1\\
2\\
3\\
4\\
5\\
\end{array}
\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\end{align}
\end{split}\]</div>
<p>Let us fix the matricial version of <span class="math notranslate nohighlight">\(F(\mathbf{M})\)</span>.</p>
<ol class="arabic simple">
<li><p><strong>Mapping</strong>. We commence by analyzing the product <span class="math notranslate nohighlight">\(\mathbf{X}\mathbf{M}\)</span> which maps the nodes in <span class="math notranslate nohighlight">\(X\)</span> to those in <span class="math notranslate nohighlight">\(Y\)</span> via the matching matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span>:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
(\mathbf{X}\mathbf{M})_{ai} = \mathbf{X}_{a:}\mathbf{M}_{:i} = \sum_{a}\sum_{b}\mathbf{X}_{ab}\mathbf{M}_{bi}
\]</div>
<p>In our example:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{X}\mathbf{M} = 
\begin{array}{l}
a\\
b\\
c\\
\end{array}
\begin{bmatrix}
0 &amp; 1 &amp; 0 \\
1 &amp; 0 &amp; 1 \\
0 &amp; 1 &amp; 0 \\
\end{bmatrix}
\cdot
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
\end{bmatrix}
=
\begin{bmatrix}
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
\end{bmatrix}
\end{split}\]</div>
<p>Each column of <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> has <em>at most</em> one <span class="math notranslate nohighlight">\(1\)</span>, we have:</p>
<div class="math notranslate nohighlight">
\[
(\mathbf{X}\mathbf{M})_{ai} = \mathbf{X}_{ab^{\ast}}\mathbf{M}_{b^{\ast}i}
\]</div>
<p>where <span class="math notranslate nohighlight">\(b^{\ast}\in {\cal N}_a\)</span> is the neighbor of <span class="math notranslate nohighlight">\(a\)</span> that matches <span class="math notranslate nohighlight">\(i\)</span>, if any. Therefore:</p>
<div class="math notranslate nohighlight">
\[
(\mathbf{X}\mathbf{M})_{ai} = \mathbf{X}_{ab^{\ast}}\mathbf{M}_{b^{\ast}i}=1\Rightarrow \exists\; \text{path}\; a\rightarrow b^{\ast}\rightarrow i\in {\cal M}\;,
\]</div>
<p>where <span class="math notranslate nohighlight">\({\cal M}\)</span> is the <span style="color:#f88146"><strong>matching graph</strong></span> (includes links of <span class="math notranslate nohighlight">\(X\)</span>, <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(M\)</span> as in <a class="reference internal" href="#matching2"><span class="std std-numref">Fig. 2.4</span></a>).</p>
<p>Therefore, <span class="math notranslate nohighlight">\(\mathbf{X}\mathbf{M}\)</span> has the following paths in <span class="math notranslate nohighlight">\({\cal M}\)</span> (one per each <span class="math notranslate nohighlight">\(1\)</span> in the matrix):</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
(\mathbf{X}\mathbf{M})_{a4}&amp;=a\rightarrow b\rightarrow 4\\
(\mathbf{X}\mathbf{M})_{b1}&amp;=b\rightarrow a\rightarrow 1\\
(\mathbf{X}\mathbf{M})_{b5}&amp;=b\rightarrow c\rightarrow 5\\
(\mathbf{X}\mathbf{M})_{c4}&amp;=c\rightarrow b\rightarrow 4\\
\end{align}
\end{split}\]</div>
<p>For instance, we show the above paths in <a class="reference internal" href="#mpaths1"><span class="std std-numref">Fig. 2.6</span></a> and <a class="reference internal" href="#mpaths2"><span class="std std-numref">Fig. 2.7</span></a>.</p>
<figure class="align-center" id="mpaths1">
<a class="reference internal image-reference" href="_images/MatchingPaths1-Photoroom.png"><img alt="_images/MatchingPaths1-Photoroom.png" src="_images/MatchingPaths1-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.6 </span><span class="caption-text">Matching paths <span class="math notranslate nohighlight">\(b\rightarrow a\rightarrow 1\)</span> and <span class="math notranslate nohighlight">\(b\rightarrow c\rightarrow 5\)</span>.</span><a class="headerlink" href="#mpaths1" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-center" id="mpaths2">
<a class="reference internal image-reference" href="_images/MatchingPaths2-Photoroom.png"><img alt="_images/MatchingPaths2-Photoroom.png" src="_images/MatchingPaths2-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.7 </span><span class="caption-text">Matching paths <span class="math notranslate nohighlight">\(a\rightarrow b\rightarrow 4\)</span> and <span class="math notranslate nohighlight">\(c\rightarrow b\rightarrow 4\)</span>.</span><a class="headerlink" href="#mpaths2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ol class="arabic simple" start="2">
<li><p><strong>Paths</strong>. We continue by analyzing the product <span class="math notranslate nohighlight">\((\mathbf{X}\mathbf{M})\mathbf{Y}\)</span>. Intuition: since <span class="math notranslate nohighlight">\(\mathbf{X}\mathbf{M}\)</span> provides paths in <span class="math notranslate nohighlight">\({\cal M}\)</span> between adjacent nodes in <span class="math notranslate nohighlight">\(X\)</span> and then crosses through the matching <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> reaching nodes in <span class="math notranslate nohighlight">\(Y\)</span>, the product <span class="math notranslate nohighlight">\((\mathbf{X}\mathbf{M})\mathbf{Y}\)</span> just <em>continues these paths</em>: some of them will end in <span class="math notranslate nohighlight">\(Y\)</span> <em>defining <span class="math notranslate nohighlight">\(3/4\)</span> sides of a rectangle</em> (see below) and some others just travel through <span class="math notranslate nohighlight">\(Y\)</span> without defining any rectangle.</p></li>
</ol>
<p>In our example:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
(\mathbf{X}\mathbf{M})\mathbf{Y} = 
\begin{array}{l}
a\\
b\\
c\\
\end{array}
\begin{bmatrix}
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
\end{bmatrix}
\cdot\;
\begin{array}{l}
1\\
2\\
3\\
4\\
5\\
\end{array}
\begin{bmatrix}
0 &amp; 1 &amp; 1 &amp; 1 &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
\end{bmatrix} = 
\begin{bmatrix}
\mathbf{1} &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
0 &amp; 1 &amp; 1 &amp; \mathbf{2} &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; \mathbf{1}\\
\end{bmatrix}
\end{split}\]</div>
<p>Then, the following paths <strong>do</strong> form <span class="math notranslate nohighlight">\(3/4\)</span> of a rectangle (in bold in <span class="math notranslate nohighlight">\((\mathbf{X}\mathbf{M})\mathbf{Y}\)</span>):</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
((\mathbf{X}\mathbf{M})\mathbf{Y})_{a1} &amp;= a\rightarrow b\rightarrow 4\rightarrow 1\\
((\mathbf{X}\mathbf{M})\mathbf{Y})_{b4} &amp;= b\rightarrow a\rightarrow 1\rightarrow 4 + b\rightarrow c\rightarrow 5\rightarrow 4\\
((\mathbf{X}\mathbf{M})\mathbf{Y})_{a1} &amp;= a\rightarrow b\rightarrow 4\rightarrow 1\\
\end{align}
\end{split}\]</div>
<p>where it is significant the <span class="math notranslate nohighlight">\(2\)</span> paths of <span class="math notranslate nohighlight">\(((\mathbf{X}\mathbf{M})\mathbf{Y})_{b4}\)</span> between nodes <span class="math notranslate nohighlight">\(b\in V\)</span> and <span class="math notranslate nohighlight">\(4\in V'\)</span> (see <a class="reference internal" href="#mpaths3"><span class="std std-numref">Fig. 2.8</span></a>):</p>
<figure class="align-center" id="mpaths3">
<a class="reference internal image-reference" href="_images/MatchingPaths3-Photoroom.png"><img alt="_images/MatchingPaths3-Photoroom.png" src="_images/MatchingPaths3-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.8 </span><span class="caption-text">Two <span class="math notranslate nohighlight">\(3/4\)</span> matching paths <span class="math notranslate nohighlight">\(b\rightarrow a\rightarrow 1\rightarrow 4\)</span> and <span class="math notranslate nohighlight">\(b\rightarrow c\rightarrow 5\rightarrow 4\)</span>.</span><a class="headerlink" href="#mpaths3" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>On the other hand, theses other paths <strong>do not</strong> form <span class="math notranslate nohighlight">\(3/4\)</span> of a rectangle:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
((\mathbf{X}\mathbf{M})\mathbf{Y})_{a5} &amp;= a\rightarrow b\rightarrow 4\rightarrow 5\\
((\mathbf{X}\mathbf{M})\mathbf{Y})_{b2} &amp;= b\rightarrow a\rightarrow 1\rightarrow 2\\
((\mathbf{X}\mathbf{M})\mathbf{Y})_{b3} &amp;= b\rightarrow a\rightarrow 1\rightarrow 3\\
((\mathbf{X}\mathbf{M})\mathbf{Y})_{c1} &amp;= c\rightarrow b\rightarrow 4\rightarrow 1\\
\end{align}
\end{split}\]</div>
<p>For instance, paths <span class="math notranslate nohighlight">\(a\gg b\rightarrow 4\gg 5\)</span> and <span class="math notranslate nohighlight">\(c\gg b\rightarrow 4\gg 1\)</span> diverge from rectangles
where the notation <span class="math notranslate nohighlight">\(\gg\)</span> denotes the first and last edges of the paths (see <a class="reference internal" href="#mpaths4"><span class="std std-numref">Fig. 2.9</span></a>).</p>
<figure class="align-center" id="mpaths4">
<a class="reference internal image-reference" href="_images/MPaths4-Photoroom.png"><img alt="_images/MPaths4-Photoroom.png" src="_images/MPaths4-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.9 </span><span class="caption-text">Paths <span class="math notranslate nohighlight">\(a\gg b\rightarrow 4\gg 5\)</span> and <span class="math notranslate nohighlight">\(c\gg b\rightarrow 4\gg 1\)</span> diverge from rectangles.</span><a class="headerlink" href="#mpaths4" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Similarly, paths <span class="math notranslate nohighlight">\(b\gg a\rightarrow 1\gg 2\)</span> and <span class="math notranslate nohighlight">\(b\gg a\rightarrow 1\gg 3\)</span> diverge even more clearly from ending up in rectangles (see <a class="reference internal" href="#mpaths5"><span class="std std-numref">Fig. 2.10</span></a>).</p>
<figure class="align-center" id="mpaths5">
<a class="reference internal image-reference" href="_images/MPaths5-Photoroom.png"><img alt="_images/MPaths5-Photoroom.png" src="_images/MPaths5-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.10 </span><span class="caption-text">Remaining diverging paths in <span class="math notranslate nohighlight">\({\cal M}\)</span>.</span><a class="headerlink" href="#mpaths5" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ol class="arabic simple" start="3">
<li><p><strong>Closing rectangles</strong>. Once we have <span class="math notranslate nohighlight">\((\mathbf{X}\mathbf{M})\mathbf{Y}\)</span> we simply perform a <em>pointwise</em> multiplication (Hadamard product) to close the rectangle:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
((\mathbf{X}\mathbf{M})\mathbf{Y})\odot \mathbf{M}\;.
\]</div>
<p>In our example:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
((\mathbf{X}\mathbf{M})\mathbf{Y})\odot \mathbf{M} = 
\begin{bmatrix}
\mathbf{1} &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
0 &amp; 1 &amp; 1 &amp; \mathbf{2} &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; \mathbf{1}\\
\end{bmatrix}\odot 
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
\end{bmatrix} = 
\begin{bmatrix}
\mathbf{1} &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; \mathbf{2} &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; \mathbf{1}\\
\end{bmatrix}
\end{split}\]</div>
<p>Note that <span class="math notranslate nohighlight">\(a\)</span> closes <span class="math notranslate nohighlight">\(1\)</span> rectangle, <span class="math notranslate nohighlight">\(c\)</span> closes <span class="math notranslate nohighlight">\(1\)</span> and <span class="math notranslate nohighlight">\(b\)</span> closes <span class="math notranslate nohighlight">\(2\)</span> (one for <span class="math notranslate nohighlight">\(a\)</span> and another one for <span class="math notranslate nohighlight">\(c\)</span>). Therefore the multiplication <span class="math notranslate nohighlight">\(((\mathbf{X}\mathbf{M})\mathbf{Y})\odot \mathbf{M}\)</span> simply <strong>filters out</strong> impossible rectangles. The result is in <a class="reference internal" href="#mpaths6"><span class="std std-numref">Fig. 2.11</span></a>.</p>
<figure class="align-center" id="mpaths6">
<a class="reference internal image-reference" href="_images/MPaths6-Photoroom.png"><img alt="_images/MPaths6-Photoroom.png" src="_images/MPaths6-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.11 </span><span class="caption-text">Final rectangles in <span class="math notranslate nohighlight">\({\cal M}\)</span>.</span><a class="headerlink" href="#mpaths6" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ol class="arabic simple" start="4">
<li><p><strong>Counting</strong>. Note that the number of rectangles comes naturally from</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
F(\mathbf{M}) = \frac{1}{2}\sum_{a}\sum_{i}(((\mathbf{X}\mathbf{M})\mathbf{Y})\odot \mathbf{M})_{ai}\;,
\]</div>
<p>which is <span class="math notranslate nohighlight">\(2\)</span> in this case, as expected! Let us review these concepts in the following exercise:</p>
<p><br></br>
<span style="color:#d94f0b">
<strong>Exercise</strong>. Given the following graphs <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
&amp;\begin{array}{cll}
\text{Graph}  &amp; \text{Nodes} &amp; \text{Edges}\\
X &amp; V=\{a,b,c\} &amp; E=\{(a,b),(b,c)\}\\
Y &amp; V'=\{1,2,3,4,5\} &amp; E=\{(1,2),(1,3),(2,4),(3,4),(1,5),(2,5)\}\\
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<strong>a)</strong> Draw them so that the assignment <span class="math notranslate nohighlight">\(f=[(a,1),(b,2),(c,3)]\)</span> is clearly visisble. Is <span class="math notranslate nohighlight">\(X\)</span> a subgraph of <span class="math notranslate nohighlight">\(Y\)</span>? If so, what is the maximal number of rectangles to close in <span class="math notranslate nohighlight">\({\cal M}(f^{\ast})\)</span> and find an optimal assignment <span class="math notranslate nohighlight">\(f^{\ast}\)</span>.
</span>
<br></br></p>
<figure class="align-center" id="mini">
<a class="reference internal image-reference" href="_images/MiniMatch-Photoroom.png"><img alt="_images/MiniMatch-Photoroom.png" src="_images/MiniMatch-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.12 </span><span class="caption-text">Matching graph <span class="math notranslate nohighlight">\({\cal M}\)</span> for <span class="math notranslate nohighlight">\(f=[(a,1),(b,2),(c,3)]\)</span>.</span><a class="headerlink" href="#mini" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><br></br>
<span style="color:#d94f0b">
In <a class="reference internal" href="#mini"><span class="std std-numref">Fig. 2.12</span></a>, we show a 3D projection of both graphs where the assignment is clearly visible. Clearly, <span class="math notranslate nohighlight">\(X\)</span> is a subgraph of <span class="math notranslate nohighlight">\(Y\)</span>. As a result, we can map all vertices and edges of <span class="math notranslate nohighlight">\(X\)</span> to <span class="math notranslate nohighlight">\(Y\)</span>, closing at most <span class="math notranslate nohighlight">\(3\)</span> rectangles.
</span>
<br></br>
<span style="color:#d94f0b">
<strong>b)</strong> Is that optimal assignment unique? Compute the maximum number of rectangles by matricially evaluating <span class="math notranslate nohighlight">\(M^{\ast}\)</span>, the matching matrix corresponding to an optimal assignment. Indicate the <strong>matching paths</strong> in each step.
</span>
<br></br>
<span style="color:#d94f0b">
In this case the optimal assignment is unique: it comes from matching the notable vertices between both graphs and it is <span class="math notranslate nohighlight">\(f=[(a,1),(b,2),(c,5)]\)</span> since this is the only way to embed <span class="math notranslate nohighlight">\(X\)</span> in <span class="math notranslate nohighlight">\(Y\)</span> completely (see <a class="reference internal" href="#mini2"><span class="std std-numref">Fig. 2.13</span></a>).
</span>
<br></br></p>
<figure class="align-center" id="mini2">
<a class="reference internal image-reference" href="_images/MiniMatch2-Photoroom.png"><img alt="_images/MiniMatch2-Photoroom.png" src="_images/MiniMatch2-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.13 </span><span class="caption-text">Matching graph <span class="math notranslate nohighlight">\({\cal M}\)</span> for <span class="math notranslate nohighlight">\(f=[(a,1),(b,2),(c,5)]\)</span>.</span><a class="headerlink" href="#mini2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><br></br>
<span style="color:#d94f0b">
Matricially, we have
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
\mathbf{X} = 
\begin{array}{l}
a\\
b\\
c\\
\end{array}
\begin{bmatrix}
0 &amp; 1 &amp; 1 \\
1 &amp; 0 &amp; 1 \\
1 &amp; 1 &amp; 0 \\
\end{bmatrix}
\;\; 
\mathbf{Y} = 
\begin{array}{l}
1\\
2\\
3\\
4\\
5\\
\end{array}
\begin{bmatrix}
0 &amp; 1 &amp; 1 &amp; 0 &amp; 1\\
1 &amp; 0 &amp; 0 &amp; 1 &amp; 1\\
1 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 1 &amp; 1 &amp; 0 &amp; 0\\
1 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\
\end{bmatrix}
\;\;\text{and}\;\;
\mathbf{M}^{\ast} = \begin{array}{l}
a\\
b\\
c\\
\end{array}
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Then, we proceed to evaluate
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
F(\mathbf{M}^{\ast}) = \frac{1}{2}\sum_{a}\sum_{i}(((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})\odot \mathbf{M}^{\ast})_{ai}\;,
 \)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<strong>Step 1:</strong> Compute <span class="math notranslate nohighlight">\(\mathbf{X}\mathbf{M}^{\ast}\)</span>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
\mathbf{X}\mathbf{M}^{\ast} = 
\begin{array}{l}
a\\
b\\
c\\
\end{array}
\begin{bmatrix}
0 &amp; 1 &amp; 1 \\
1 &amp; 0 &amp; 1 \\
1 &amp; 1 &amp; 0 \\
\end{bmatrix}
\;\cdot \;
\begin{array}{l}
a\\
b\\
c\\
\end{array}
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix} = 
\begin{bmatrix}
0 &amp; 1 &amp; 0 &amp; 0 &amp; 1\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
1 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\
\end{bmatrix}
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
And the paths so far are:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
(\mathbf{X}\mathbf{M}^{\ast})_{a2} &amp;= a\rightarrow b\rightarrow 2\\
(\mathbf{X}\mathbf{M}^{\ast})_{a5} &amp;= a\rightarrow c\rightarrow 5\\
(\mathbf{X}\mathbf{M}^{\ast})_{b1} &amp;= b\rightarrow a\rightarrow 1\\
(\mathbf{X}\mathbf{M}^{\ast})_{b5} &amp;= b\rightarrow c\rightarrow 5\\
(\mathbf{X}\mathbf{M}^{\ast})_{c1} &amp;= c\rightarrow a\rightarrow 1\\
(\mathbf{X}\mathbf{M}^{\ast})_{c2} &amp;= c\rightarrow b\rightarrow 2\\
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<strong>Step 2:</strong> Compute <span class="math notranslate nohighlight">\((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y}\)</span>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
(\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y} = 
\begin{array}{l}
a\\
b\\
c\\
\end{array}
\begin{bmatrix}
0 &amp; 1 &amp; 0 &amp; 0 &amp; 1\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
1 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\
\end{bmatrix}
\cdot\; 
\begin{array}{l}
1\\
2\\
3\\
4\\
5\\
\end{array}
\begin{bmatrix}
0 &amp; 1 &amp; 1 &amp; 0 &amp; 1\\
1 &amp; 0 &amp; 0 &amp; 1 &amp; 1\\
1 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 1 &amp; 1 &amp; 0 &amp; 0\\
1 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\
\end{bmatrix} = 
\begin{bmatrix}
2 &amp; 1 &amp; 0 &amp; 1 &amp; 1\\
1 &amp; 2 &amp; 1 &amp; 0 &amp; 1\\
1 &amp; 1 &amp; 1 &amp; 1 &amp; 2\\
\end{bmatrix}
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
And the <span class="math notranslate nohighlight">\(3/4\)</span>-rectangle paths are:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{a1} &amp;= a\rightarrow b\rightarrow 2\rightarrow 1 + a\rightarrow  c\rightarrow 5\rightarrow 1\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{a2} &amp;= a\rightarrow c\rightarrow 5\rightarrow 2\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{a4} &amp;= a\rightarrow b\rightarrow 2\rightarrow 4\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{a5} &amp;= a\rightarrow b\rightarrow 2\rightarrow 5\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{b1} &amp;= b\rightarrow c\rightarrow 5\rightarrow 1\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{b2} &amp;= b\rightarrow a\rightarrow 1\rightarrow 2 + 
b\rightarrow c\rightarrow 5\rightarrow 2\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{b3} &amp;= b\rightarrow a\rightarrow 1\rightarrow 3\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{b5} &amp;= b\rightarrow a\rightarrow 1\rightarrow 5\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{c1} &amp;= c\rightarrow b\rightarrow 2\rightarrow 1\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{c2} &amp;= c\rightarrow a\rightarrow 1\rightarrow 2\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{c3} &amp;= c\rightarrow a\rightarrow 1\rightarrow 3\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{c4} &amp;= c\rightarrow b\rightarrow 2\rightarrow 4\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{c5} &amp;= c\rightarrow a\rightarrow 1\rightarrow 5 + 
c\rightarrow b\rightarrow 2\rightarrow 5\\
\end{align}
\)</span>
</span>
<br><br>
<span style="color:#d94f0b">
<strong>Step 3</strong>. We higlight the correct matches and apply Hadamard product:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})\odot \mathbf{M}^{\ast} = 
\begin{bmatrix}
\mathbf{2} &amp; 1 &amp; 0 &amp; 1 &amp; 1\\
1 &amp; \mathbf{2} &amp; 1 &amp; 0 &amp; 1\\
1 &amp; 1 &amp; 1 &amp; 1 &amp; \mathbf{2}\\
\end{bmatrix}
\odot\; 
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Finally, if we sum all the components of the Hadamard product and divide by <span class="math notranslate nohighlight">\(2\)</span> we have <span class="math notranslate nohighlight">\(3\)</span> rectangles as shown in <a class="reference internal" href="#mini2"><span class="std std-numref">Fig. 2.13</span></a>. We are done!
</span></p>
</section>
<section id="integer-constraints-qap">
<h3><span class="section-number">2.2.3. </span>Integer Constraints: QAP<a class="headerlink" href="#integer-constraints-qap" title="Permalink to this heading">#</a></h3>
<p>We have clarified an objective function of MCS (graph matching) <span class="math notranslate nohighlight">\(F(\mathbf{M})\)</span> interpretation for a particular <span class="math notranslate nohighlight">\(\mathbf{M}\in\{0,1\}^{n\times m}\)</span> (number of rectangles). The function is <span style="color:#f88146"><strong>quadratic</strong> in <span class="math notranslate nohighlight">\(\mathbf{M}\)</span></span> since it requires two multiplications of the matching matrix for its evaluation, but evaluating it takes <span class="math notranslate nohighlight">\(O(n^4)\)</span>.</p>
<p>In addition, the structure of <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is not simply binary. Since each candidate assignment <span class="math notranslate nohighlight">\(f\)</span> encoded by this matrix must be an injective (one-to-one) function <span class="math notranslate nohighlight">\(f:V\rightarrow V'\)</span> we have that for <span class="math notranslate nohighlight">\(m\le n\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\forall a\in V:\sum_{i\in V'}\mathbf{M}_{ai}\le 1\;\text{and}\; \forall i\in V':\sum_{a\in V}\mathbf{M}_{ai}\le 1\;,
\]</div>
<p>i.e. each row/column cannot have more than one <span class="math notranslate nohighlight">\(1\)</span>. Some precisions:</p>
<ul class="simple">
<li><p>Formally, all row/column may be all-zeros but if they are, then we do not have a solution.</p></li>
<li><p>In particular, we need to match a coumple of vertices to close a single rectangle. Therefore we need at least to columns with a single one placed in different rows.</p></li>
<li><p>Thus, the above notation means that if one row/column is all-zeros there is only one of them which is not!</p></li>
<li><p>Ideally, for <span class="math notranslate nohighlight">\(m\le n\)</span> we should have <span class="math notranslate nohighlight">\(m\)</span> columns with a <span class="math notranslate nohighlight">\(1\)</span> all placed in different rows.</p></li>
</ul>
<p>This constrained nature of the so called <span style="color:#f88146"><strong>Quadratic Assignment Problem (QAP)</strong></span> is what makes it NP:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbf{M}^{\ast}= &amp; \arg\max_{{\cal P}}F(\mathbf{M}) = \frac{1}{2}\sum_{a\in V}\sum_{i\in V'}\sum_{b\in V}\sum_{j\in V'}\mathbf{M}_{ai}\mathbf{M}_{bj}\mathbf{X}_{ab}\mathbf{Y}_{ij}\\
{\cal P}=&amp;\left\{\mathbf{M}\in \{0,1\}^{m\times n}:\forall a\in V:\sum_{i\in V'}\mathbf{M}_{ai}\le 1\;\text{and}\; \forall i\in V':\sum_{a\in V}\mathbf{M}_{ai}\le 1\;\right\}
\end{align}
\end{split}\]</div>
<p>Therefore, the QAP (we use this name in the following) is originally posed in terms of <span style="color:#f88146"><strong>Integer Programming (IP)</strong></span>
since the <em>unknowns</em> to discover are binary <span class="math notranslate nohighlight">\(m\times n\)</span> matrices <span class="math notranslate nohighlight">\(\mathbf{M}\in\{0,1\}^{m\times n}\)</span> subject to be in <span class="math notranslate nohighlight">\({\cal P}\)</span>.</p>
<p>In particular, if <span class="math notranslate nohighlight">\(m=n\)</span> (both graphs have the same number of nodes), then:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\({\cal P}\)</span> becomes <span class="math notranslate nohighlight">\(\Pi_n\)</span>, the space of <em>permutations</em> of order <span class="math notranslate nohighlight">\(n\)</span> and we have <span class="math notranslate nohighlight">\(n!\)</span> <em>bijections</em> <span class="math notranslate nohighlight">\(f=\pi:V\rightarrow V'\)</span>.</p></li>
<li><p>Each matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> encodes a permutation <span class="math notranslate nohighlight">\(\pi(a),\pi(b),\ldots\)</span>, where <span class="math notranslate nohighlight">\(V=\{a,b,\ldots\}\)</span> with <span class="math notranslate nohighlight">\(|V|=n\)</span> are the rows of <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> (each one with a unique <span class="math notranslate nohighlight">\(1\)</span> at different columns.</p></li>
<li><p>Then <span class="math notranslate nohighlight">\(V'=\{\pi(i):i\in\{a,b,c,\ldots\}\}\)</span> with <span class="math notranslate nohighlight">\(|V'|=n\)</span> and <span class="math notranslate nohighlight">\(\pi^{-1}(i)\in V\)</span> does exist and it is unique.</p></li>
</ul>
<p>More formally:</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
\Pi_n=&amp;\left\{\mathbf{M}\in \{0,1\}^{m\times n}:\forall a\in V:\sum_{i\in V'}\mathbf{M}_{ai}= 1\;\text{and}\; \forall i\in V':\sum_{a\in V}\mathbf{M}_{ai}= 1\;\right\}
\end{align}
\]</div>
<p>where we have transformed the inequality constraints into equality ones!</p>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Permutohedron">Permutohedron</a> is a useful means of visualizing the space of solutions <span class="math notranslate nohighlight">\(\Pi_n\)</span>. Each point is a permutation <span class="math notranslate nohighlight">\(\pi\)</span> and it has <span class="math notranslate nohighlight">\(n-1\)</span> neighbors. Given <span class="math notranslate nohighlight">\(\pi\)</span>, its neighboring permutations <span class="math notranslate nohighlight">\(\pi'\in {\cal N}_{\pi}\)</span> differ from <span class="math notranslate nohighlight">\(\pi\)</span> in <em>one transposition</em>, i.e. one interchange between two components.</p>
<p>For instance, in <a class="reference internal" href="#pin"><span class="std std-numref">Fig. 2.14</span></a> we show <span class="math notranslate nohighlight">\(\Pi_4\)</span>. It has <span class="math notranslate nohighlight">\(n!=24\)</span> nodes with <span class="math notranslate nohighlight">\(n-1=3\)</span> neighbors each. For instance, the neighbors of <span class="math notranslate nohighlight">\(\pi=[3,4,2,1]\)</span> are <span class="math notranslate nohighlight">\({\cal N}_{\pi}=\{[2,4,3,1],[3,4,1,2],[4,3,2,1]\}\)</span>, where  <span class="math notranslate nohighlight">\(\pi'=[2,4,3,1]\)</span> is the result of interchanging (transposing) <span class="math notranslate nohighlight">\(2\)</span> and <span class="math notranslate nohighlight">\(3\)</span> in <span class="math notranslate nohighlight">\(\pi=[3,4,2,1]\)</span>.</p>
<figure class="align-center" id="pin">
<a class="reference internal image-reference" href="_images/PiN-Photoroom.png"><img alt="_images/PiN-Photoroom.png" src="_images/PiN-Photoroom.png" style="width: 600px; height: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.14 </span><span class="caption-text">Permutohedron for of order <span class="math notranslate nohighlight">\(n=4\)</span>. Please define the unlabeled nodes.</span><a class="headerlink" href="#pin" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="simulated-annealing">
<h2><span class="section-number">2.3. </span>Simulated Annealing<a class="headerlink" href="#simulated-annealing" title="Permalink to this heading">#</a></h2>
<p>The Permutohedron provides a glimpse of the <span style="color:#f88146"><strong>discrete seach space</strong></span>, specially because it highlighs its topology, i.e. its local structure.</p>
<p>With this instrument to hand, it is natural to <span style="color:#f88146">envision <strong>intelligent search</strong> as a random walk between an initial permutation <span class="math notranslate nohighlight">\(\pi^0\)</span> and a final one <span class="math notranslate nohighlight">\(\pi^{\ast}\)</span></span>:</p>
<ul class="simple">
<li><p>The <em>intelligence</em> is partially provided by the <strong>objective function</strong> <span class="math notranslate nohighlight">\(F(\pi)\)</span> that discriminates between good and bad solutions.</p></li>
<li><p>The <em>search strategy</em> is what exploits the knowledge provided by the objective function. One of the simplest strategies is that of a <strong>random walk (RW)</strong> <span class="math notranslate nohighlight">\(\pi^0\rightarrow\pi^1\rightarrow\ldots\rightarrow \pi^{\ast}\)</span> inside <span class="math notranslate nohighlight">\(\Pi_n\)</span>.</p></li>
</ul>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Simulated_annealing">Simulated Annealing (SA)</a> is a principled way of combining intelligence and RW-search. It works as follows:</p>
<p>Let <span class="math notranslate nohighlight">\(\Omega\)</span> be the <strong>search space</strong> and <span class="math notranslate nohighlight">\(\omega\in \Omega\)</span> a <strong>discrete state</strong>, then we define a <strong>Markov chain</strong> <span class="math notranslate nohighlight">\(X_0,X_1,\ldots\)</span> for a <em>maximization problem</em> as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
p(X_{t+1}=\omega'|X_{t}=\omega) =
\begin{cases}
     1 &amp;\;\text{if}\; \Delta F\ge 0 \\[2ex]
     \exp(\beta(t)\cdot \Delta F)&amp;\;\text{otherwise}\\[2ex]
\end{cases}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\Delta F:=F(\omega')-F(\omega)\)</span> and <span class="math notranslate nohighlight">\(\beta(t):=\frac{1}{T(t)}\)</span> where <span class="math notranslate nohighlight">\(T\)</span> is the <strong>computational temperature</strong>. Some explanations:</p>
<ul class="simple">
<li><p>Since we are maximizing <span class="math notranslate nohighlight">\(F\)</span>, having <span class="math notranslate nohighlight">\(\Delta F:=F(\omega')-F(\omega)\ge 0\)</span> for <span class="math notranslate nohighlight">\(\omega'\in {\cal N}_{\omega}\)</span> means that <span class="math notranslate nohighlight">\(F(\omega')\ge F(\omega)\)</span>, i.e. that we are in the <em>correct way</em> (or at least not in the wrong way!). In this case, we should <strong>accept</strong> (with probability <span class="math notranslate nohighlight">\(1\)</span>) <span class="math notranslate nohighlight">\(\omega'\)</span> as the new state of the search.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(F(\omega')&lt; F(\omega)\)</span>, a <strong>greedy method</strong> or a <strong>branch-and-bound</strong> should reject <span class="math notranslate nohighlight">\(\omega'\)</span> as a promising direction. However, SA gives a <strong>chance of acceptance</strong> which is proportional to how far is <span class="math notranslate nohighlight">\(\omega'\)</span> of being promising, which is <span class="math notranslate nohighlight">\(\Delta F = F(\omega')-F(\omega)&lt; 0\)</span>.</p></li>
</ul>
<p>However, if <span class="math notranslate nohighlight">\(F(\omega')&lt; F(\omega)\)</span>, the chance of accepting <span class="math notranslate nohighlight">\(\omega'\)</span> must depend of the <strong>stage of the search process</strong> where we take the decision. This stage is parameterized by the computational temperature <span class="math notranslate nohighlight">\(\beta(t)=\frac{1}{T(t)}\)</span></p>
<p>Suppose that the computational temperature is <span class="math notranslate nohighlight">\(T(t)\)</span> is a <strong>monotonic decreasing function</strong> with <span class="math notranslate nohighlight">\(t\)</span> such as <span class="math notranslate nohighlight">\(T(t)=\frac{1}{\log(1+t)}\)</span>. This is why this is called an <strong>annealing schedule</strong> Then:</p>
<ul class="simple">
<li><p>At <span class="math notranslate nohighlight">\(t\rightarrow 0\)</span> (early stages of the search) the chance should be hight. Then, we usually set <span class="math notranslate nohighlight">\(T(0)\rightarrow\infty\)</span> (high temperature). As <span class="math notranslate nohighlight">\(\Delta F&lt;0\)</span>, then <span class="math notranslate nohighlight">\(\exp(\beta(t)\cdot \Delta F)\)</span> does not decays too much, since it is attenuated. As a result, solutions <span class="math notranslate nohighlight">\(\omega'\)</span> with <span class="math notranslate nohighlight">\(\Delta F&lt;0\)</span> are typically accepted if <span class="math notranslate nohighlight">\(|\Delta F&lt;0|\)</span> is small enough. The larger <span class="math notranslate nohighlight">\(|\Delta F&lt;0|\)</span> the more probable that <span class="math notranslate nohighlight">\(\omega'\)</span> is consider an <strong>extremal event</strong> (part of the queue of the exponential) and thus discarded.</p></li>
<li><p>However, for <span class="math notranslate nohighlight">\(t\rightarrow \infty\)</span>, we have <span class="math notranslate nohighlight">\(T(t)\rightarrow 0\)</span> (low temperature). The same decrement <span class="math notranslate nohighlight">\(|\Delta F&lt;0|\)</span> that was admissible for smaller values of <span class="math notranslate nohighlight">\(t\)</span> is not yet accepted because SA behaves like a greedy method.</p></li>
</ul>
<div class="proof algorithm admonition" id="Metropolis">
<p class="admonition-title"><span class="caption-number">Algorithm 2.1 </span> (Metropolis-Hastings)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inputs</strong> Given a function <span class="math notranslate nohighlight">\(F(\omega)\)</span>, an annealing schedule <span class="math notranslate nohighlight">\(T(t)\)</span> and an inital state <span class="math notranslate nohighlight">\(\omega_0\)</span><br />
<strong>Output</strong> <span class="math notranslate nohighlight">\(\omega^{\ast}=\arg\max_{\omega\in\Omega} F(\omega)\)</span></p>
<ol class="arabic simple">
<li><p>convegence = False</p></li>
<li><p><span class="math notranslate nohighlight">\(\omega_{old}\leftarrow \omega_0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(t\leftarrow 0\)</span></p></li>
<li><p><strong>while</strong> <span class="math notranslate nohighlight">\(\neg\)</span> convergence:</p>
<ol class="arabic simple">
<li><p>Select <span class="math notranslate nohighlight">\(\omega'\in {\cal N}_{\omega}\)</span></p></li>
<li><p>Calculate <span class="math notranslate nohighlight">\(\Delta F=F(\omega')-F(\omega_{old})\)</span></p></li>
<li><p><strong>if</strong> <span class="math notranslate nohighlight">\(\Delta F\ge 0\)</span> <strong>then</strong> <span class="math notranslate nohighlight">\(\omega_{new}\leftarrow \omega'\)</span></p></li>
<li><p><strong>else</strong>:</p>
<ol class="arabic simple">
<li><p>Draw <span class="math notranslate nohighlight">\(p\in [0,1]\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(q\leftarrow \exp\left(\frac{\Delta F}{T(t)}\right)\)</span></p></li>
<li><p><strong>if</strong> <span class="math notranslate nohighlight">\(q\ge p\)</span> <strong>then</strong> <span class="math notranslate nohighlight">\(\omega_{new}\leftarrow \omega'\)</span></p></li>
</ol>
</li>
<li><p><span class="math notranslate nohighlight">\(t\leftarrow t+1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(T(t)\leftarrow \frac{1}{\log(1 + t)}\)</span></p></li>
<li><p>convergence = <span class="math notranslate nohighlight">\((T(t)&lt;T_{min})\)</span> <strong>or</strong> <span class="math notranslate nohighlight">\((t&gt;t_{max})\)</span></p></li>
</ol>
</li>
<li><p><strong>return</strong> <span class="math notranslate nohighlight">\(\omega_{new}\)</span></p></li>
</ol>
</section>
</div><section id="approximating-qap-with-sa">
<h3><span class="section-number">2.3.1. </span>Approximating QAP with SA<a class="headerlink" href="#approximating-qap-with-sa" title="Permalink to this heading">#</a></h3>
<p>Let us apply SA to approximate the QAP. To that end, we are going to <strong>match the Aspirin’s structure</strong> (see <a class="reference internal" href="#sa-aspirin"><span class="std std-numref">Fig. 2.16</span></a>-Left) with a random permutation of its vertices (<a class="reference internal" href="#sa-aspirin"><span class="std std-numref">Fig. 2.16</span></a>-Right). The left graph with nodes <span class="math notranslate nohighlight">\(V=\{a,b,\ldots,m\}\)</span> and links, mimics the structure of the Aspirin. In this first approach we discard, for the moment, both nodes (atom) labels (<span class="math notranslate nohighlight">\(\text{C}\)</span>,<span class="math notranslate nohighlight">\(\text{O}\)</span> and <span class="math notranslate nohighlight">\(\text{OH}\)</span>) and edges (bonds) labels (single, double).</p>
<p>On the right, the graph has nodes <span class="math notranslate nohighlight">\(V'=\{1,2,\ldots,13\}\)</span>. Since <span class="math notranslate nohighlight">\(|V|=|V'|=13\)</span>, there <strong>state space</strong> <span class="math notranslate nohighlight">\(\Omega\)</span> is given by the <span class="math notranslate nohighlight">\(\Pi_{n=13}\)</span> Permutohedron, with  <span class="math notranslate nohighlight">\(n!\approx 6\times 10^{9}\)</span> states, each one with <span class="math notranslate nohighlight">\(n-1=12\)</span> edges.</p>
<p>We know that the optimal permutation <span class="math notranslate nohighlight">\(\pi^{\ast}\)</span> is given by <span class="math notranslate nohighlight">\(\pi^{\ast}(a)=1,\pi^{\ast}(b)=2,\ldots, \pi^{\ast}(m)=13\)</span>, i.e. <span class="math notranslate nohighlight">\(\mathbf{M}^{\ast}=\mathbf{I}_n\)</span> is the identity matrix of dimension <span class="math notranslate nohighlight">\(n\)</span>. However, we assume a realistic case where the input permutation <span class="math notranslate nohighlight">\(\pi^0\)</span> is rather different from the optimal one:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\pi^0 = 
\begin{bmatrix}
\overbrace{7}^a &amp; \overbrace{12}^b &amp; \overbrace{5}^{c} &amp; \overbrace{11}^{d} &amp; \overbrace{3}^e &amp; \overbrace{9}^f &amp; \overbrace{2}^g &amp; \overbrace{8}^h &amp; \overbrace{10}^i &amp; \overbrace{4}^j &amp; \overbrace{1}^k &amp; \overbrace{6}^l &amp; \overbrace{13}^m\\
\end{bmatrix}
\end{split}\]</div>
<p><strong>1) Initial Matching</strong>. However, instead of starting SA with a random <span class="math notranslate nohighlight">\(\pi^0\)</span>, it is a good practice to compute a <span style="color:#f88146"><strong>greedy approximation</strong></span>. In the case of graph matching or QAP, a greedy algorithm may rely on matching <span class="math notranslate nohighlight">\(a,b,c,\ldots\)</span> with nodes <span class="math notranslate nohighlight">\(1,2,3,\ldots\)</span> in such a way that it is <span style="color:#f88146"><em>preferred to match nodes with the largest number of neighbors (degree) as possible</em></span>.</p>
<p>Then, the greedy matching leads to</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\pi^0 = 
\begin{bmatrix}
\overbrace{3}^a &amp; \overbrace{4}^b &amp; \underline{\overbrace{5}^{c}} &amp; \overbrace{9}^{d} &amp; \underline{\overbrace{1}^e} &amp; \overbrace{6}^f &amp; \overbrace{8}^g &amp; \overbrace{10}^h &amp; \overbrace{12}^i &amp; \overbrace{2}^j &amp; \overbrace{7}^k &amp; \overbrace{10}^l &amp; \overbrace{13}^m\\
\end{bmatrix}
\end{split}\]</div>
<p>We check <a class="reference internal" href="#sa-aspirin"><span class="std std-numref">Fig. 2.16</span></a>, where we plot the <em>final approximation of SA</em> with <span class="math notranslate nohighlight">\(10\)</span> closing rectangles, that the greedy <span class="math notranslate nohighlight">\(\pi^0\)</span> is consistent with matching nodes with mutually largerst degrees:</p>
<ul class="simple">
<li><p>We underlined the matchings with largest degrees (maximum degree is <span class="math notranslate nohighlight">\(3\)</span>): <span class="math notranslate nohighlight">\(c\rightarrow 5\)</span>, <span class="math notranslate nohighlight">\(e\rightarrow 1\)</span>.</p></li>
<li><p>One of the risks of greedy matching is that we may be <strong>stuck in a local maximum</strong>, which really happens (SA here recovers from <span class="math notranslate nohighlight">\(e\rightarrow 1\)</span> but not from <span class="math notranslate nohighlight">\(c\rightarrow 5\)</span>).</p></li>
<li><p>However, the proper annealing scheduling typically <strong>takes the search out of local optima</strong> in the early stages of the search.</p></li>
</ul>
<p><strong>2) Neighboring</strong>. The second aspect to define when applying SA to the QAP is how to <span style="color:#f88146"><strong>ensure proper neighborhoods <span class="math notranslate nohighlight">\({\cal N}_{\omega}\)</span></strong></span>. In other words, if given <span class="math notranslate nohighlight">\(\omega\)</span> we choose as <span class="math notranslate nohighlight">\(\omega'\)</span> an arbitrarily large  random variation, we <em><span style="color:#f88146">may miss the irreducibility property of the Markov chain (all states must be reached)</em></span>.</p>
<p>Then, a good way of navigating properly through the search space (the Permutohedron <span class="math notranslate nohighlight">\(\Pi_n\)</span> in this case) is to:</p>
<ol class="arabic simple">
<li><p><strong>Choose</strong> randomly if we are going to interchange rows or colums in <span class="math notranslate nohighlight">\(\mathbf{M}_{\omega}\)</span>.</p></li>
<li><p><strong>Interchange</strong> two rows (or columns) whose indexes are randomly chosen. The result is <span class="math notranslate nohighlight">\(\mathbf{M}_{\omega'}\)</span></p></li>
</ol>
<p>This is <strong>equivalent</strong> to perform a transposition in the Permutohedron <span class="math notranslate nohighlight">\(\Pi_n\)</span>.</p>
<p><strong>3)Annealing Schedule</strong>. The last ingredient to set is a <span style="color:#f88146"><strong>proper temperature cooling (annealing schedule)</strong></span> and the specific values <span class="math notranslate nohighlight">\(T_0\)</span> and <span class="math notranslate nohighlight">\(T_f\)</span>.</p>
<ul class="simple">
<li><p>In this example, we simply make <span class="math notranslate nohighlight">\(T(t+1)=T(t)-\alpha\cdot T(t)=(1-\alpha)\cdot T(t)\)</span> with <span class="math notranslate nohighlight">\(\alpha\ll 1\)</span>.</p></li>
<li><p>This leads to a neg-exponential decrease since:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
T(1)&amp;=(1-\alpha)\cdot T(0)\\
T(2)&amp;=(1-\alpha)\cdot T(1)=(1-\alpha)^2\cdot T(0)\\
    &amp;\vdots\\
T(n)&amp;=(1-\alpha)\cdot T(n-1)=(1-\alpha)^n\cdot T(0)\\
\end{align}
\end{split}\]</div>
<p>This succession is decreasing since we only multiply <span class="math notranslate nohighlight">\(T(0)\)</span> by a decreasing fraction. Actually, we have set <span class="math notranslate nohighlight">\(T(0)=1/5=0.2\)</span> and <span class="math notranslate nohighlight">\(\alpha = 1/1.075\approx 0.93\)</span>. The exponential decrease can be seen by looking at the <strong>logarithmic transformation</strong> (exponentials are lines in log space):</p>
<div class="math notranslate nohighlight">
\[
T(n) = (1-\alpha)^n\cdot T(0)\Rightarrow \log(T(n))=n\cdot log(1-\alpha) + \log T(0)\;.
\]</div>
<p>Since <span class="math notranslate nohighlight">\((1-\alpha)&lt;1\)</span> then its log is negative!</p>
<p>This schedule is a <strong>bit agressive</strong> but playing a bit with <span class="math notranslate nohighlight">\(\alpha\)</span> we can close <span class="math notranslate nohighlight">\(10-11\)</span> rectangles from <span class="math notranslate nohighlight">\(13\)</span> possible (this is the mumber of edges of the Aspirin graph).</p>
<p>In <a class="reference internal" href="#sa-curves"><span class="std std-numref">Fig. 2.15</span></a> we play with different values of <span class="math notranslate nohighlight">\(\alpha\)</span>. For the sake of clarity, herein we only represent the <strong>best cost obtained so far</strong>. Note that for different regimes we get different results, in this case between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(11\)</span> rectangles. It is interesting to note that:</p>
<ul class="simple">
<li><p>The best result is obtained with one of the smallest <span class="math notranslate nohighlight">\(\alpha\)</span>s (<span class="math notranslate nohighlight">\(\alpha=0.85\)</span>)</p></li>
<li><p>The annealing schedules tend to increase more the objective function <span class="math notranslate nohighlight">\(F\)</span> in the early stages of the seach where SA is more free to explore!</p></li>
<li><p>Note that the most strict schedule (<span class="math notranslate nohighlight">\(\alpha=0.93\)</span>) reaches <span class="math notranslate nohighlight">\(9\)</span> rectangles in the middle stages and finaly peaks <span class="math notranslate nohighlight">\(10\)</span> rectangles. This is the solution showed in <a class="reference internal" href="#sa-aspirin"><span class="std std-numref">Fig. 2.16</span></a>.</p></li>
</ul>
<p>The right image shows the negligible differences betweeen the annealing schedules in the log-log domain.</p>
<figure class="align-center" id="sa-curves">
<a class="reference internal image-reference" href="_images/SA-Curves-Photoroom.png"><img alt="_images/SA-Curves-Photoroom.png" src="_images/SA-Curves-Photoroom.png" style="width: 800px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.15 </span><span class="caption-text">Playing with <span class="math notranslate nohighlight">\(\alpha\)</span> for different annealing schedules.</span><a class="headerlink" href="#sa-curves" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><strong>4)Understanding the solution</strong>. Last, but by no  means least, we have to interpret to what extent our <span class="math notranslate nohighlight">\(F\)</span> reaches or not an <em>interesting solution</em>. Herein, <span style="color:#f88146"><em>interesting means</em> <strong>global</strong></span>. For instance:</p>
<ul class="simple">
<li><p>The solution in <a class="reference internal" href="#sa-aspirin"><span class="std std-numref">Fig. 2.16</span></a> captures mainly the central hexagon, although under a rotation around the <span class="math notranslate nohighlight">\(g-i\)</span> axis and a flipping or torsion wrt the vertical: edge <span class="math notranslate nohighlight">\(f-e\)</span> becomes <span class="math notranslate nohighlight">\(8-10\)</span>, but edge <span class="math notranslate nohighlight">\(h-i\)</span> becomes <span class="math notranslate nohighlight">\(3-9\)</span>.</p></li>
<li><p>The top part of the molecule in the Left  matches a bottom part of that of the Right, indicating a global deformation.</p></li>
<li><p>Also the bottom-left part of the molecule in the Left matches the top part of that in the Right (again a deformation).</p></li>
<li><p>Overall, the largest subgraphs are correctly matched but the smallest ones are misplaced.</p></li>
</ul>
<p>Therefore, althoug the solution obtained seems <strong>quantitatively global</strong> it is partially <strong>qualitatively global</strong>. This reveals a need of making the objective function <span style="color:#f88146"><strong>more informative</strong></span> (we will come back to this point later on).</p>
<figure class="align-center" id="sa-aspirin">
<a class="reference internal image-reference" href="_images/SA-Aspirin-Photoroom.png"><img alt="_images/SA-Aspirin-Photoroom.png" src="_images/SA-Aspirin-Photoroom.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.16 </span><span class="caption-text">Approximating the Aspirin’s Isomorphism with SA.</span><a class="headerlink" href="#sa-aspirin" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="interpretation-of-sa">
<h3><span class="section-number">2.3.2. </span>Interpretation of SA<a class="headerlink" href="#interpretation-of-sa" title="Permalink to this heading">#</a></h3>
<p><strong>Intuitive interpretation</strong>. From an intuitive point of view, SA can be described as follows <a class="reference external" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=645602">Hoffmann and Buhmann 1997</a>:</p>
<ol class="arabic simple">
<li><p>Cost differences between neighboring states act as a <strong>force field</strong>.</p></li>
<li><p>The effect of the computational temperature can be interpreted as a random force with an <strong>amplitude proportional to T</strong>.</p></li>
<li><p>Valleys and peaks with a cost difference less than T are smeared out and <strong>vanish</strong> in the stochastic search. Vanishing is more likely to happen in the early stages of the search where we need to scape from local (subobtimal) solutions.</p></li>
</ol>
<p><strong>Methodological Interpretation</strong>. In the AI jargon, <span class="math notranslate nohighlight">\(F\)</span> is considered an <span style="color:#f88146"><strong>heuristic</strong></span> and SA is considered a <span style="color:#f88146"><strong>meta-heuristic</strong></span>:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Heuristic">Heuristic</a>. This term was introduced by Herbert Simon and it loosely means “seach shortcut”, i.e. some mechanism for deciding what solution is interesting and what is not in a potentially large space of solutions. This concept is our subject. Herein, it is the number of rectangles.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Metaheuristic">Meta-Heuristic</a> are procedures that “modulate the application of a heuristic”. SA is a metaheuristic because it decides when the search is more stochastic and when it becomes more greedy.</p></li>
</ul>
<p><strong>Formal interpretation</strong>. Remember that the <a class="reference external" href="https://arxiv.org/pdf/1504.01896">Metropolis Algorithm</a> implements an irreducible Markov chain <span class="math notranslate nohighlight">\(X_0,X_1,\ldots,X_t\)</span> along <span class="math notranslate nohighlight">\(\Omega\)</span>. This Markov chain is <strong>stationary</strong> i.e. it converges to a given probability distribution <span class="math notranslate nohighlight">\(G\)</span> which means that after a given time step <span class="math notranslate nohighlight">\(t\)</span> if <span class="math notranslate nohighlight">\(X_{t}\sim G(\omega)\)</span> then also <span class="math notranslate nohighlight">\(X_{t+1}\sim G(\omega)\)</span>. The stationary distribution is</p>
<div class="math notranslate nohighlight">
\[
\lim_{t\rightarrow\infty}p(X^{t+1}|X^{t})=G(\omega)\;,
\]</div>
<p>independently of the choose of <span class="math notranslate nohighlight">\(X_0\)</span>. In this case, the stationary distribution <span class="math notranslate nohighlight">\(G(\omega)\)</span> is</p>
<div class="math notranslate nohighlight">
\[
G(\omega) = \frac{\exp(\beta\cdot F(\omega))}{Z},\;\; \text{with}\;\; Z = \sum_{\omega\in\Omega}\exp(\beta\cdot F(\omega))\;,
\]</div>
<p>which is known as the <span style="color:#f88146"><strong>Gibbs distribution</strong></span>. Look, for instance, at the <span class="math notranslate nohighlight">\(q\)</span> variable at the step <span class="math notranslate nohighlight">\(4.2.\)</span> of the Metropolis-Hastings algorithm:</p>
<div class="math notranslate nohighlight">
\[
q\leftarrow \exp\left(\frac{\Delta F}{T(t)}\right) = 
\exp\left(\beta(t)\Delta F\right) = \frac{\exp\left(\beta(t)F(\omega')\right)}{\exp\left(\beta(t) F(\omega_{old})\right)} = \frac{\frac{\exp\left(\beta(t)F(\omega')\right)}{Z(t)}}{\frac{\left(\beta(t) F(\omega_{old})\right)}{Z(t)}}=\frac{G(\omega')}{G(\omega_{old})}\;.
\]</div>
<p>Therefore, the so-called <strong>acceptance probability</strong> is a ratio between two “Gibbsian” probabilities!. Note that in the Gibbs distribution, for a given <span class="math notranslate nohighlight">\(\beta\)</span> the states <span class="math notranslate nohighlight">\(\omega\in \Omega\)</span> with larger <span class="math notranslate nohighlight">\(F(\omega)\)</span> are more probable. As a result, <span class="math notranslate nohighlight">\(q\)</span> is the largest possible when <span class="math notranslate nohighlight">\(F(\omega')\gg F(\omega_{old})\)</span> (of course for this <span class="math notranslate nohighlight">\(\beta\)</span>).</p>
<p>Consequently, SA can be seen as a <span style="color:#f88146"><strong>sampling process</strong> that converges to the global optimal <span class="math notranslate nohighlight">\(\omega^{\ast}\)</span> of <span class="math notranslate nohighlight">\(F(\omega)\)</span></span> if the annealing schedule is a proper one. However, what is the <strong>fomal role</strong> of the temperature (or its inverse: <span class="math notranslate nohighlight">\(\beta\)</span>)? Solving this question is a good excuse to dive into <strong>Information Theory</strong>, a mathematical discipline which is built on top of Probability and it is fundamental to undestanding intelligent search.</p>
</section>
<section id="gibbs-sampling">
<h3><span class="section-number">2.3.3. </span>Gibbs Sampling<a class="headerlink" href="#gibbs-sampling" title="Permalink to this heading">#</a></h3>
<p>SA shows that intelligent search can be seen as deploying random walks for exploring combinatorial spaces such as <span class="math notranslate nohighlight">\(\Pi_n\)</span>. For this section, we need a key probabilistic concept: the expectation of a random variable.</p>
<p>Remember that the <strong>expectation</strong> of a discrete random variable <span class="math notranslate nohighlight">\(\omega\)</span> is defined as follows:</p>
<div class="math notranslate nohighlight">
\[
E(X)=\sum_{\omega\in \Omega}\omega\cdot p(X=\omega)\;.
\]</div>
<p>Expectation gives us an idea of the <strong>spatial concentration</strong> of the values <span class="math notranslate nohighlight">\(\omega\in\Omega\)</span> attending to <span class="math notranslate nohighlight">\(p(X=\omega)\)</span>. Actually <span class="math notranslate nohighlight">\(E(X)\)</span> can be seen as <em>the most representative</em> of this values (i.e. the <em>most likely</em> of them).</p>
<p>For determining <span class="math notranslate nohighlight">\(E(X)\)</span> it is mandatory to know all the probabilities <span class="math notranslate nohighlight">\(p(X=\omega)\)</span>.</p>
<p>However, <span style="color:#f88146">what if <span class="math notranslate nohighlight">\(p(X=\omega)=G(X)\)</span>, i.e. if <span class="math notranslate nohighlight">\(X\)</span> is <strong>Gibbsian</strong>?</span>. This is the case of <span class="math notranslate nohighlight">\(X=F(\omega)\)</span>, the value of the cost function. In this latter case,</p>
<div class="math notranslate nohighlight">
\[
E(X) = \sum_{\omega\in \Omega}\omega\cdot G(X=\omega) = \sum_{\omega\in \Omega}\omega\cdot \frac{\exp\left(\beta\cdot F(\omega)\right)}{Z}\;,
\]</div>
<p>is the <strong>expected cost</strong>. Can we really calculate it? Well, it is impossible to do it analitically because:</p>
<ol class="arabic simple">
<li><p>We should know all the values <span class="math notranslate nohighlight">\(F(\omega)\)</span>. This is equivalent to solve the problem encoded by this cost function by means of <strong>brute force</strong>. Remember that for the QAP this implies to evaluate <strong>all the states of the Permutohedron</strong>, i.e. <span class="math notranslate nohighlight">\(n!\)</span> states whose individual evaluation takes <span class="math notranslate nohighlight">\(O(n^4)\)</span>.</p></li>
<li><p>The Gibbs distribution seems to be restricted to a given <span class="math notranslate nohighlight">\(\beta\)</span>. We should evaluate <span class="math notranslate nohighlight">\(Z=\sum_{\omega\in\Omega}G(\omega)\)</span>, a very large sum, for that particular <span class="math notranslate nohighlight">\(\beta\)</span>. Therefore, <span class="math notranslate nohighlight">\(E(X)\)</span> seems to be <span class="math notranslate nohighlight">\(\beta-\)</span>dependent as well.</p></li>
</ol>
<p>Instead, the Metropolis-Hastings algorithm allows us to <strong>approximate</strong> <span class="math notranslate nohighlight">\(E(X)\)</span> as follows:</p>
<div class="math notranslate nohighlight">
\[
E(X)\approx \frac{1}{R}\sum_{r=1}^{R}F(\omega_r)\;,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\omega_1,\omega_2,\ldots, \omega_r\)</span> are the states visited by the algorithm when it follows an <strong>admisible anneling schedule</strong> such as <span class="math notranslate nohighlight">\(T(t)=\frac{C}{\log(1+t)}\)</span> where <span class="math notranslate nohighlight">\(C\)</span> is a constant. This means that <span class="math notranslate nohighlight">\(\omega_r\)</span> is <strong>accepted</strong> at <span class="math notranslate nohighlight">\(T(r)\)</span>.</p>
<p>Some related considerations:</p>
<ol class="arabic simple">
<li><p>The sequence <span class="math notranslate nohighlight">\(\omega_1,\omega_2,\ldots,\)</span> is a <strong>random walk</strong> along <span class="math notranslate nohighlight">\(\Omega\)</span> which is driven by <span class="math notranslate nohighlight">\(F(\omega)\)</span> and converges to the Gibbs probability.</p></li>
<li><p>The lower the temperature <span class="math notranslate nohighlight">\(T(t)\)</span> the closer we become to the Gibbs distribution. Therefore <span style="color:#f88146">the computational temperature works as a <strong>Lagrange parameter</strong> to enforce the convergence</span> towards the Gibbs distribution.</p></li>
<li><p>Formally, not all the <strong>samples</strong> <span class="math notranslate nohighlight">\(\omega_1,\omega_2,\ldots,\omega_r\)</span> are generated by <span class="math notranslate nohighlight">\(G(\omega)\)</span> since every random walk has a <strong>transient period</strong> (unstable values) and we do not know exactly at what time instant we have the convergence, i.e. <span class="math notranslate nohighlight">\(\omega_t\)</span> become proper samples of <span class="math notranslate nohighlight">\(G(\omega)\)</span>.</p></li>
<li><p>Following <a class="reference external" href="https://eml.berkeley.edu/reprints/misc/understanding.pdf">Understanding Gibbs Sampling</a>, a good strategy is to start different random walks at different <span class="math notranslate nohighlight">\(X_0\)</span>s (initial permutations in QAP) and track the samples until we can observe some <strong>consensus</strong>.</p></li>
</ol>
<p>In <a class="reference internal" href="#sa-expectations"><span class="std std-numref">Fig. 2.17</span></a>, we show three random walks generated from different <span class="math notranslate nohighlight">\(X_0\)</span>s, for the admisible annealing (inverse log) with <span class="math notranslate nohighlight">\(C=3\)</span>. None of them reaches the global optimum in <span class="math notranslate nohighlight">\(R=7,000\)</span> iterations. Actually their approximate expectations <span class="math notranslate nohighlight">\(E(X)\)</span> are respectively <span class="math notranslate nohighlight">\(8.637\)</span>, <span class="math notranslate nohighlight">\(8.178\)</span> and
<span class="math notranslate nohighlight">\(9.371\)</span> if we remove the first <span class="math notranslate nohighlight">\(1,000\)</span> samples (considered as transient regime), whereas we have <span class="math notranslate nohighlight">\(9.051\)</span>, <span class="math notranslate nohighlight">\(8.466\)</span>, and <span class="math notranslate nohighlight">\(9.791\)</span> if all the samples are included.</p>
<p>What is interesting here is that <span style="color:#f88146"><strong>it is quite difficult to reach the global optimum</strong></span> since:</p>
<ol class="arabic simple">
<li><p>There are fewer states with that value in general and most of them are sub-optimal. This is indiated by the fact that <span class="math notranslate nohighlight">\(E(X)\ll \omega^{\ast}\)</span> for <span class="math notranslate nohighlight">\(X=F(\omega)\)</span>.</p></li>
<li><p>In combinatorial problems such as QAP, the cost function has a discrete number of <strong>energy levels</strong> and this usually leads to <strong>plateaus</strong> (regions of constast cost) as cooling progresses. For instance, in <a class="reference internal" href="#sa-expectations"><span class="std std-numref">Fig. 2.17</span></a> random search seems blocked in a sub-optimal state, at least for such number of iterations <span class="math notranslate nohighlight">\(R\)</span>.</p></li>
</ol>
<figure class="align-center" id="sa-expectations">
<a class="reference internal image-reference" href="_images/SA-Expectations-Photoroom.png"><img alt="_images/SA-Expectations-Photoroom.png" src="_images/SA-Expectations-Photoroom.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.17 </span><span class="caption-text">Three random walks along <span class="math notranslate nohighlight">\(\Pi_n\)</span> with differernt <span class="math notranslate nohighlight">\(X_0\)</span>s.</span><a class="headerlink" href="#sa-expectations" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Note also that herein we have highlighted the main features of SA. Please check the beautiful paper of the Geman’s brothers: Stochastic Relaxation, <a class="reference external" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=4767596">Gibss Distribution and the Bayesian Restoration of Images</a> one of the most influential papers in all times.</p>
</section>
<section id="limitations-of-sa">
<h3><span class="section-number">2.3.4. </span>Limitations of SA<a class="headerlink" href="#limitations-of-sa" title="Permalink to this heading">#</a></h3>
<p>SA is appealing for AI since it allows us to track the global optimum in a sort of random walk. However:</p>
<ol class="arabic simple">
<li><p>The quality or “intelligence” of the random walk relies on <span style="color:#f88146"><strong>how informative</strong></span> is the cost function. How is information measured? We will address this question later on.</p></li>
<li><p>The <span style="color:#f88146">global optimum is only guaranteed for a <strong>slow</strong> annealing</span> <span class="math notranslate nohighlight">\(T(t)=\frac{C}{\log(1+t)}\rightarrow 0\)</span>. SA has to be slow enough to not missing that global optimum; otherwise SA becomes greedy prematurely. This is an <strong>important limitation</strong> of SA: remember that for QAP we have to evaluate <span class="math notranslate nohighlight">\(F(\omega)\)</span> at each time <span class="math notranslate nohighlight">\(t\)</span> and it takes <span class="math notranslate nohighlight">\(O(n^4)\)</span>.</p></li>
</ol>
</section>
</section>
<section id="central-clustering">
<h2><span class="section-number">2.4. </span>Central Clustering<a class="headerlink" href="#central-clustering" title="Permalink to this heading">#</a></h2>
<p><strong>Deterministic Annealing</strong> (DA) emerges as a faster method than SA. In order to motivate this technique it is more convenient to visit another NP problem. This problem is <strong>central clustering</strong> (or <span style="color:#f88146"><strong><span class="math notranslate nohighlight">\(k-\)</span>centrer clustering</strong></span>) and it is formulated as follows:</p>
<p><em>Given a set <span class="math notranslate nohighlight">\({\cal X}=\{\mathbf{x}_1,\mathbf{x_2},\ldots,\mathbf{x}_m\}\subset \mathbb{R}^d\)</span> (<span class="math notranslate nohighlight">\(d-\)</span>dimensional points)  and an integer parameter <span class="math notranslate nohighlight">\(k&gt;1\)</span>, <em>find a set of <span class="math notranslate nohighlight">\(k\)</span> centers</em> <span class="math notranslate nohighlight">\({\cal C}=\{\mathbf{c}_1,\mathbf{c}_2,\ldots,\mathbf{c}_k\}\subset \mathbb{R}^d\)</span> such that so that the Euclidean distance <span class="math notranslate nohighlight">\(D(\mathbf{x},\mathbf{c})\)</span> of each point <span class="math notranslate nohighlight">\(\mathbf{x}_a\)</span> to its closest center <span class="math notranslate nohighlight">\(\mathbf{c}_i\)</span> is minimal.</em></p>
<section id="clusters-and-prototypes">
<h3><span class="section-number">2.4.1. </span>Clusters and Prototypes<a class="headerlink" href="#clusters-and-prototypes" title="Permalink to this heading">#</a></h3>
<p>A more intuitive formulation is as follows. Let</p>
<div class="math notranslate nohighlight">
\[
\text{cluster}(\mathbf{c}_i) = \{\mathbf{x}_a\in{\cal X}: D(\mathbf{x}_a,\mathbf{c}_i)\le D(\mathbf{x}_a,\mathbf{c}_j),j\neq i\}\;,
\]</div>
<p>be a <span style="color:#f88146"><strong>cluster</strong></span>, i.e. a subset of <span class="math notranslate nohighlight">\({\cal X}\)</span> where its elements <span class="math notranslate nohighlight">\(\mathbf{x}_a\)</span> are closer to the cluster’s <span style="color:#f88146"><strong>prototype</strong></span> <span class="math notranslate nohighlight">\(\mathbf{c}_i\)</span> than to any other. Then, the problem is also formulated as follows:</p>
<p><em>Partition <span class="math notranslate nohighlight">\({\cal X}\)</span> in <span class="math notranslate nohighlight">\(k\)</span> (disjoint) clusters such that the sum of distances between the points and the prototypes is minimal.</em></p>
<p>Some clarifications:</p>
<ol class="arabic simple">
<li><p>The problem is a <span style="color:#f88146"><strong>chicken-and-egg</strong></span> problem: a) We need to know the <span class="math notranslate nohighlight">\(k\)</span> centers <span class="math notranslate nohighlight">\(\mathbf{c}_i\)</span> beforehand in order to determine the clusters <span class="math notranslate nohighlight">\(\text{cluster}(\mathbf{c}_i)\)</span> but b) the prototypes have to be determined once the clusters are done according with the criterion of minimal distances.</p></li>
<li><p>The NP-hardness of the problem is given by the <span style="color:#f88146"><strong>partitioning flavor</strong></span>. Actually, the worst case complexity is <span class="math notranslate nohighlight">\(O(k^m)\)</span> since each of the <span class="math notranslate nohighlight">\(m\)</span> different points can be exclusively assigned to <span class="math notranslate nohighlight">\(k\)</span> centers (<strong>r-permutations with repetition</strong> <span class="math notranslate nohighlight">\(P_{\sigma}(m,k)=k^m)\)</span>.</p></li>
<li><p>The prototypes <span class="math notranslate nohighlight">\(\mathbf{c}_i\)</span> <span style="color:#f88146"><strong>do not necessarily belong to</strong></span> <span class="math notranslate nohighlight">\({\cal X}\)</span> and they must be discovered.</p></li>
</ol>
<p>See for instance a well defined problem in <a class="reference internal" href="#km-clusters"><span class="std std-numref">Fig. 2.18</span></a> where the red dots are ideal centers <span class="math notranslate nohighlight">\(\mathbf{c}_i\)</span> which are the expectations <span class="math notranslate nohighlight">\(\mu_i\)</span> of bidimensional Gaussians <span class="math notranslate nohighlight">\(N(\mu_i,\sigma\mathbf{I})\)</span> with <span class="math notranslate nohighlight">\(\sigma=0.5\)</span>.</p>
<figure class="align-center" id="km-clusters">
<a class="reference internal image-reference" href="_images/KM-clusters-Photoroom.png"><img alt="_images/KM-clusters-Photoroom.png" src="_images/KM-clusters-Photoroom.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.18 </span><span class="caption-text">Clusters and estimated prototypes in <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span>.</span><a class="headerlink" href="#km-clusters" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="cost-functions">
<h3><span class="section-number">2.4.2. </span>Cost Functions<a class="headerlink" href="#cost-functions" title="Permalink to this heading">#</a></h3>
<section id="attractors">
<h4><span class="section-number">2.4.2.1. </span>Attractors<a class="headerlink" href="#attractors" title="Permalink to this heading">#</a></h4>
<p>A first compact cost function could be:</p>
<div class="math notranslate nohighlight">
\[
F({\cal C}) = \sum_{a=1}^m\min_{1\le i\le k}D(\mathbf{x}_a,\mathbf{c}_i)\;. 
\]</div>
<p>where we are interested in <span class="math notranslate nohighlight">\({\cal C}^{\ast}\)</span>, the set <span class="math notranslate nohighlight">\(k\)</span> centers/prototypes  <span style="color:#f88146"><strong>minimizing the total distance</strong></span>.</p>
<p>In <a class="reference internal" href="#km-clusters"><span class="std std-numref">Fig. 2.18</span></a>, two centers <span class="math notranslate nohighlight">\(\mathbf{c}_1=[-1,-1]^T\)</span> and <span class="math notranslate nohighlight">\(\mathbf{c}_2=[1,-1]^T\)</span> and mutually closer than the third one <span class="math notranslate nohighlight">\(\mathbf{c}_3=[0,2]^T\)</span>. Then, if we represent the individual cost of each point <span class="math notranslate nohighlight">\(\mathbf{x}_a\)</span> wrt each center, i.e. <span class="math notranslate nohighlight">\(min_{1\le i\le k}D(\mathbf{x}_a,\mathbf{c}_i)\)</span> (see <a class="reference internal" href="#km-dist"><span class="std std-numref">Fig. 2.19</span></a>) note that there is well-defined minimum at <span class="math notranslate nohighlight">\(\mathbf{c}_1=[-1,-1]^T\)</span> which we interpret as an <span style="color:#f88146"><strong>attractor</strong> or <strong>meta-stable state</strong></span>, since it distorts the locations of the other two minima. Note also, that the cost function is clearly <strong>non convex</strong> and it has many <strong>saddle points</strong> (see for instance the 3D view in <a class="reference internal" href="#km-dist3d"><span class="std std-numref">Fig. 2.20</span></a>)</p>
<figure class="align-center" id="km-dist">
<a class="reference internal image-reference" href="_images/KM-dist-removebg-preview.png"><img alt="_images/KM-dist-removebg-preview.png" src="_images/KM-dist-removebg-preview.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.19 </span><span class="caption-text">Individual cost wrt closest centers.</span><a class="headerlink" href="#km-dist" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-center" id="km-dist3d">
<a class="reference internal image-reference" href="_images/KM-dist3D-removebg-preview.png"><img alt="_images/KM-dist3D-removebg-preview.png" src="_images/KM-dist3D-removebg-preview.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.20 </span><span class="caption-text">Individual cost wrt closest centers (3D view).</span><a class="headerlink" href="#km-dist3d" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>However, if we also include the point-to-cluster <span style="color:#f88146"><strong>assignment variables</strong></span> <span class="math notranslate nohighlight">\(\mathbf{M}_{ai}\)</span>, we aim to <strong>jointly</strong> minimize:</p>
<div class="math notranslate nohighlight">
\[
F({\cal C},\mathbf{M}) = \sum_{a=1}^m\mathbf{M}_{ai}D(\mathbf{x}_a,\mathbf{c}_i)\;,\text{s.t.}\;\sum_{i=1}^k\mathbf{M}_{ai}=1\;,\forall a\in \{1,\ldots,m\}\;,
\]</div>
<p>where each point can be only assigned to a single cluster and all points must be assigned (each row has a single <span class="math notranslate nohighlight">\(1\)</span>).</p>
</section>
<section id="independence">
<h4><span class="section-number">2.4.2.2. </span>Independence<a class="headerlink" href="#independence" title="Permalink to this heading">#</a></h4>
<p>Note that the Gibbs distribution for <span class="math notranslate nohighlight">\(F({\cal C},\mathbf{M})\)</span> is</p>
<div class="math notranslate nohighlight">
\[
G({\cal C},\mathbf{M})=\frac{\exp(-\beta F({\cal C},\mathbf{M}))}{Z}\;\;\text{with}\;\;\; Z=\sum_{{\cal C},\mathbf{M}}\exp(-\beta F({\cal C},\mathbf{M}))\;,
\]</div>
<p>where the negative exponential means that <span style="color:#f88146">the probability of a solution <strong>decays exponentially with the distances</strong></span> beween the points and the cluster centers or prototypes.</p>
<p>Instead of sampling <span class="math notranslate nohighlight">\(\Omega={\cal C}\times{\cal P}\)</span> with SA, where</p>
<div class="math notranslate nohighlight">
\[
{\cal P} =\left\{\mathbf{M}\in \{0,1\}^{m\times k}:\forall a\in\{1,\ldots,m\}:\sum_{i=1}^k\mathbf{M}_{ai}=1,\right\} 
\]</div>
<p>we are going to <span style="color:#f88146">assume that the variables <span class="math notranslate nohighlight">\({\cal C}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> are <strong>statitically indepedendent</strong></span>. Then, following the <strong>Appendix</strong>, we compute the <strong>marginal</strong> of the Gibbs distribution wrt the assignment matrices:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
G({\cal C})&amp;=\sum_{\mathbf{M}\in{\cal P}} G({\cal C},\mathbf{M})\\
           &amp;=\frac{1}{Z}\sum_{\mathbf{M}\in{\cal P}}\exp(-\beta F({\cal C},\mathbf{M}))\\
           &amp;=\frac{1}{Z}\sum_{\mathbf{M}\in{\cal P}}\exp\left(-\beta \sum_{a=1}^m\sum_{i=1}^k\mathbf{M}_{ai}D(\mathbf{x}_a,\mathbf{c}_i)\right)\\
           &amp;=\frac{1}{Z}\sum_{\mathbf{M}\in{\cal P}}Q(\mathbf{M})\;.
\end{align}
\end{split}\]</div>
<p>Now, looking at the sum of neg-exponentials, we observe that the sum is over the <span style="color:#f88146"><strong>legal assignment matrices</strong></span> <span class="math notranslate nohighlight">\(\mathbf{M}\in{\cal P}\)</span> (each point must be assigned to a unique prototype). This means that any <strong>legal</strong> matrix will be a collection of rows ratisfying:</p>
<div class="math notranslate nohighlight">
\[
\text{rows}(\mathbf{M})\in {\cal C}_k=\overbrace{\{\underbrace{(1,0,\ldots,0)}_{I_1:k\;\text{elements}},\underbrace{(0,1,\ldots,0)}_{I_2:k\;\text{elements}},\ldots,\underbrace{(0,0,\ldots,1)}_{I_k:k\;\text{elements}}\}}^{m\;\text{elements}}\;.
\]</div>
<p>This means that for each of the <span class="math notranslate nohighlight">\(m\)</span> rows of <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> we have <span class="math notranslate nohighlight">\(k\)</span> options for <span class="math notranslate nohighlight">\(m\)</span> positions, leading to <span class="math notranslate nohighlight">\(k^m\)</span> <strong>total legal matrices</strong>, i.e. terms in <span class="math notranslate nohighlight">\(\sum_{\mathbf{M}\in {\cal P}}Q(\mathbf{M})\)</span>. However, this number can be reduced if we perform a <span style="color:#f88146"><strong>second independence assumption</strong>: the assignmnet of a point to a cluster is independent to that of another point</span> (logically this is not true for nearby points but this simplifies the calculations).</p>
<p>This allows us to express the neg-exp sum as the following sum, implementing a logical <span class="math notranslate nohighlight">\(\lor\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\sum_{\mathbf{M}\in{\cal P}} Q(\mathbf{M})=\sum_{\text{rows}(\mathbf{M}^{(1)})}\sum_{\text{rows}(\mathbf{M}^{(2)})}\ldots\sum_{\text{rows}(\mathbf{M}^{(m)})}Q(\mathbf{M})
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{M}^{(1)},\mathbf{M}^{(2)},\ldots,\mathbf{M}^{(m)}\)</span> are the assignment matrices that can be chosen for any particular point <span class="math notranslate nohighlight">\(\mathbf{x}_1,\mathbf{x}_2,\ldots,\mathbf{x}_m\)</span>.</p>
<p>Since <strong>independence means factorization</strong> we have <span class="math notranslate nohighlight">\(\sum\sum\ldots\sum = \sum\cdot\sum\ldots\sum\)</span> as in multiple integration, i.e.:</p>
<div class="math notranslate nohighlight">
\[
Z = \sum_{\mathbf{M}\in{\cal P}} Q(\mathbf{M})=\prod_{a=1}^m\sum_{\text{rows}(\mathbf{M}^{(a)})}Q(\mathbf{M}^{(a)}) = \prod_{a=1}^m\sum_{\text{rows}(\mathbf{M}^{(a)})}\exp\left(-\beta\sum_{i=1}^k\mathbf{M}^{(a)}_{ai}D(\mathbf{x}_a,\mathbf{c}_i)\right)\;.
\]</div>
<p>where the product <span class="math notranslate nohighlight">\(\prod_{a=1}^m\)</span> absorbs the sums <span class="math notranslate nohighlight">\(\sum_{a=1}^m\)</span> inside each exponential.</p>
<p>Now <em>pay attention!</em> This the point where we use the fact that <span class="math notranslate nohighlight">\(\sum_{i=1}^k\mathbf{M}^{(a)}_{ai}=1,\forall a\)</span> (for each row!), i.e. only one cluster will be chosen. Actually, we have an XOR! This leads us to:</p>
<div class="math notranslate nohighlight">
\[
Z=\sum_{\mathbf{M}\in{\cal P}} Q(\mathbf{M})=\prod_{a=1}^m\sum_{\text{rows}(\mathbf{M}^{(a)})}Q(\mathbf{M}^{(a)}) = \prod_{a=1}^m\sum_{i=1}^k\exp\left(-\beta D(\mathbf{x}_a,\mathbf{c}_i)\right)\;.
\]</div>
<p><strong>Final result</strong>. Then, in order to capture the above factorization, the original cost function <span class="math notranslate nohighlight">\(F({\cal C},\mathbf{M})\)</span> must be transformed as follows</p>
<div class="math notranslate nohighlight">
\[
F_{\beta}({\cal C}) = -\frac{1}{\beta}\log Z = -\frac{1}{\beta}\sum_{a=1}^m \log\sum_{i=1}^k \exp\left(-\beta D(\mathbf{x}_a,\mathbf{c}_i)\right)\;.
\]</div>
<p>which can be computed in <span class="math notranslate nohighlight">\(O(nk)\)</span>. Actually, <span class="math notranslate nohighlight">\(F_{\beta} = -\frac{1}{\beta}\log Z\)</span> is usally called the <a class="reference external" href="https://en.wikipedia.org/wiki/Gibbs_free_energy#:~:text=In%20traditional%20use%2C%20the%20term,non%2Dpressure%2Dvolume%20work">Free Energy</a>.</p>
</section>
<section id="derivation">
<h4><span class="section-number">2.4.2.3. </span>Derivation<a class="headerlink" href="#derivation" title="Permalink to this heading">#</a></h4>
<p>The below DA algorithm for central clustering results from the <strong>minimization of the Free energy</strong> as follows:</p>
<p>Let us compute the derivative of</p>
<div class="math notranslate nohighlight">
\[
F_{\beta}({\cal C})=-\frac{1}{\beta}\sum_{a=1}^m \log\underbrace{\sum_{i=1}^k \exp\left(-\beta D(\mathbf{x}_a,\mathbf{c}_i)\right)}_{Q(\mathbf{x}_a)}
\]</div>
<p>wrt each center <span class="math notranslate nohighlight">\(\mathbf{c}_i\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\frac{\partial F_{\beta}}{\partial \mathbf{c}_i} &amp;= -\frac{1}{\beta} \sum_{a=1}^m\frac{\partial \log Q(\mathbf{x}_a)}{\partial \mathbf{c}_i}\\
&amp;= -\frac{1}{\beta}\sum_{a=1}^m\frac{1}{Q(\mathbf{x}_a)}\cdot \frac{\partial Q(\mathbf{x}_a)}{\partial \mathbf{c}_i}\\
&amp;= -\frac{1}{\beta}\sum_{a=1}^m\frac{1}{Q(\mathbf{x}_a)}\cdot \left(-e^{-\beta D(\mathbf{x}_a,\mathbf{c}_i)}\right)\cdot\frac{\partial D(\mathbf{x}_a,\mathbf{c}_i)}{\mathbf{c}_i}\;.\\
\end{align}
\end{split}\]</div>
<p>For <span class="math notranslate nohighlight">\(D(\mathbf{x}_a,\mathbf{c}_i)=||\mathbf{x}_a-\mathbf{c}_i||^2\)</span> we have:</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
\frac{\partial D(\mathbf{x}_a,\mathbf{c}_i)}{\mathbf{c}_i}=2(\mathbf{x}_a-\mathbf{c}_i)
\end{align}
\]</div>
<p>Then, plugging this derivative in the main formula, and expanding the <span class="math notranslate nohighlight">\(Q(\mathbf{x}_a)\)</span>, we obtain:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\frac{\partial F_{\beta}}{\partial \mathbf{c}_i} &amp;= -\frac{1}{\beta}\sum_{a=1}^m\frac{1}{Q(\mathbf{x}_a)}\cdot \left(-e^{-\beta D(\mathbf{x}_a,\mathbf{c}_i)}\right)\cdot 2(\mathbf{x}_a-\mathbf{c}_i)\\
&amp;= \frac{2}{\beta}\sum_{a=1}^m\frac{e^{-\beta D(\mathbf{x}_a,\mathbf{c}_i)}}{\sum_{i'=1}^k e^{-\beta D(\mathbf{x}_a,\mathbf{c}_{i'})}}\cdot (\mathbf{x}_a-\mathbf{c}_i)\;.
\end{align}
\end{split}\]</div>
<p>Note that</p>
<div class="math notranslate nohighlight">
\[
\langle \mathbf{M}_{ai} \rangle = \frac{e^{-\beta D(\mathbf{x}_a,\mathbf{c}_i)}}{\sum_{i'=1}^k e^{-\beta D(\mathbf{x}_a,\mathbf{c}_{i'})}}\;.
\]</div>
<p>Then,</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
\frac{\partial F_{\beta}}{\partial \mathbf{c}_i} &amp;= 
\frac{2}{\beta}\sum_{a=1}^m\langle \mathbf{M}_{ai} \rangle\cdot (\mathbf{x}_a-\mathbf{c}_i)\;.
\end{align}
\]</div>
<p>Since the optimum is obtained when the gradient is zero, we have:</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial F_{\beta}}{\partial \mathbf{c}_i} = \mathbf{0}\Rightarrow \sum_{a=1}^m\langle \mathbf{M}_{ai} \rangle\cdot (\mathbf{x}_a-\mathbf{c}_i)=\mathbf{0}\Rightarrow 
\mathbf{c}_i = \frac{1}{\sum_{a=1}^m\langle \mathbf{M}_{ai} \rangle}\sum_{a=1}^m\mathbf{x}_a\langle \mathbf{M}_{ai} \rangle\;.
\]</div>
<p>Therefore, the DA algorithm for central clustering is simply derived from the gradient of the free energy. Summarizing, DA consists in <span style="color:#f88146"><strong>performing gradient descent</strong> wrt to each inverse temperature <span class="math notranslate nohighlight">\(\beta\)</span></span>.</p>
</section>
</section>
<section id="deterministic-annealing">
<h3><span class="section-number">2.4.3. </span>Deterministic Annealing<a class="headerlink" href="#deterministic-annealing" title="Permalink to this heading">#</a></h3>
<p><a class="reference external" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=726788">Deterministic Annealing (DA)</a> is a search technique easily applicable to the central clustering problem (see more details in <a class="reference external" href="https://thesis.library.caltech.edu/2858/1/Rose_k_1991.pdf">Keneth Rose’s PhD Thesis</a>).</p>
<p>The basic idea of DA is that for each value of <span class="math notranslate nohighlight">\(\beta=\frac{1}{T}\)</span> we <span style="color:#f88146"><strong>interate two phases</strong></span> for minimizing
the free energy <span class="math notranslate nohighlight">\(F_{\beta}({\cal C})\)</span>:</p>
<ol class="arabic simple">
<li><p><strong>Expectation</strong>. For <ins>fixed centers</ins> <span class="math notranslate nohighlight">\(\mathbf{c}_i\)</span>, we estimate the <span style="color:#f88146"><strong>probability</strong></span> that any point <span class="math notranslate nohighlight">\(\mathbf{x}_a\)</span> “belongs” to each cluster (“membership”). We denote such probabilities as <span class="math notranslate nohighlight">\(\langle \mathbf{M}_{ai} \rangle\)</span> and they are given by:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\langle \mathbf{M}_{ai} \rangle = \frac{\exp(-\beta D(\mathbf{x}_a,\mathbf{c}_i))}{\sum_{i'=1}^k \exp(-\beta D(\mathbf{x}_a,\mathbf{c}_{i'}))}\;.
\]</div>
<ol class="arabic simple" start="2">
<li><p><strong>Update</strong>. For <ins>fixed probabilities</ins> <span class="math notranslate nohighlight">\(\langle \mathbf{M}_{ai} \rangle\)</span>, we update the <span style="color:#f88146"><strong>centers</strong></span>. If <span class="math notranslate nohighlight">\(D(\mathbf{x}_a,\mathbf{c}_i)=||\mathbf{x}_q-\mathbf{c}_i||^2\)</span> (squared Euclidean distance), then we have</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\mathbf{c}_i =  \frac{\sum_{a=1}^m \mathbf{x}_a \langle \mathbf{M}_{ai}\rangle}{\sum_{a=1}^m\langle \mathbf{M}_{ai}\rangle}\;,
\]</div>
<p>i.e. the new (“fuzzy”) centers are the expected centers according to the fixed probabilities or (“memberships”).</p>
<div class="proof algorithm admonition" id="DA-alg">
<p class="admonition-title"><span class="caption-number">Algorithm 2.2 </span> (Deterministic Annealing [Clustering])</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inputs</strong> Given a set of points <span class="math notranslate nohighlight">\({\cal X}=\{\mathbf{x}_1,\ldots,\mathbf{x}_m\}\)</span>, the free energy <span class="math notranslate nohighlight">\(F_{\beta}({\cal C})\)</span>, an annealing schedule <span class="math notranslate nohighlight">\(\beta =1/T(t)\)</span> and an inital state <span class="math notranslate nohighlight">\({\cal C}^0=(\mathbf{c}^0_1,\ldots,\mathbf{c}^0_k)\)</span><br />
<strong>Outputs</strong> <span class="math notranslate nohighlight">\({\cal C}^{\ast}=\arg\min_{{\cal C}\in\Omega} F_{\beta\rightarrow\infty}({\cal C})\)</span> and <span class="math notranslate nohighlight">\(\langle \mathbf{M}^{\ast}_{ai}\rangle\)</span></p>
<ol class="arabic">
<li><p>convegence = False</p></li>
<li><p><span class="math notranslate nohighlight">\(\langle \mathbf{M}^{old}_{ai}\rangle\leftarrow 1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(t\leftarrow 0\)</span></p></li>
<li><p><strong>while</strong> <span class="math notranslate nohighlight">\(\neg\)</span> convergence:</p>
<ol class="arabic">
<li><p><strong>for</strong> <span class="math notranslate nohighlight">\(\mathbf{x}_a\in {\cal X}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{c}_i\in {\cal C}\)</span>:</p>
<p><span class="math notranslate nohighlight">\(
\langle \mathbf{M}_{ai} \rangle = \frac{\exp(-\beta D(\mathbf{x}_a,\mathbf{c}_i))}{\sum_{i'=1}^k \exp(-\beta D(\mathbf{x}_a,\mathbf{c}_{i'}))}
\)</span></p>
</li>
<li><p><strong>for</strong> <span class="math notranslate nohighlight">\(\mathbf{c}_i\in {\cal C}\)</span>:</p>
<p><span class="math notranslate nohighlight">\(
\mathbf{c}_i =  \frac{\sum_{a=1}^m \mathbf{x}_a \langle \mathbf{M}_{ai}\rangle}{\sum_{a=1}^m\langle \mathbf{M}_{ai}\rangle}
\)</span></p>
</li>
<li><p><span class="math notranslate nohighlight">\(t\leftarrow t+1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(T(t)\leftarrow \frac{1}{\log(1 + t)}\)</span></p></li>
<li><p>convergence = <span class="math notranslate nohighlight">\((T(t)&lt;T_{min})\)</span> <strong>or</strong> <span class="math notranslate nohighlight">\((t&gt;t_{max})\)</span> <strong>or</strong> <span class="math notranslate nohighlight">\((\sum_{ai}|\langle \mathbf{M}_{ai}\rangle - \langle \mathbf{M}^{old}_{ai}\rangle|\le\epsilon )\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\langle \mathbf{M}^{old}_{ai}\rangle\leftarrow \langle \mathbf{M}_{ai}\rangle\)</span></p></li>
</ol>
</li>
<li><p><strong>return</strong> <span class="math notranslate nohighlight">\({\cal C}^{\ast}\)</span>, <span class="math notranslate nohighlight">\(\langle M^{\ast}\rangle\)</span></p></li>
</ol>
</section>
</div><p>Some considerations about the above algorithm:</p>
<ul class="simple">
<li><p>It is <strong>deterministic</strong>, i.e. we do not draw random numbers at any step of the algoorithm.</p></li>
<li><p>The <strong>initial (inverse) temperature</strong> <span class="math notranslate nohighlight">\(\beta=1/T_{max}\)</span>, where <span class="math notranslate nohighlight">\(T_{max}=T(0)\)</span>, is used as in SA, to make all the assignments almost equally probable: note that <span class="math notranslate nohighlight">\(e^{-\beta D(\mathbf{x}_a,\mathbf{c}_i)}\rightarrow 1\)</span>, if <span class="math notranslate nohighlight">\(\beta\rightarrow 0\)</span>. Under these conditions, we have <span class="math notranslate nohighlight">\(\langle M_{ai}\rangle\approx 1/k\)</span>.</p></li>
<li><p><strong>Initialization</strong>. <span class="math notranslate nohighlight">\(T_{max}\)</span> is set to the maximum variance <span class="math notranslate nohighlight">\(\sigma^2_{max}\)</span> of  the data. If the data is multidimensional, as it happens usually, <span class="math notranslate nohighlight">\(\sigma^2_{max}\)</span> has an spectral interpretation (PCA).</p></li>
<li><p>However, as the algorithm evolves, <span class="math notranslate nohighlight">\(\beta\)</span> increases and the <strong>exponential decay becomes more selective</strong>: given <span class="math notranslate nohighlight">\(D(\mathbf{x}_a,\mathbf{c}_i)\le D(\mathbf{x}_a,\mathbf{c}_j)+\alpha\)</span>, the second distance decays exponentially faster than the first as <span class="math notranslate nohighlight">\(\beta\)</span> increases.</p></li>
<li><p><strong>Alternating Expectation and Update</strong>. Given the probabilities <span class="math notranslate nohighlight">\(\langle M_{ai}\rangle\)</span> we update the centers <span class="math notranslate nohighlight">\(\mathbf{c}_i\)</span> and then we re-compute the probabilities until a “fixed point” (stable assignment/centers) is reached.</p></li>
<li><p><strong>Convervence</strong>. The algorithm converges to the nearest local optimum of the free energy to the initialization point <span class="math notranslate nohighlight">\({\cal C}^0\)</span>. We add the condition <span class="math notranslate nohighlight">\(\sum_{ai}|\langle \mathbf{M}_{ai}\rangle - \langle \mathbf{M}^{old}_{ai}\rangle|\le\epsilon\)</span> with <span class="math notranslate nohighlight">\(\epsilon&gt;0\)</span>, which means that the algorithm stops if the <span class="math notranslate nohighlight">\(\langle \mathbf{M}_{ai}\rangle\)</span> are stable enough. For instance, if we start by setting <span class="math notranslate nohighlight">\(\langle M_{ai}\rangle\approx 1/k\)</span>, the algorithm only performs a single iteration. Why? Because the centers in step 4.2. are not modified at all.</p></li>
<li><p><strong>Complexity</strong>. Each iteration takes <span class="math notranslate nohighlight">\(O(mk)\)</span> and the number of iterations can be accelerated by a faster annealing schedule.</p></li>
<li><p><strong>Outputs</strong>. The algorithm returns the best centers <span class="math notranslate nohighlight">\({\cal C}^{\ast}\)</span> and the optimal assignments <span class="math notranslate nohighlight">\(\langle \mathbf{M}_{ai}^{\ast}\rangle\)</span> where a point <span class="math notranslate nohighlight">\(\mathbf{x}_a\)</span> is assigned to the cluster centered at <span class="math notranslate nohighlight">\(\mathbf{c}_{i'}\)</span> if:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
i' = \arg\max_{1\le i\le k}\langle \mathbf{M}_{ai}^{\ast}\rangle\;.
\]</div>
<p>We show how the algorithm works in one-dimensional points in the following exercise:
<br></br>
<span style="color:#d94f0b">
<strong>Exercise</strong>. Given the following points <span class="math notranslate nohighlight">\({\cal X}=\{1,2,3,7,7.5,8.25\}\)</span> in <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>, cluster them with <span class="math notranslate nohighlight">\(k=2\)</span>, starting from a unique cluster. Use the following inverse-temperature scheduling: <span class="math notranslate nohighlight">\(\beta(t+1)=\beta(t)\beta_r\)</span>, with <span class="math notranslate nohighlight">\(\beta_r = 1.075\)</span>.
<br><br>
Answer. We have then a <span class="math notranslate nohighlight">\((m=6,k=2)\)</span> instance of central clustering. Firstly, we analize the data. The mean and standard deviation of the data are respectively <span class="math notranslate nohighlight">\(\mu=4.79\)</span> and <span class="math notranslate nohighlight">\(\sigma=2.87\)</span>. We may use the mean to encode the unique center, for instance: <span class="math notranslate nohighlight">\(c^0_1=c^0_2=\mu\)</span>. However, this would result in terminating the algorithm in a single iteration with <span class="math notranslate nohighlight">\(\langle \mathbf{M}_{ai}\rangle = 0.5,\forall a,i\)</span>.
<br></br>
A simple way to avoid the <span class="math notranslate nohighlight">\(50/50\)</span> setting is to make <span class="math notranslate nohighlight">\(c^0_1=\mu + 0.01,\;\; c^0_2=\mu\)</span>. Then the initial centers are <span class="math notranslate nohighlight">\(c_1^0 = \mathbf{4.801}\)</span> and <span class="math notranslate nohighlight">\(c_2^0 = \mathbf{4.791}\)</span>.
<br></br>
Regarding <span class="math notranslate nohighlight">\(\beta(0)=1/T_{max}\)</span> we make <span class="math notranslate nohighlight">\(T_{max}=\sigma\)</span> which results in <span class="math notranslate nohighlight">\(\beta(0)=1/2.87=0.34\)</span>.
</span>
<br></br>
<span style="color:#d94f0b">
<ins>Iteration 1</ins>. At each iteration we recompute the (transposed) <strong>squared distances</strong> matrix <span class="math notranslate nohighlight">\(\mathbf{D}\)</span> where <span class="math notranslate nohighlight">\(\mathbf{D}_{ia}=(c_i-x_a)^2\)</span> with <span class="math notranslate nohighlight">\(a\in\{1,\ldots,6\}\)</span> and <span class="math notranslate nohighlight">\(i\in\{1,2\}\)</span>. We transpose it to better visualize how far is each center from each data point. Better seen in tabular form:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|ccc}
  \mathbf{D}^{(1)} &amp; x_1     &amp; x_2    &amp; x_3    &amp; x_4   &amp; x_5   &amp; x_6\\
  \hline
  c_1        &amp; 14.452  &amp; 7.849  &amp;  3.246 &amp; 4.832 &amp; 7.281 &amp; 11.891 \\
  c_2        &amp; 14.376  &amp; 7.793  &amp;  3.210 &amp; 4.876 &amp; 7.335 &amp; 11.960 \\  
  \hline
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Then we calculate the (transposed) neg-exponentials and the sum of each column for later normalization:
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|cccccc}
  \exp(-\beta(0)\mathbf{D}^{(1)}) &amp; x_1     &amp; x_2    &amp; x_3    &amp; x_4   &amp; x_5   &amp; x_6\\
  \hline
  c_1        &amp; 0.007  &amp; 0.069 &amp; 0.331 &amp; 0.193 &amp; 0.084 &amp; 0.017 \\
  c_2        &amp; 0.007  &amp; 0.070 &amp; 0.335 &amp; 0.190 &amp; 0.082 &amp; 0.017 \\  
  \hline
  \sum       &amp; 0.014  &amp; 0.139 &amp; 0.666 &amp; 0.383 &amp; 0.166 &amp; 0.034 \\
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Then we proceed to normalize the columns, and also sum the resuling rows for preparing the computation of the new centers:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|cccccc|c}
 \langle \mathbf{M}^{(1)}\rangle  &amp; x_1     &amp; x_2    &amp; x_3    &amp; x_4   &amp; x_5   &amp; x_6 &amp;\sum_{a=1}^m  \langle \mathbf{M}^{(1)}_{ai}\rangle\\
  \hline
  c_1        &amp; 0.493  &amp; 0.495 &amp; 0.496 &amp; 0.503 &amp; 0.504 &amp; 0.505 &amp;  2.996 \\
  c_2        &amp; 0.506  &amp; 0.504 &amp; 0.503 &amp; 0.496 &amp; 0.495 &amp; 0.494 &amp;  2.998 \\  
  \hline
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Then the new centers become:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
\mathbf{c}_1^{(1)} &amp;= \frac{1}{2.996}\left(\mathbf{1}\cdot 0.493 + \mathbf{2}\cdot 0.495 + \ldots + \mathbf{8.25}\cdot 0.505\right) = \mathbf{4.819}\\
\mathbf{c}_2^{(1)} &amp;= \frac{1}{2.998}\left(\mathbf{1}\cdot 0.506 + \mathbf{2}\cdot 0.504 + \ldots + \mathbf{8.25}\cdot 0.494\right) = \mathbf{4.763}
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
where the first center <span class="math notranslate nohighlight">\(c_1\)</span> starts to attract the largest values of <span class="math notranslate nohighlight">\({\cal X}\)</span> and <span class="math notranslate nohighlight">\(c_2\)</span> attracts the lowest ones.
</span>
<br></br>
<span style="color:#d94f0b">
<ins>Iteration 2</ins>. Given the new centers, we recompute their distances wrt  all the points in <span class="math notranslate nohighlight">\({\cal X}\)</span>. The new (transposed) distance is:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|cccccc}
  \mathbf{D}^{(2)} &amp; x_1     &amp; x_2    &amp; x_3    &amp; x_4   &amp; x_5   &amp; x_6\\
  \hline
  c_1        &amp; 14.590  &amp; 7.950  &amp; 3.311  &amp; 4.753  &amp; 7.183  &amp; 11.766 \\
  c_2        &amp; 14.164  &amp; 7.637  &amp; 3.110  &amp; 5.001  &amp; 7.487  &amp; 12.155 \\  
  \hline
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Then, the normalized neg-exponetials for <span class="math notranslate nohighlight">\(\beta(2)=0.365\)</span> are:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|cccccc|c}
 \langle \mathbf{M}^{(2)}\rangle  &amp; x_1     &amp; x_2    &amp; x_3    &amp; x_4   &amp; x_5   &amp; x_6 &amp;\sum_{a=1}^m  \langle \mathbf{M}^{(2)}_{ai}\rangle\\
  \hline
  c_1        &amp; 0.461 &amp; 0.471 &amp; 0.481 &amp; 0.522 &amp; 0.527 &amp; 0.535 &amp;  2.997 \\
  c_2        &amp; 0.538 &amp; 0.528 &amp; 0.518 &amp; 0.477 &amp; 0.472 &amp; 0.464 &amp;  2.997 \\  
  \hline
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Then the new centers become:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
\mathbf{c}_1^{(2)} &amp;= \frac{1}{2.997}\left(\mathbf{1}\cdot 0.461 + \mathbf{2}\cdot 0.471 + \ldots + \mathbf{8.25}\cdot 0.535\right) = \mathbf{4.960}\\
\mathbf{c}_2^{(2)} &amp;= \frac{1}{2.997}\left(\mathbf{1}\cdot 0.538 + \mathbf{2}\cdot 0.528 + \ldots + \mathbf{8.25}\cdot 0.464\right) = \mathbf{4.622}
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<ins>Iteration 3</ins>. This is the <strong>most informative iteration</strong> so far because the two centers are clearly separated. They define what we later call a <strong>phase change</strong>. The distances give a hint of this:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|cccccc}
  \mathbf{D}^{(3)} &amp; x_1     &amp; x_2    &amp; x_3    &amp; x_4   &amp; x_5   &amp; x_6\\
  \hline
  c_1        &amp; 15.689  &amp; 8.767  &amp; 3.845  &amp; 4.157  &amp; \mathbf{6.446}  &amp;  10.817\\
  c_2        &amp; 13.121  &amp; \mathbf{6.876}  &amp; 2.632  &amp; 5.653  &amp; 8.280  &amp;  13.159\\  
  \hline
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
where the largest values are attracted by <span class="math notranslate nohighlight">\(c_2\)</span> and the smallest ones by <span class="math notranslate nohighlight">\(c_2\)</span> (see for instances the data in bold).
Then, the normalized neg-exponetials for <span class="math notranslate nohighlight">\(\beta(3)=0.392\)</span> are:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|cccccc|c}
 \langle \mathbf{M}^{(3)}\rangle  &amp; x_1     &amp; x_2    &amp; x_3    &amp; x_4   &amp; x_5   &amp; x_6 &amp;\sum_{a=1}^m  \langle \mathbf{M}^{(3)}_{ai}\rangle\\
  \hline
  c_1        &amp; 0.267 &amp; 0.322 &amp; 0.383 &amp; 0.642 &amp; \mathbf{0.672} &amp; 0.715 &amp;  3.001 \\
  c_2        &amp; 0.732 &amp; \mathbf{0.677} &amp; 0.616 &amp; 0.357 &amp; 0.327 &amp; 0.284 &amp;  2.993 \\  
  \hline
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
and then the new centers more “polarized”:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
\mathbf{c}_1^{(3)} &amp;= \frac{1}{3.001}\left(\mathbf{1}\cdot 0.267 + \mathbf{2}\cdot 0.322 + \ldots + \mathbf{8.25}\cdot 0.715\right) = \mathbf{5.828}\\
\mathbf{c}_2^{(3)} &amp;= \frac{1}{2.993}\left(\mathbf{1}\cdot 0.732 + \mathbf{2}\cdot 0.677 + \ldots + \mathbf{8.25}\cdot 0.284\right) = \mathbf{3.752}
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<ins>Iterations 4 and 5</ins>. In these iterations, “intra-cluster” distances in bold) get small and stabilized<br />
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|cccccc}
  \mathbf{D}^{(4)} &amp; x_1     &amp; x_2    &amp; x_3    &amp; x_4   &amp; x_5   &amp; x_6\\
  \hline
  c_1        &amp; 23.317  &amp; 14.659  &amp; 8.002  &amp; \mathbf{1.371}   &amp; \mathbf{2.792}  &amp;  \mathbf{5.862} \\
  c_2        &amp; \mathbf{7.575}   &amp; \mathbf{3.070}   &amp; \mathbf{0.565}  &amp; 10.547  &amp; 14.045  &amp; 20.229\\  
  \hline
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|cccccc}
  \mathbf{D}^{(5)} &amp; x_1     &amp; x_2    &amp; x_3    &amp; x_4   &amp; x_5   &amp; x_6\\
  \hline
  c_1        &amp; 42.347  &amp; 30.332  &amp; 20.317  &amp; \mathbf{0.257}   &amp; \mathbf{0.000}  &amp;  \mathbf{0.551} \\
  c_2        &amp; \mathbf{1.0841}  &amp; \mathbf{0.001}   &amp; \mathbf{0.919}   &amp; 24.589   &amp; 29.798  &amp; 38.548  \\  
  \hline
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
and the centers are respectively
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
c_1^{(4)}&amp;=7.507,\; c_2^{(4)}=2.041\\
c_1^{(5)}&amp;=7.583,\; c_2^{(5)}=1.999\\
\end{align}
\)</span>
<span>
<br></br>
<span style="color:#d94f0b">
<ins>Last iteration</ins>. Interestingly, at the end of iteration 5 we have the following assignment matrix:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|cccccc|c}
 \langle \mathbf{M}^{(5)}\rangle  &amp; x_1     &amp; x_2    &amp; x_3    &amp; x_4   &amp; x_5   &amp; x_6 &amp;\sum_{a=1}^m  \langle \mathbf{M}^{(5)}_{ai}\rangle\\
  \hline
  c_1        &amp; 0.000 &amp; 0.000 &amp; 0.000 &amp; 0.999 &amp; 0.999 &amp; 0.999 &amp; 2.997  \\
  c_2        &amp; 0.999 &amp; 0.999 &amp; 0.999 &amp; 0.000 &amp; 0.000 &amp; 0.000 &amp; 2.997  \\  
  \hline
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Note that the first 3 points belong to cluster 2 and the second 3 points belong to cluster 1. Is this enough to converge? Let us see. First of all we recompute the distances:
</span>
<br></br>
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|cccccc}
  \mathbf{D}^{(6)} &amp; x_1     &amp; x_2    &amp; x_3    &amp; x_4   &amp; x_5   &amp; x_6\\
  \hline
  c_1        &amp; 43.337  &amp; 31.171  &amp; 21.004  &amp; 0.340    &amp;  0.006   &amp;  0.444 \\
  c_2        &amp; 0.999   &amp; 0.000   &amp; 1.000   &amp; 25.000   &amp;  30.250  &amp;  39.062 \\  
  \hline
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Then, the normalized neg-exponentials for <span class="math notranslate nohighlight">\(\beta(6)=0.488\)</span> are:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|cccccc|c}
 \langle \mathbf{M}^{(6)}\rangle  &amp; x_1     &amp; x_2    &amp; x_3    &amp; x_4   &amp; x_5   &amp; x_6 &amp;\sum_{a=1}^m  \langle \mathbf{M}^{(3)}_{ai}\rangle\\
  \hline
  c_1        &amp; 0.000 &amp; 0.000 &amp; 0.000 &amp; 0.999 &amp; 0.999  &amp; 0.999  &amp; 2.997   \\
  c_2        &amp; 0.999 &amp; 0.999 &amp; 0.999 &amp; 0.000 &amp; 0.000  &amp;  0.000 &amp; 2.997   \\  
  \hline
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Which is clearly “stabilized” wrt <span class="math notranslate nohighlight">\(\langle \mathbf{M}^{(5)}\rangle\)</span> (it is identical). As a result, <strong>the cluster centers will be identical</strong> and the algorithm <strong>converges</strong> returning these cluster centers <span class="math notranslate nohighlight">\(c_1^{(6)}=c_1^{(5)}\)</span>, <span class="math notranslate nohighlight">\(c_2^{(6)}=c_2^{(5)}\)</span> and <span class="math notranslate nohighlight">\(\langle \mathbf{M}^{\ast}\rangle=\langle \mathbf{M}^{(6)}\rangle\)</span>.
</span>
<br></br></p>
<section id="entropy-and-free-energy">
<h4><span class="section-number">2.4.3.1. </span>Entropy and Free Energy<a class="headerlink" href="#entropy-and-free-energy" title="Permalink to this heading">#</a></h4>
<p>Deterministic Annealing (DA) relies on the following <strong>theorem</strong>:</p>
<p><em>Minimizing the Free Energy <span class="math notranslate nohighlight">\(F(\omega)=-\frac{1}{\beta}\log Z\)</span> is equivalent to maximizing the Entropy <span class="math notranslate nohighlight">\(H(G)\)</span> of the Gibbs distribution <span class="math notranslate nohighlight">\(G(\omega)=\exp(-\beta{\cal E}(\omega))/Z\)</span>, where <span class="math notranslate nohighlight">\({\cal E}(\omega)\)</span> is a cost (energy) function, as follows:</em></p>
<div class="math notranslate nohighlight">
\[
F(\omega) = \langle {\cal E}(\omega) \rangle - \frac{1}{\beta}H(G)\;.  
\]</div>
<p><strong>Proof</strong>. We start by expanding the definition of entropy (see the <strong>Appendix</strong>):</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
H(G) &amp;:=-\sum_{\omega}G(\omega)\log G(\omega)\\
     &amp;= -\sum_{\omega}\frac{\exp(-\beta{\cal E}(\omega))}{Z}\log \frac{\exp(-\beta{\cal E}(\omega))}{Z}\\
     &amp;= -\sum_{\omega}\frac{\exp(-\beta{\cal E}(\omega))}{Z}\left[-\beta {\cal E}(\omega) - \log Z\right]\\
     &amp;= -\sum_{\omega}G(\omega)\left[-\beta {\cal E}(\omega) - \log Z\right]\;.\\
\end{align}
\end{split}\]</div>
<p>Since, <span class="math notranslate nohighlight">\(\langle {\cal E}(\omega) \rangle\)</span> is the expectation</p>
<div class="math notranslate nohighlight">
\[
\langle {\cal E}(\omega) \rangle = \sum_{\omega}G(\omega){\cal E}(\omega)\;,
\]</div>
<p>we have</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
H(G) &amp;= -\sum_{\omega}G(\omega)\left[-\beta {\cal E}(\omega) - \log Z\right]\\
     &amp;= \beta\langle {\cal E}(\omega) \rangle + \sum_{\omega}G(\omega)\log Z\;.\\
\end{align}
\end{split}\]</div>
<p>Since <span class="math notranslate nohighlight">\(G(\omega)\)</span> is a probability distribution, we have <span class="math notranslate nohighlight">\(\sum_{\omega}G(\omega)=1\)</span> and therefore</p>
<div class="math notranslate nohighlight">
\[
H(G) = \beta\langle {\cal E}(\omega) \rangle + \log Z\;,
\]</div>
<p>and finally,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
-\log Z &amp;= \beta\langle {\cal E}(\omega) \rangle - H(G)\\
-\frac{1}{\beta}\log Z &amp;= \langle {\cal E}(\omega) \rangle -\frac{1}{\beta}H(G)\\
F(\omega) &amp;= \langle {\cal E}(\omega)\rangle -\frac{1}{\beta}H(G)\;.\\
\end{align}
\end{split}\]</div>
<p>Consequently, since <span class="math notranslate nohighlight">\(H(G)\ge 0\)</span>, we have that minimizing <span class="math notranslate nohighlight">\(F(\omega)\)</span> implies minimizing  <span class="math notranslate nohighlight">\(\langle {\cal E}(\omega)\rangle\)</span> (known as <span style="color:#f88146"><strong>average cost</strong></span> or <span style="color:#f88146"><strong>average distortion</strong></span>) as well as maximizing (i.e. -minimizing) the entropy <span class="math notranslate nohighlight">\(H(G)\)</span> if the average cost is kept constant.</p>
</section>
<section id="maximum-entropy">
<h4><span class="section-number">2.4.3.2. </span>Maximum Entropy<a class="headerlink" href="#maximum-entropy" title="Permalink to this heading">#</a></h4>
<p>The expansion of Free energy <span class="math notranslate nohighlight">\(F(\omega)\)</span> as</p>
<div class="math notranslate nohighlight">
\[
F(\omega) = \langle {\cal E}(\omega) \rangle - \frac{1}{\beta}H(G)\;.  
\]</div>
<p>suggests how it is minimized:</p>
<ol class="arabic simple">
<li><p>In the beginning, where we have <span class="math notranslate nohighlight">\(T_{max}\)</span> and <span class="math notranslate nohighlight">\(\beta\rightarrow 0\)</span>, we have that the dominant term is the negative of entropy <span class="math notranslate nohighlight">\(-H(G)\)</span>. This means that in the early stages of the algorithm, <strong>entropy is maximized</strong>.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Principle_of_maximum_entropy">Maximum Entropy</a> is a fundamental principle in Information Theory. It states that: <em><span style="color:#f88146">of all the probability distributions that satisfy a given set of constraints, choose the one that maximizes the entropy</em></span>.</p></li>
<li><p>Membership probabilities, <span class="math notranslate nohighlight">\(\langle\mathbf{M}_{ai}\rangle\)</span> can be interpreted as <strong>conditional probabilities</strong></p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\langle\mathbf{M}_{ai}\rangle = p(\mathbf{x}_a\in \text{cluster}(\mathbf{c}_i))=p(C=
i|X=a)\;,
\]</div>
<p>i.e., given a point <span class="math notranslate nohighlight">\(\mathbf{x}_a\)</span>, <span class="math notranslate nohighlight">\(p(C=
i|X=a)\)</span> denotes <span style="color:#f88146"><em>how likely is <span class="math notranslate nohighlight">\(\mathbf{c}_i\)</span> to be the true center for this point</em></span>. This is usually called <span style="color:#f88146"><strong>likelihood</strong></span>: how good is this center for be a <span style="color:#f88146"><strong>codeword</strong></span> of that point.</p>
<ol class="arabic simple" start="4">
<li><p>As a result, the <strong>conditional entropy</strong> <span class="math notranslate nohighlight">\(H(C|X)\)</span> is maximized in the early stages of DA:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
H(C|X)&amp;= \sum_{\mathbf{x}_a}p(X=a)H(C|X=a)\\
      &amp;\approx \frac{1}{m}\sum_{\mathbf{x}_a}H(C|X=a)\\
      &amp;= -\frac{1}{m}\sum_{\mathbf{x}_a}\sum_{\mathbf{c}_i}p(C=i|X=a)\log p(C=i|X=a)\\
      &amp;= -\frac{1}{m}\sum_{a}\sum_{i}\langle\mathbf{M}_{ai}\rangle\log \langle\mathbf{M}_{ai}\rangle\\
\end{align}
\end{split}\]</div>
<p>However, should be interesting to compute also the conditional entropy <span class="math notranslate nohighlight">\(H(X|C)\)</span> so that we can visualize the <strong>entropy per cluster</strong> instead of the <strong>entropy per point</strong> as in <span class="math notranslate nohighlight">\(H(C|X)\)</span>. To this end, look at the Bayes theorem:</p>
<div class="math notranslate nohighlight">
\[
p(X|C)=\frac{p(C|X)p(X)}{p(C)}\;.
\]</div>
<p>We assume <span class="math notranslate nohighlight">\(p(X=a)=\frac{1}{m}\)</span> since we don’t know how probable is a specific data in advance. But, how to estimate <span class="math notranslate nohighlight">\(p(C)\)</span> we exploit the following property:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
p(C=i) &amp;= \sum_{\mathbf{x}_a}p(X=a)p(C=i|X=a)\\ 
       &amp;= \frac{1}{m}\sum_{\mathbf{x}_a}p(C=i|X=a)\\
       &amp;= \frac{1}{m}\sum_{a}\langle\mathbf{M}_{ai}\rangle\\
\end{align}
\end{split}\]</div>
<p>Then, we have that</p>
<div class="math notranslate nohighlight">
\[
p(X=a|C=i)=\frac{\frac{1}{m}\langle\mathbf{M}_{ai}\rangle}{\frac{1}{m}\sum_{a}\langle\mathbf{M}_{ai}\rangle} = \frac{\langle\mathbf{M}_{ai}\rangle}{\sum_{a}\langle\mathbf{M}_{ai}\rangle}
\]</div>
<p>And finally</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
H(X|C) &amp;= \sum_{\mathbf{c}_i}p(C=i)H(X|C=i)\\
       &amp;\approx \frac{1}{m}\sum_{\mathbf{c}_i}\sum_{a}\langle\mathbf{M}_{ai}\rangle H(X|C=i)\;,\\
\end{align}
\end{split}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}
H(X|C=i) &amp;= -\sum_{\mathbf{x}_a}p(X=a|C=i)\log p(X=a|C=i)\\
         &amp;= -\sum_{a}\frac{\langle\mathbf{M}_{ai}\rangle}{\sum_{a}\langle\mathbf{M}_{ai}\rangle}\log \frac{\langle\mathbf{M}_{ai}\rangle}{\sum_{a}\langle\mathbf{M}_{ai}\rangle}\;.
\end{split}\]</div>
<p>is the <span style="color:#f88146"><strong>entropy per cluster</strong> <span class="math notranslate nohighlight">\(i\)</span></span> and it is a good quantity to analyze the <strong>convergence of the algorithm</strong>.</p>
<p>Look, for instance, at <a class="reference internal" href="#km-entropy-example"><span class="std std-numref">Fig. 2.21</span></a> for the solutions of the above exercise where <span class="math notranslate nohighlight">\(\langle M_{ai}\rangle\)</span> behave like Bernouilli variables when we have two clusters. At the last iteration, the <strong>maximal entropy per cluster</strong> is lower than the initial one: it is around <span class="math notranslate nohighlight">\(1\)</span> bit (i.e. <span class="math notranslate nohighlight">\(\log 3=1.09\)</span> nats) because half of the points belong to each cluster and half of them do not. This <strong>indicates good convergence</strong></p>
<figure class="align-center" id="km-entropy-example">
<a class="reference internal image-reference" href="_images/KM-entropy-example-removebg-preview.png"><img alt="_images/KM-entropy-example-removebg-preview.png" src="_images/KM-entropy-example-removebg-preview.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.21 </span><span class="caption-text">DA as entropy minimization in the exercise example.</span><a class="headerlink" href="#km-entropy-example" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>However, as we show in <a class="reference internal" href="#km-entropy-example-k3"><span class="std std-numref">Fig. 2.22</span></a> in the motivating example for <span class="math notranslate nohighlight">\(k=3\)</span> clusters, the final <strong>maximal entropy per cluster</strong> is around <span class="math notranslate nohighlight">\(4-5\)</span> bits (i.e. <span class="math notranslate nohighlight">\(\log 102 = 4.62\)</span> nats). This indicates that the data is <span style="color:#f88146"><strong>not well quantized</strong></span> with <span class="math notranslate nohighlight">\(k=3\)</span> centers.</p>
<figure class="align-center" id="km-entropy-example-k3">
<a class="reference internal image-reference" href="_images/KM-entropy-example-K3-removebg-preview.png"><img alt="_images/KM-entropy-example-K3-removebg-preview.png" src="_images/KM-entropy-example-K3-removebg-preview.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.22 </span><span class="caption-text">DA as entropy minimization the motivating example (K=3).</span><a class="headerlink" href="#km-entropy-example-k3" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>However, as we show in <a class="reference internal" href="#km-entropy-example-k2"><span class="std std-numref">Fig. 2.23</span></a> in the motivating example for <span class="math notranslate nohighlight">\(k=3\)</span> clusters, the final <strong>maximal entropy per cluster</strong> is around <span class="math notranslate nohighlight">\(5\)</span> bits (i.e. <span class="math notranslate nohighlight">\(\log 201 = 5.30\)</span> nats). This indicates that the data is <span style="color:#f88146"><strong>better quantized</strong></span> with <span class="math notranslate nohighlight">\(k=2\)</span> centers: <span style="color:#f88146">we get (nearly) the same entropy with less centers!</span></p>
<figure class="align-center" id="km-entropy-example-k2">
<a class="reference internal image-reference" href="_images/KM-entropy-example-K2-removebg-preview.png"><img alt="_images/KM-entropy-example-K2-removebg-preview.png" src="_images/KM-entropy-example-K2-removebg-preview.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.23 </span><span class="caption-text">DA as entropy minimization the motivating example (K=2).</span><a class="headerlink" href="#km-entropy-example-k2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Actually, the new centers are <span class="math notranslate nohighlight">\(\mathbf{c}_1=[0,-1]^T\)</span> and <span class="math notranslate nohighlight">\(\mathbf{c}_2=[0,2]^T\)</span> (see <a class="reference internal" href="#km-clusters-k2"><span class="std std-numref">Fig. 2.24</span></a>).</p>
<figure class="align-center" id="km-clusters-k2">
<a class="reference internal image-reference" href="_images/KM-clusters-K2-removebg-preview.png"><img alt="_images/KM-clusters-K2-removebg-preview.png" src="_images/KM-clusters-K2-removebg-preview.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.24 </span><span class="caption-text">Clusters and estimated prototypes in <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span> (K=2).</span><a class="headerlink" href="#km-clusters-k2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>As a result, <span style="color:#f88146"><strong>entropy is crucial</strong> for the interpretation of clustering problems!</span></p>
</section>
</section>
</section>
<section id="softmax-for-graph-matching">
<h2><span class="section-number">2.5. </span>SoftMax for Graph Matching<a class="headerlink" href="#softmax-for-graph-matching" title="Permalink to this heading">#</a></h2>
<section id="softmaxing">
<h3><span class="section-number">2.5.1. </span>SoftMaxing<a class="headerlink" href="#softmaxing" title="Permalink to this heading">#</a></h3>
<section id="continuation-methods">
<h4><span class="section-number">2.5.1.1. </span>Continuation Methods<a class="headerlink" href="#continuation-methods" title="Permalink to this heading">#</a></h4>
<p>Back to the graph matching problem or MCS (Maximum Common Subgraph), we have formulated it in
<span style="color:#f88146"><strong>discrete terms</strong> via SA</span>:</p>
<ol class="arabic simple">
<li><p>The search space <span class="math notranslate nohighlight">\({\cal P}\)</span> is the set of <strong>binary matrices</strong>
<span class="math notranslate nohighlight">\(\mathbf{M}\in\{0,1\}^{m\times n}\)</span> whose rows and columns have a unique <span class="math notranslate nohighlight">\(1\)</span>. When <span class="math notranslate nohighlight">\(m=n\)</span> we have that the search space is
the Permuthoedron <span class="math notranslate nohighlight">\(\Pi_n\)</span>, i.e. the set of <strong>permutation matrices</strong>.</p></li>
<li><p>SA explores the search space via <strong>random walks</strong> that eventually hit the <strong>global maximum</strong>
under a <strong>slow annealing schedule</strong>. Each iteration takes <span class="math notranslate nohighlight">\(O(n^4)\)</span> for evaluating the
quadratic cost function <span class="math notranslate nohighlight">\(F(\mathbf{M})\)</span>.</p></li>
</ol>
<p>We have seen that central clustering can be posed, however, in <span style="color:#f88146"><strong>continuous terms</strong> via DA</span>:</p>
<ol class="arabic simple">
<li><p>The search space is <span class="math notranslate nohighlight">\(\mathbb{R}^d\times {\cal P}\)</span>: we have to jointly find <span class="math notranslate nohighlight">\(k\)</span> centers
<span class="math notranslate nohighlight">\(\mathbf{c}_i\in\mathbb{R}^d\)</span> and a binary matrix <span class="math notranslate nohighlight">\(\mathbf{M}\in\{0,1\}^{m\times k}\)</span> indicating
how the <span class="math notranslate nohighlight">\(m\)</span> points <span class="math notranslate nohighlight">\(\mathbf{x}_a\in\mathbb{R}^d\)</span> are assigned to the most probable cluster.</p></li>
<li><p>DA <strong>decouples the optimization</strong> of the Free energy <span class="math notranslate nohighlight">\(F({\cal C},\mathbf{M})\)</span>: given a high-entropic
(almost uniform) initial assignment we alternate <strong>expectation</strong> (update the assignments while
the centers are fixed) and <strong>update</strong> the centers. Each iteration takes <span class="math notranslate nohighlight">\(O(m\times k)\)</span> and
it <strong>allows faster annealing schedules</strong>.</p></li>
<li><p><span style="color:#f88146"><strong>Remember</strong></span> that DA’s success relies on the possibility of evaluating <span class="math notranslate nohighlight">\(Z\)</span>
(the Gibbs partition function) thanks to the <strong>independence assumption</strong>: points are assumed to
be independently assigned to any cluster.</p></li>
</ol>
<p>In the <a class="reference external" href="https://gurobi-optimods.readthedocs.io/en/latest/index.html">Gurobi framework </a>,
for optimization, where graph matching is seen as a Maximmum Clique, many combinatorial algorithm share
the following features with DA:</p>
<ol class="arabic simple">
<li><p><strong>Transforming</strong> the original discrete problem into a continuous one.</p></li>
<li><p><strong>Optimize</strong> the objective function in the continuous space by means of a polynomial method.</p></li>
<li><p><strong>Revert</strong> the result to the discrete space through a <em>clean-up</em> heuristic.</p></li>
</ol>
<p>These methods are called <span style="color:#f88146"><strong>continuation method</strong></span>.</p>
</section>
<section id="softmax-operator">
<h4><span class="section-number">2.5.1.2. </span>SoftMax operator<a class="headerlink" href="#softmax-operator" title="Permalink to this heading">#</a></h4>
<p>In 1996, <a class="reference external" href="https://www.cise.ufl.edu/~anand/pdf/pamigm3.pdf">Steven Gold and Anand Rangarajan</a>
exploited the following <strong>simple algorithm</strong> for finding the maximum element in a list
of numbers:</p>
<div class="proof algorithm admonition" id="Softmax-alg">
<p class="admonition-title"><span class="caption-number">Algorithm 2.3 </span> (Soft Maximum)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inputs</strong> A list of elements <span class="math notranslate nohighlight">\(L=[X_1,\ldots,X_m]\)</span> with <span class="math notranslate nohighlight">\(X_i\in\mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(\beta_0&gt;0\)</span><br />
<strong>Outputs</strong> <span class="math notranslate nohighlight">\(m_i&gt;0\)</span> if <span class="math notranslate nohighlight">\(X_i=\max_{L}\)</span> and <span class="math notranslate nohighlight">\(0\)</span> otherwise.</p>
<ol class="arabic">
<li><p>Initialize <span class="math notranslate nohighlight">\(\beta\leftarrow \beta_0\)</span></p></li>
<li><p><strong>while</strong> <span class="math notranslate nohighlight">\(\beta &lt; \beta_f\)</span>:</p>
<ol class="arabic">
<li><p><strong>for</strong> <span class="math notranslate nohighlight">\(i=1,\ldots, m\)</span>:</p>
<p><span class="math notranslate nohighlight">\(m_i\leftarrow \exp(\beta X_i)\)</span></p>
</li>
<li><p><strong>for</strong> <span class="math notranslate nohighlight">\(i=1,\ldots, m\)</span>:</p>
<p><span class="math notranslate nohighlight">\(m_i\leftarrow \frac{m_i}{\sum_{i=1}^m m_i}\)</span></p>
</li>
<li><p>Increase <span class="math notranslate nohighlight">\(\beta\)</span></p></li>
</ol>
</li>
<li><p><strong>return</strong> <span class="math notranslate nohighlight">\(\{m_i\}\)</span> where <span class="math notranslate nohighlight">\(\sum_{i=1}^m m_i=1\)</span></p></li>
</ol>
</section>
</div><p>This algorithm is equivalent to give the <span class="math notranslate nohighlight">\(\{m_i\}\)</span> which maximize
<span class="math notranslate nohighlight">\(\sum_{i=1}^m m_iX_i\)</span>, now formulated in continuous terms via the <strong>control parameter</strong>
<span class="math notranslate nohighlight">\(\beta&gt;0\)</span>. This is the <strong>softmax</strong> operator:</p>
<div class="math notranslate nohighlight">
\[
m_j = \frac{\exp(\beta X_j)}{\sum_{i=1}^m\exp(\beta X_i)}\;,
\]</div>
<p>which is the classical mechanism to select class-membership in the last layer of a neural network!</p>
<p>We show this mechanism in <a class="reference internal" href="#daexample"><span class="std std-numref">Fig. 2.25</span></a>. As we increase <span class="math notranslate nohighlight">\(\beta\)</span>, the <span class="math notranslate nohighlight">\(m_i\)</span> corresponding to the maximum <span class="math notranslate nohighlight">\(X_i\)</span>
(note that there may be many maximal values) tend to <span class="math notranslate nohighlight">\(1\)</span>, whereas the <span class="math notranslate nohighlight">\(m_i\)</span> for the non-maximal values drop to <span class="math notranslate nohighlight">\(0\)</span>.
In the neural-network jargon, this mechanism is dubbed as <strong>winner takes all</strong> or <strong>WTA</strong>.</p>
<figure class="align-center" id="daexample">
<a class="reference internal image-reference" href="_images/DAExample-Photoroom.png"><img alt="_images/DAExample-Photoroom.png" src="_images/DAExample-Photoroom.png" style="width: 800px; height: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.25 </span><span class="caption-text">Softmaxing a list of real-valued elements.</span><a class="headerlink" href="#daexample" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="graduated-assignment">
<h3><span class="section-number">2.5.2. </span>Graduated Assignment<a class="headerlink" href="#graduated-assignment" title="Permalink to this heading">#</a></h3>
<section id="linear-assignment">
<h4><span class="section-number">2.5.2.1. </span>Linear Assignment<a class="headerlink" href="#linear-assignment" title="Permalink to this heading">#</a></h4>
<p>Linear Assignment (LA) is polinomial problem with many applications in Computer Science and AI.
Given a <strong>bipartite graph</strong> <span class="math notranslate nohighlight">\(G=(V,E)\)</span> where: a) <span class="math notranslate nohighlight">\(V = V_1\cup V_2\)</span>,<span class="math notranslate nohighlight">\(V_1\cap V_2=\emptyset\)</span> is
a vertex partition and b) <span class="math notranslate nohighlight">\(E=V_1\times V_2\)</span>, i.e. there are only edges between <span class="math notranslate nohighlight">\(V_1\)</span> and <span class="math notranslate nohighlight">\(V_2\)</span>.
In addition, the graph is <strong>weighted</strong> since we are given a matrix of variables
<span class="math notranslate nohighlight">\(\mathbf{X}\in\mathbb{R}^{m\times n}\)</span>, with <span class="math notranslate nohighlight">\(m=|V_1|\)</span>, <span class="math notranslate nohighlight">\(n=|V_2|\)</span>, where <span class="math notranslate nohighlight">\(\mathbf{X}_{ai}\)</span> measures the <strong>affinity</strong>
between <span class="math notranslate nohighlight">\(i\in V_1\)</span> and <span class="math notranslate nohighlight">\(j\in V_2\)</span> and its meaning depends on the problem (compatibility between processes and
CPUs, local similarity between points of two shapes, etc).</p>
<p>The <span style="color:#f88146"><strong>discrete</strong> (original) version</span> of LA is kind of obvious:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbf{M}^{\ast} &amp;= \arg\max_{{\cal P}} E(\mathbf{M})=\sum_{a\in V_1}\sum_{i\in V_2}\mathbf{M}_{ai}\mathbf{X}_{ai}\\
{\cal P}=&amp;\left\{\mathbf{M}\in \{0,1\}^{m\times n}:\forall a\in V_1:\sum_{i\in V_2}\mathbf{M}_{ai}\le 1\;\text{and}\; \forall i\in V_2:\sum_{a\in V_1}\mathbf{M}_{ai}\le 1\;\right\}
\end{align}
\end{split}\]</div>
<p>In other words, <span style="color:#f88146">LA is the <strong>linear version</strong> of QAP</span> where <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> is <strong>real-valued</strong>
instead of being an adjacency matrix. Concerning the search space, if <span class="math notranslate nohighlight">\(m=n\)</span> then <span class="math notranslate nohighlight">\({\cal P}=\Pi_n\)</span>
space is the Permuthoedron. However, it is not in NP and actually it can be solved in <span class="math notranslate nohighlight">\(O(n^3)\)</span> with
the so called <a class="reference external" href="https://en.wikipedia.org/wiki/Hungarian_algorithm">Hungarian algorithm</a>.</p>
<p>However, herein we are going to introduce the <span style="color:#f88146"><strong>soft/continuous</strong> version</span> which
is basically an extension of <strong>SoftMax</strong> incorporating:</p>
<ul class="simple">
<li><p><strong>Continuous assingments</strong>. Instead of <span class="math notranslate nohighlight">\(\mathbf{M}\in \{0,1\}^{m\times n}\)</span> we have <span class="math notranslate nohighlight">\(\mathbf{M}\in [0,1]^{m\times n}\)</span>.</p></li>
<li><p><strong>Two-way constraints</strong>. Each <span class="math notranslate nohighlight">\(i\in V_1\)</span> has a <strong>probability</strong> of being assigned to <span class="math notranslate nohighlight">\(a\in V_2\)</span> and viceversa. Therefore:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\forall a:\sum_{i=1}^n\mathbf{M}_{ai}=1\;\;\text{and}\;\;\forall i:\sum_{a=1}^m\mathbf{M}_{ai}=1\;.
\]</div>
<p>i.e. our search space is a matricial generalization of the <span style="color:#f88146">(vectorial) <strong>simplex</strong></span>:</p>
<div class="math notranslate nohighlight">
\[
\Delta_n =\left\{\{m_i\}\in\mathbb{R}^n:\sum_{i=1}^nm_i=1\right\}\;.
\]</div>
<p>Actually, if <span class="math notranslate nohighlight">\(m=n\)</span> the search space is not the Permuthoedron <span class="math notranslate nohighlight">\(\Pi_n\)</span> but the
<a class="reference external" href="https://en.wikipedia.org/wiki/Doubly_stochastic_matrix">Birkhoff polytope</a> <span class="math notranslate nohighlight">\(\mathbb{B}_n\)</span>. In matricial
terms, <span class="math notranslate nohighlight">\(\mathbb{B}_n\)</span> is the set of <strong>doubly stochastic</strong> matrices (matrices whose rows and columns add <span class="math notranslate nohighlight">\(1\)</span>).
In this regard, remember that <span class="math notranslate nohighlight">\(\Pi_n\subset \mathbb{B}_n\)</span> since every permutation matrix is doubly stochastic.
Therefore, the vertices of the Birkhoff polytope are the elements of <span class="math notranslate nohighlight">\(\Pi_n\)</span> (solutions to the discrete problem)
but during the resolution of the problem <span style="color:#f88146"><strong>continuous solutions</strong> lying in the
edges and sides of the polytope are <strong>allowed</strong></span>.</p>
<p>Algorithmically, the <strong>SoftLA</strong> needs to <strong>enforce the two-way constraints</strong> in every iteration as follows:</p>
<div class="proof algorithm admonition" id="SoftLA-alg">
<p class="admonition-title"><span class="caption-number">Algorithm 2.4 </span> (SoftLA)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inputs</strong> Affinity matrix <span class="math notranslate nohighlight">\(\mathbf{X}\in\mathbb{R}^{m\times n}\)</span>, <span class="math notranslate nohighlight">\(\beta_0&gt;0\)</span><br />
<strong>Outputs</strong> <span class="math notranslate nohighlight">\(\mathbf{M}^{\ast}\)</span> maximal assignment.</p>
<ol class="arabic simple">
<li><p>Initialize <span class="math notranslate nohighlight">\(\beta\leftarrow \beta_0\)</span></p></li>
<li><p><strong>while</strong> <span class="math notranslate nohighlight">\(\beta &lt; \beta_f\)</span>:</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}_{ai}\leftarrow \exp(\beta \mathbf{X}_{ai})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\leftarrow\text{Sinkhorn}(\mathbf{M})\)</span></p></li>
<li><p>Increase <span class="math notranslate nohighlight">\(\beta\)</span></p></li>
</ol>
</li>
<li><p><strong>return</strong> <span class="math notranslate nohighlight">\(\mathbf{M}^{\ast}\)</span> optimal doubly-stochastic matrix.</p></li>
</ol>
</section>
</div><p>where <span class="math notranslate nohighlight">\(\text{Sinkhorn}(\mathbf{M})\)</span> is an iterative row-col normalization process which
converges to a stochastic matrix:</p>
<div class="proof algorithm admonition" id="Sinkhorn-alg">
<p class="admonition-title"><span class="caption-number">Algorithm 2.5 </span> (Sinkhorn)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inputs</strong> Exponential assignment matrix: <span class="math notranslate nohighlight">\(\mathbf{M}=\exp(\beta\mathbf{X})\)</span><br />
<strong>Outputs</strong> <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> doubly-stochastic matrix.</p>
<ol class="arabic">
<li><p><span class="math notranslate nohighlight">\(t\leftarrow 0\)</span></p></li>
<li><p>convergence<span class="math notranslate nohighlight">\(\leftarrow\)</span> False</p></li>
<li><p><strong>while</strong> <span class="math notranslate nohighlight">\(\neg\)</span>convergence:</p>
<ol class="arabic">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}^{old}_{ai}\leftarrow \mathbf{M}_{ai}\)</span></p></li>
<li><p><strong>for</strong> <span class="math notranslate nohighlight">\(a=1,2,\ldots,m\)</span> (Normalize rows)</p>
<p><span class="math notranslate nohighlight">\(\mathbf{M}_{ai}\leftarrow \frac{\mathbf{M}_{ai}}{\sum_{i=1}^n \mathbf{M}_{ai}}\)</span></p>
</li>
<li><p><strong>for</strong> <span class="math notranslate nohighlight">\(i=1,2,\ldots,n\)</span> (Normalize cols)</p>
<p><span class="math notranslate nohighlight">\(\mathbf{M}_{ai}\leftarrow \frac{\mathbf{M}_{ai}}{\sum_{i=a}^m \mathbf{M}_{ai}}\)</span></p>
</li>
<li><p><span class="math notranslate nohighlight">\(t\leftarrow t + 1\)</span></p></li>
<li><p>convergence = <span class="math notranslate nohighlight">\((t&gt;t_{max})\)</span> <strong>or</strong> <span class="math notranslate nohighlight">\((\sum_{ai}|\mathbf{M}_{ai}- \mathbf{M}^{old}_{ai}|\le\epsilon )\)</span></p></li>
</ol>
</li>
<li><p><strong>return</strong> <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> doubly-stochastic matrix.</p></li>
</ol>
</section>
</div><p>Interestingly, the structure of <span class="math notranslate nohighlight">\(\text{SoftLa}\)</span> is rather simple and essentially is the similar to that
of <span class="math notranslate nohighlight">\(\text{SoftMax}\)</span> but for matrices, taking <span class="math notranslate nohighlight">\(O(n^2)\)</span> instead of <span class="math notranslate nohighlight">\(O(n^3)\)</span> as the Hungarian algorithm.</p>
<p>In <a class="reference internal" href="#hungarian"><span class="std std-numref">Fig. 2.26</span></a> we show how <span class="math notranslate nohighlight">\(\text{SoftLa}\)</span> solves a problem in a couple of
iterations</p>
<figure class="align-center" id="hungarian">
<a class="reference internal image-reference" href="_images/SA-Hungarian-removebg-preview.png"><img alt="_images/SA-Hungarian-removebg-preview.png" src="_images/SA-Hungarian-removebg-preview.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.26 </span><span class="caption-text">SoftLA solution for a <span class="math notranslate nohighlight">\(m=n=5\)</span> instance with random costs.</span><a class="headerlink" href="#hungarian" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Note that:</p>
<ol class="arabic simple">
<li><p>The general initialization is <span class="math notranslate nohighlight">\(\mathbf{M}^0=\mathbf{1}^T\mathbf{1}+ \epsilon\mathbf{I}\)</span>,
i.e. the matrix of ones with a slight perturbation: <span class="math notranslate nohighlight">\(\mathbf{M}^0_{ai}=1+\epsilon\)</span>. This
initialization is known as <strong>baricenter</strong> or <strong>neutral</strong>.</p></li>
<li><p>In the above example, <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> is drawn from <span class="math notranslate nohighlight">\(n\times n\)</span> <strong>random</strong> integers between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(n^2-1\)</span>.</p></li>
<li><p>The role of <span class="math notranslate nohighlight">\(\text{Sinkhorn}\)</span> is to enforce the two-way constraints and sometimes it may lead
to a very entropic doubly-stochastic matrix as we show in the following exercise.
<br></br>
<span style="color:#d94f0b">
<strong>Exercise</strong>. Prove that applying <span class="math notranslate nohighlight">\(\text{Sinkhorn}\)</span> to the exponentiation of the above matrix
converges to a maximum entropy assignment. Do not use <span class="math notranslate nohighlight">\(\beta\)</span>. Explain <strong>why</strong>.
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\mathbf{X}=
\begin{bmatrix}
x          &amp; x+\epsilon\\
x-\epsilon &amp; x\\
\end{bmatrix}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
A priori, it seems that the optimal assignment is <span class="math notranslate nohighlight">\((a=1)\rightarrow (i=2)\)</span> and <span class="math notranslate nohighlight">\((a=2)\rightarrow (i=2)\)</span>
but this is not possible due to the two-way constraint. Let us apply the exponential:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\mathbf{M}=
\begin{bmatrix}
e^x          &amp; e^{x+\epsilon}\\
e^{x-\epsilon} &amp; e^x\\
\end{bmatrix}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<ins>Row normalization</ins> makes things independent of <span class="math notranslate nohighlight">\(x\)</span>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
\mathbf{M} &amp;=
\begin{bmatrix}
\frac{e^x}{e^x + e^{x+\epsilon}}   &amp; \frac{e^{x+\epsilon}}{e^x + e^{x+\epsilon}}\\
\frac{e^{x-\epsilon}}{e^x + e^{x-\epsilon}} &amp; \frac{e^x}{e^x + e^{x-\epsilon}}\\
\end{bmatrix}
=\begin{bmatrix}
\frac{1}{1 + e^{\epsilon}}   &amp; \frac{e^{\epsilon}}{1 + e^{\epsilon}}\\
\frac{e^{-\epsilon}}{1 + e^{-\epsilon}} &amp; \frac{1}{1 + e^{-\epsilon}}\\
\end{bmatrix}
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<ins>Column normalization</ins>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
\mathbf{M}_{:1} &amp;= \frac{1}{1 + e^{\epsilon}}  + \frac{e^{-\epsilon}}{1 + e^{-\epsilon}} 
              = \frac{(1 + e^{-\epsilon})+e^{-\epsilon}(1 + e^{\epsilon})}{(1 + e^{\epsilon})(1 + e^{-\epsilon})}
              = \frac{(1 + e^{-\epsilon}) + (1 + e^{-\epsilon})}{(1 + e^{\epsilon})(1 + e^{-\epsilon})}
              = \frac{2}{1 + e^{\epsilon}}\\
\mathbf{M}_{:2} &amp;= \frac{e^{\epsilon}}{1 + e^{\epsilon}} + \frac{1}{1 + e^{-\epsilon}}
              = \frac{e^{\epsilon}(1 + e^{-\epsilon}) + (1 + e^{\epsilon})}{(1 + e^{\epsilon})(1 + e^{-\epsilon})}
              = \frac{(1 + e^{\epsilon}) + (1 + e^{\epsilon})}{(1 + e^{\epsilon})(1 + e^{-\epsilon})}
              = \frac{2}{1 + e^{-\epsilon}}
\end{align}   
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
\mathbf{M} &amp;=
\begin{bmatrix}
\frac{\mathbf{M}_{a1}}{\mathbf{M}_{:1}}   &amp; \frac{\mathbf{M}_{a2}}{\mathbf{M}_{:2}} \\
\frac{\mathbf{M}_{b1}}{\mathbf{M}_{:1}}   &amp; \frac{\mathbf{M}_{b2}}{\mathbf{M}_{:2}} \\
\end{bmatrix} 
= \begin{bmatrix}
\frac{1}{1 + e^{\epsilon}}:\frac{2}{1 + e^{\epsilon}}              &amp; \frac{e^{\epsilon}}{1 + e^{\epsilon}}:\frac{2}{1 + e^{-\epsilon}}\\
\frac{e^{-\epsilon}}{1 + e^{-\epsilon}}:\frac{2}{1 + e^{\epsilon}} &amp; \frac{1}{1 + e^{-\epsilon}}:\frac{2}{1 + e^{-\epsilon}}\\
\end{bmatrix}
= \begin{bmatrix}
\frac{1}{2}   &amp; \frac{1}{2}\\
\frac{1}{2}   &amp; \frac{1}{2}\\
\end{bmatrix}
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
which proves the statement. <strong>Why</strong>? Well, adding an <span class="math notranslate nohighlight">\(\epsilon\)</span> in one column and
subracting it in the opposite column leads to maximal uncertainty wrt the diagonal
which is preserved. This is not obvious, and even <strong>counter-ituitive</strong>, but it is a bit clarified by the removal of
<span class="math notranslate nohighlight">\(x\)</span> after row normalization.
</span>
<br></br></p></li>
</ol>
</section>
<section id="softassign">
<h4><span class="section-number">2.5.2.2. </span>SoftAssign<a class="headerlink" href="#softassign" title="Permalink to this heading">#</a></h4>
<p>The extension of <span class="math notranslate nohighlight">\(\text{SoftLa}\)</span> to graph matching is almost straight. Now, instead of
having a linear cost function, the graph-matching cost function is <strong>quadratic</strong> in <span class="math notranslate nohighlight">\(\mathbf{M}\)</span>
(it is the QAP-Quadratic Assignment Problem). Then, the <span style="color:#f88146"><strong>relaxed QAP</strong></span> becomes</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbf{M}^{\ast}= &amp; \arg\max_{{\cal B}}F(\mathbf{M}) = \frac{1}{2}\sum_{a\in V}\sum_{i\in V'}\sum_{b\in V}\sum_{j\in V'}\mathbf{M}_{ai}\mathbf{M}_{bj}\mathbf{X}_{ab}\mathbf{Y}_{ij}\\
{\cal B}=&amp;\left\{\mathbf{M}\in [0,1]^{(m+1)\times (n+1)}:\forall a\in V:\sum_{i\in V'}\mathbf{M}_{ai}=1\;\text{and}\; \forall i\in V':\sum_{a\in V}\mathbf{M}_{ai}=1\;\right\}
\end{align}
\end{split}\]</div>
<p>where</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\({\cal B}\)</span> is the set of doubly-stochastic matrices of dimension <span class="math notranslate nohighlight">\((m+1)\times (n+1)\)</span>, and
the Birkhoff polytope or order <span class="math notranslate nohighlight">\(n+1\)</span>, i.e. <span class="math notranslate nohighlight">\({\cal B}_{n+1}\)</span>, if <span class="math notranslate nohighlight">\(m=n\)</span>.</p></li>
<li><p>Why an <strong>extra dimension</strong>? If <span class="math notranslate nohighlight">\(m&lt;n\)</span>, for instance, we can only have <span class="math notranslate nohighlight">\(m\)</span> one-to-one assignments
and <span class="math notranslate nohighlight">\(n-m\)</span> un-assigned nodes. In order to deal with this, we assume that these un-asigned nodes
match a <span style="color:#f88146"><strong>slack</strong> or <strong>virtual</strong> node</span>.
Therefore, adding an extra dimension accomodates two virtual
nodes (one per graph). Similar reasoning for <span class="math notranslate nohighlight">\(m&gt;n\)</span>.</p></li>
</ol>
<p>Note that <span class="math notranslate nohighlight">\(\text{SoftLA}\)</span> is just a Deterministic Annealing (DA) applied to linear assignment.
If so, one of the driving features of DA is to <span style="color:#f88146">assume <strong>assignment independence</strong></span>,
i.e. we may assume that the <em>assignment of <span class="math notranslate nohighlight">\(a\in V\)</span> to <span class="math notranslate nohighlight">\(i\in V'\)</span> is independent of that of
another <span class="math notranslate nohighlight">\(a'\in V\)</span> to <span class="math notranslate nohighlight">\(i'\in V'\)</span></em>.</p>
<p><strong>Taylor Expansion</strong>. <a class="reference external" href="https://www.cise.ufl.edu/~anand/pdf/pamigm3.pdf">Steven Gold and Anand Rangarajan</a> used a similar principle
to approximate the quadratic cost function. Note that <span class="math notranslate nohighlight">\(f(x)\approx f(a) + f'(a)(x-a)\)</span> is
the first order Taylor expansion. Then</p>
<div class="math notranslate nohighlight">
\[
F(\mathbf{M})\approx F(\mathbf{M}^0) + F'(\mathbf{M}^0)\cdot\sum_{a\in V}\sum_{i\in V}(\mathbf{M}_{ai}-\mathbf{M}^0_{ai})\;.
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}
F'(\mathbf{M}^0):={\frac{\partial F}{\partial\mathbf{M}_{a_i}}}\bigg|_{\mathbf{M}^0}=\underbrace{\sum_{b\in V}\sum_{j\in V'}\mathbf{M}_{bj}\mathbf{X}_{ab}\mathbf{Y}_{ij}}_{\mathbf{Q}_{ai}}\\
\end{split}\]</div>
<p>i.e. the derivative of a quadratic function is a linear one! Then, for a fixed <span class="math notranslate nohighlight">\(\mathbf{M}^0\)</span>, we
have that</p>
<div class="math notranslate nohighlight">
\[
\max F(\mathbf{M}) = \max \sum_{a\in V}\sum_{i\in V}\mathbf{M}_{ai}\mathbf{Q}_{ai}\;,
\]</div>
<p>i.e. a <strong>linear assignment problem</strong>.
In other words:</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{Q}_{ai}=\sum_{b\in V}\sum_{j\in V'}\mathbf{M}_{bj}\mathbf{X}_{ab}\mathbf{Y}_{ij}\)</span> works as
a <strong>temporary affinity matrix</strong> for each <span class="math notranslate nohighlight">\(\beta\)</span>.</p></li>
<li><p>Given <span class="math notranslate nohighlight">\(\mathbf{Q}_{ai}\)</span> we iterate to get the best (maximal) assignment <span class="math notranslate nohighlight">\(\mathbf{M}_{ai}\)</span> for this
<span class="math notranslate nohighlight">\(\beta\)</span>, i.e. we solve a <strong>new assignment problem</strong>.</p></li>
<li><p>Increase <span class="math notranslate nohighlight">\(\beta\)</span> and start again!</p></li>
</ol>
<p>This is the typical <strong>decoupled structure</strong> of DA problems and it leads to the
<span class="math notranslate nohighlight">\(\text{SoftAssign}\)</span> algorithm detailed below.</p>
<div class="proof algorithm admonition" id="SoftAssign-alg">
<p class="admonition-title"><span class="caption-number">Algorithm 2.6 </span> (SoftAssign)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inputs</strong> Adjacency matrices <span class="math notranslate nohighlight">\(\mathbf{X}\in\{0,1\}^{m\times m}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{Y}\in\{0,1\}^{n\times n}\)</span>,  <span class="math notranslate nohighlight">\(\beta_0&gt;0\)</span><br />
<strong>Outputs</strong> <span class="math notranslate nohighlight">\(\hat{\mathbf{M}}^{\ast}\)</span> (extended) maximal quadratic assignment.</p>
<ol class="arabic simple">
<li><p>Initialize <span class="math notranslate nohighlight">\(\beta\leftarrow \beta_0\)</span>,  <span class="math notranslate nohighlight">\(\hat{\mathbf{M}}_{ai}\leftarrow 1+\epsilon\)</span></p></li>
<li><p><strong>while</strong> <span class="math notranslate nohighlight">\(\beta &lt; \beta_f\)</span>:</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(t\leftarrow 0\)</span></p></li>
<li><p>convergence<span class="math notranslate nohighlight">\(\leftarrow\)</span> False</p></li>
<li><p><strong>while</strong> <span class="math notranslate nohighlight">\(\neg\)</span>convergence:</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\hat{\mathbf{M}}^{old}_{ai}\leftarrow \hat{\mathbf{M}}_{ai}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{Q}_{ai}\leftarrow \sum_{b=1}^m\sum_{j=1}^n\mathbf{M}_{bj}\mathbf{X}_{ab}\mathbf{Y}_{ij}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}^0_{ai}\leftarrow \exp(\beta \mathbf{Q}_{ai})\)</span></p></li>
<li><p>Expand <span class="math notranslate nohighlight">\(\mathbf{M}^0\rightarrow \hat{\mathbf{M}}^0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{\mathbf{M}}^0\leftarrow\text{Sinkhorn}(\hat{\mathbf{M}}^0)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(t\leftarrow t + 1\)</span></p></li>
<li><p>convergence = <span class="math notranslate nohighlight">\((t&gt;t_{max})\)</span> <strong>or</strong> <span class="math notranslate nohighlight">\((\sum_{ai}|\hat{\mathbf{M}}_{ai}- \hat{\mathbf{M}}^{old}_{ai}|\le\epsilon' )\)</span></p></li>
</ol>
</li>
<li><p>Increase <span class="math notranslate nohighlight">\(\beta\)</span></p></li>
</ol>
</li>
<li><p><strong>return</strong> <span class="math notranslate nohighlight">\(\hat{\mathbf{M}}^{\ast}\)</span> optimal doubly-stochastic matrix.</p></li>
</ol>
</section>
</div><p>Some notes:</p>
<ol class="arabic simple">
<li><p>If <span class="math notranslate nohighlight">\(m\neq n\)</span> we always assume <span class="math notranslate nohighlight">\(m\le n\)</span>, i.e. <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> is the smallest graph.</p></li>
<li><p>Given the expanded <span class="math notranslate nohighlight">\(\hat{\mathbf{M}}\)</span> in step <span class="math notranslate nohighlight">\(1\)</span>, we implicitly use its
<span class="math notranslate nohighlight">\(\mathbf{M}\)</span> <span class="math notranslate nohighlight">\(m\times n\)</span> matrix in steps <span class="math notranslate nohighlight">\(3.2\)</span> and <span class="math notranslate nohighlight">\(3.3\)</span>.</p></li>
<li><p>In step <span class="math notranslate nohighlight">\(3.4\)</span> we expand explicitly <span class="math notranslate nohighlight">\(\mathbf{M}^0\)</span> by incorporating an additiona row and column
of zeros. Note that <span class="math notranslate nohighlight">\(\text{Sinkhorn}\)</span> <strong>always needs</strong> a <span class="math notranslate nohighlight">\((m+1)\times (n+1)\)</span> matrix if <span class="math notranslate nohighlight">\(m\neq n\)</span>!</p></li>
</ol>
<p><strong>Complexity</strong>. It is not difficult to see that the complexity of <span class="math notranslate nohighlight">\(\text{SoftAssign}\)</span> is
roughtly <span class="math notranslate nohighlight">\(O(n^3)\)</span>, or more precisely <span class="math notranslate nohighlight">\(O(|E|n)\)</span>, if <span class="math notranslate nohighlight">\(m=n\)</span> and <span class="math notranslate nohighlight">\(|E|\)</span> is the number of edges.
Such a complexity is due to step 3.2 (the computation of <span class="math notranslate nohighlight">\(\mathbf{Q}\)</span> which involves the
product of 3 matrices).</p>
</section>
<section id="cleanup">
<h4><span class="section-number">2.5.2.3. </span>Cleanup<a class="headerlink" href="#cleanup" title="Permalink to this heading">#</a></h4>
<p>Remember that continuation methods are <strong>solved in the continuum</strong> but our <strong>original
is discrete</strong>. Given the <span class="math notranslate nohighlight">\(\text{SoftAssign}\)</span> solution <span class="math notranslate nohighlight">\(\hat{\mathbf{M}}^{\ast}\)</span>, which can
be very entropic, we must recover the closest discrete matrix (which is not unique, in general).
This task is performed by a <span style="color:#f88146"><strong>cleanup heuristic</strong> or algorithm</span> like the one detailed
below:</p>
<div class="proof algorithm admonition" id="Cleanup-alg">
<p class="admonition-title"><span class="caption-number">Algorithm 2.7 </span> (Cleanup)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inputs</strong> <span class="math notranslate nohighlight">\(\hat{\mathbf{M}}\in[0,1]^{(m+1)\times (n+1)}\)</span> optimal doubly-stochastic matrix<br />
<strong>Outputs</strong> Closest discrete matrix <span class="math notranslate nohighlight">\(\mathbf{M}\in\{0,1\}^{(m+1)\times (n+1)}\)</span></p>
<ol class="arabic">
<li><p>yet_asigned <span class="math notranslate nohighlight">\(\leftarrow 0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}[a,i]\leftarrow 0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\epsilon \leftarrow 10^{-6}\)</span></p></li>
<li><p><strong>while</strong> yet_asigned<span class="math notranslate nohighlight">\(&lt; m\)</span>:</p>
<ol class="arabic">
<li><p>changes_done<span class="math notranslate nohighlight">\(\leftarrow\)</span> False</p></li>
<li><p><strong>for</strong> <span class="math notranslate nohighlight">\(a\in\{1,2,\ldots,m+1\}\)</span>:</p>
<ol class="arabic">
<li><p>candidates <span class="math notranslate nohighlight">\(\leftarrow \emptyset\)</span></p></li>
<li><p>max_row <span class="math notranslate nohighlight">\(\leftarrow \max\:\hat{\mathbf{M}}[a,:]\)</span></p></li>
<li><p>row_capacity <span class="math notranslate nohighlight">\(\leftarrow\)</span> max_row <span class="math notranslate nohighlight">\(- \epsilon\)</span></p></li>
<li><p><strong>for</strong> <span class="math notranslate nohighlight">\(i\in\{1,2,\ldots,n+1\}\)</span>:</p>
<ol class="arabic">
<li><p>max_col <span class="math notranslate nohighlight">\(\leftarrow \max\;\hat{\mathbf{M}}[i,:]\)</span></p></li>
<li><p>col_capacity <span class="math notranslate nohighlight">\(\leftarrow\)</span> max_col <span class="math notranslate nohighlight">\(- \epsilon\)</span></p></li>
<li><p><strong>if</strong> <span class="math notranslate nohighlight">\((\mathbf{M}[a,i]&gt;\)</span>row_capacity<span class="math notranslate nohighlight">\()\)</span> <strong>and</strong> <span class="math notranslate nohighlight">\((\mathbf{M}[a,i]&gt;\)</span>col_capacity<span class="math notranslate nohighlight">\()\)</span>:</p>
<p>candidates <span class="math notranslate nohighlight">\(\leftarrow\)</span> candidates <span class="math notranslate nohighlight">\(\cup \{i\}\)</span></p>
</li>
</ol>
</li>
<li><p><strong>if</strong> <span class="math notranslate nohighlight">\(|\)</span>candidates<span class="math notranslate nohighlight">\(|\)</span>&gt;0:</p>
<ol class="arabic simple">
<li><p>max_val <span class="math notranslate nohighlight">\(\leftarrow\)</span> <span class="math notranslate nohighlight">\(\max \mathbf{M}[a,\)</span>candidates<span class="math notranslate nohighlight">\(]\)</span></p></li>
<li><p>selection <span class="math notranslate nohighlight">\(\leftarrow\)</span> <span class="math notranslate nohighlight">\(\arg\max\)</span> <span class="math notranslate nohighlight">\(\mathbf{M}[a,\)</span>candidates<span class="math notranslate nohighlight">\(]\)</span></p></li>
<li><p>col <span class="math notranslate nohighlight">\(\leftarrow\)</span> candidates[selection]</p></li>
<li><p>yet_assigned <span class="math notranslate nohighlight">\(\leftarrow\)</span> yet_assigned + 1</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}[a,\)</span>col<span class="math notranslate nohighlight">\(]\leftarrow\)</span> 1</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}[a,:]\leftarrow-\infty\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}[:,col]\leftarrow-\infty\)</span></p></li>
<li><p>changes_done <span class="math notranslate nohighlight">\(\leftarrow\)</span> True</p></li>
</ol>
</li>
</ol>
</li>
<li><p><strong>if</strong> <span class="math notranslate nohighlight">\(\neg\)</span> changes_done:</p>
<p><strong>break</strong></p>
</li>
</ol>
</li>
<li><p><strong>return</strong> <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> binary matrix.</p></li>
</ol>
</section>
</div><p>The algorithm, basically a <span style="color:#f88146"><strong>greedy</strong> version of the Hungarian algorithm</span>, proceeds as follows:</p>
<ol class="arabic simple">
<li><p><ins>Steps 2.1-2.4</ins>. For every row <span class="math notranslate nohighlight">\(a\)</span>, we build a list of <em>candidates</em> keeping track of both the row and col
capacities.</p></li>
<li><p><ins>Step 2.5</ins>. If the list of candidates is not empty, we proceed to get the best of them (step 5.5) and then we proceed
to exclude the corresponding row and column (steps 5.6 and 5.7).</p></li>
</ol>
<p>This takes <span class="math notranslate nohighlight">\(O(n^2)\)</span> and could be replaced by a run of <span class="math notranslate nohighlight">\(\text{SoftLA}\)</span>. Remember that if the algorithm
finds any match to a slack vertex these machings should be cleared.</p>
<p><strong>Results</strong>. Coming back to the Aspirin Isomorphism, we use the setting recommended
in Gold and Rangarajan’s paper: <span class="math notranslate nohighlight">\(\epsilon = 0.1\)</span>, <span class="math notranslate nohighlight">\(\epsilon'=0.5\)</span>, <span class="math notranslate nohighlight">\(\beta_0=0.5\)</span>,
<span class="math notranslate nohighlight">\(\beta_f=10.0\)</span>, <span class="math notranslate nohighlight">\(\beta_r=1.075\)</span> and <span class="math notranslate nohighlight">\(I_0=4\)</span>, <span class="math notranslate nohighlight">\(I_1=30\)</span>, where the last two numbers
are the maximal iterations of the internal <strong>while</strong> loop and <span class="math notranslate nohighlight">\(\text{Sinkhorn}\)</span>,
respectively.</p>
<p>The result in <a class="reference internal" href="#da-aspirin"><span class="std std-numref">Fig. 2.27</span></a> is nearly perfect and we can claim that Aspirin
is isomorphic wrt to a permutation of itself!</p>
<figure class="align-center" id="da-aspirin">
<a class="reference internal image-reference" href="_images/DA-Aspirnin-removebg-preview.png"><img alt="_images/DA-Aspirnin-removebg-preview.png" src="_images/DA-Aspirnin-removebg-preview.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.27 </span><span class="caption-text">Detecting the Aspirin’s Isomorphism with DA.</span><a class="headerlink" href="#da-aspirin" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>We leave to the practice lessons the extension of the algorithm for incorporating
both <span style="color:#f88146">node and edge <strong>attributtes</strong></span>.</p>
</section>
</section>
</section>
<section id="appendix">
<h2><span class="section-number">2.6. </span>Appendix<a class="headerlink" href="#appendix" title="Permalink to this heading">#</a></h2>
<section id="id1">
<h3><span class="section-number">2.6.1. </span>Independence<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<p><strong>Statistical independence</strong>. It is well known that two random variables <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are <strong>independent</strong> iff:</p>
<div class="math notranslate nohighlight">
\[
p(A,B) = p(A)\cdot p(B)\;.
\]</div>
<p>Or, in other words, applying the Bayes theorem we have that <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are independent iff</p>
<div class="math notranslate nohighlight">
\[
p(A,B) = p(B|A)p(A) = p(A|B)p(B)\Rightarrow p(B|A)=p(B)\;\text{and}\;p(A|B)=p(B)\;.
\]</div>
<p>In other words:</p>
<ul class="simple">
<li><p>Independence implies factorizing the joint distribution <span class="math notranslate nohighlight">\(p(A,B)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are indendent if the knowledge of one of them does not influence the probability of the other, i.e. <span class="math notranslate nohighlight">\(p(A|B)=p(A)\)</span> and <span class="math notranslate nohighlight">\(p(B|A)=p(B)\)</span>.</p></li>
</ul>
<p><strong>Marginalization</strong>. Alternatively, we may define statistical independence by checking the marginal probabilities. Let <span class="math notranslate nohighlight">\(a_1,a_2,\ldots,a_m\)</span> the discrete values of <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(b_1,b_2,\ldots,b_n\)</span> similarly for <span class="math notranslate nohighlight">\(B\)</span>. Then:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
&amp;&amp;\sum_{a_i}\sum_{b_j}p(A=a_i,B=b_j)=1\;\text{total probability}\\
&amp;&amp; p(A=a_i)=\sum_{b_j}p(A=a_i,B=b_j)\;\text{marginal wrt}\; A\\
&amp;&amp; p(B=b_i)=\sum_{a_i}p(A=a_i,B=b_j)\;\text{marginal wrt}\; B\\
\end{align}
\end{split}\]</div>
<p>Then, <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are independent if we can write a joint distribution as the product of two marginal distributions:</p>
<div class="math notranslate nohighlight">
\[
p(A=a_i,B=b_j) = p(A=a_i)\cdot p(B=b_j)\;\forall a_i,b_j\;.
\]</div>
<p>Let us practice a bit this concept in the following exercise.</p>
<p><br></br>
<span style="color:#d94f0b">
<strong>Exercise</strong>. Given the above table representing the joint distribution of two discrete random variables <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>, determine where they are indepedent or not. <strong>a)</strong> Usign the marginals. <strong>b)</strong> Using the conditional probabities.
</span>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|ccc}
         &amp; B=b_1 &amp; B=b_2 &amp; B=b_3 \\
  \hline
  A=a_1  &amp; 0.1   &amp; 0.2   &amp; 0.3\\
  A=a_2  &amp; 0.1   &amp; 0.2   &amp; 0.1\\  
  \hline
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<strong>a)</strong> First all, note that <span class="math notranslate nohighlight">\(\sum_{a_i,b_j}p(A=a_i,B=b_j)=1\)</span>. Now, let us compute the marginals summing the rows for <span class="math notranslate nohighlight">\(A\)</span> and the columns for <span class="math notranslate nohighlight">\(B\)</span>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
p(A=a_1) &amp;= \sum_{b_j}p(A=a_1,B=b_j)=0.1 + 0.2 + 0.3 = \mathbf{0.6}\\
p(A=a_2) &amp;= \sum_{b_j}p(A=a_2,B=b_j)=0.1 + 0.2 + 0.1 = \mathbf{0.4}\\
p(B=b_1) &amp;= \sum_{a_i}p(A=a_i,B=b_1)=0.1 + 0.1 = \mathbf{0.2}\\
p(B=b_2) &amp;= \sum_{a_i}p(A=a_i,B=b_2)=0.2 + 0.2 = \mathbf{0.4}\\
p(B=b_3) &amp;= \sum_{a_i}p(A=a_i,B=b_3)=0.3 + 0.1 = \mathbf{0.4}\\
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Now we check independence:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
p(A=a_1,B=b_1) &amp;=0.1\neq p(A=a_1)p(B=b_1) = \mathbf{0.6}\times\mathbf{0.2}=0.12\\
p(A=a_1,B=b_2) &amp;=0.2\neq p(A=a_1)p(B=b_2) = \mathbf{0.6}\times\mathbf{0.4}=0.24\\
p(A=a_1,B=b_3) &amp;=0.3\neq p(A=a_1)p(B=b_3) = \mathbf{0.6}\times\mathbf{0.4}=0.24\\
p(A=a_2,B=b_1) &amp;=0.1\neq p(A=a_2)p(B=b_1) = \mathbf{0.4}\times\mathbf{0.2}=0.08\\
p(A=a_2,B=b_2) &amp;=0.2\neq p(A=a_2)p(B=b_2) = \mathbf{0.4}\times\mathbf{0.4}=0.16\\
p(A=a_2,B=b_3) &amp;=0.1\neq p(A=a_2)p(B=b_3) = \mathbf{0.4}\times\mathbf{0.4}=0.16\\
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
However, note that in all cases <span class="math notranslate nohighlight">\(p(A=a_i,B=b_j)\approx p(A=a_i)p(B=b_j)\)</span>.
</span>
<br></br>
<span style="color:#d94f0b">
<strong>b)</strong> Now, we can compute the conditional probabilities using the Bayes theorem: <span class="math notranslate nohighlight">\(p(A=a_i|B=b_j)=p(A=a_i,B=b_j)/p(B=b_j)\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|ccc}
                  &amp; B=b_1 &amp; B=b_2 &amp; B=b_3 \\
  \hline
  p(A=a_1|B=b_j)  &amp; \frac{0.1}{0.2}=0.5   &amp; \frac{0.2}{0.4}=0.5  &amp; \frac{0.3}{0.4}=0.75\\
  p(A=a_2|B=b_j)  &amp; \frac{0.1}{0.2}=0.5   &amp; \frac{0.2}{0.4}=0.5   &amp; \frac{0.1}{0.4}=0.25\\  
  \hline
                &amp; \sum = 1 &amp; \sum = 1 &amp; \sum=1\\
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
and <span class="math notranslate nohighlight">\(p(B=b_j|A=a_i)=p(A=a_i,B=b_j)/p(A=a_i)\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|ccc|c}
                  &amp; p(B=b_1|A=a_i) &amp; p(B=b_2|A=a_i) &amp; p(B=b_3|A=a_i) \\
  \hline
  A=a_1  &amp; \frac{0.1}{0.6}=0.17   &amp; \frac{0.2}{0.6}=0.33  &amp; \frac{0.3}{0.6}=0.5 &amp; \sum = 1\\
  A=a_2  &amp; \frac{0.1}{0.4}=0.25   &amp; \frac{0.2}{0.4}=0.5   &amp; \frac{0.1}{0.4}=0.25 &amp; \sum = 1\\  
  \hline
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Note that the conditional probabilities adds <span class="math notranslate nohighlight">\(1\)</span> wrt the “influenced” variable, i.e.
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\forall a_i: \sum_{b_j} p(A=a_i|B=b_j)= 1\;\text{and}\; 
\forall b_j: \sum_{a_i} p(B=b_j|A=a_i)= 1
\)</span>
</span>
<br></br></p>
</section>
<section id="entropy">
<h3><span class="section-number">2.6.2. </span>Entropy<a class="headerlink" href="#entropy" title="Permalink to this heading">#</a></h3>
<p>This is the <strong>first point</strong> in the subject where we talk about <span style="color:#f88146"><strong>Information Theory</strong></span>, the main auxiliary maths behind this course. In this regard, we refer you to the <a class="reference external" href="https://link.springer.com/book/10.1007/978-1-84882-297-9">author’s book on the subject</a>.</p>
<section id="definition-and-properties">
<h4><span class="section-number">2.6.2.1. </span>Definition and properties<a class="headerlink" href="#definition-and-properties" title="Permalink to this heading">#</a></h4>
<p>The above exercise reveals one esential property of DA: <span style="color:#f88146">we cannot converge without keeping the <strong>maximizing the entropy</strong></span>. But, what is entropy?</p>
<p><strong>Entropy</strong> is the ultimate measure of uncertainty defined by <a class="reference external" href="https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf">Shannon</a> as follows:</p>
<p>Given a discrete random variable <span class="math notranslate nohighlight">\(X\)</span>, with possible values <span class="math notranslate nohighlight">\(\{x_1,\ldots,x_n\}\)</span>, its <strong>entropy</strong> is given by:</p>
<div class="math notranslate nohighlight">
\[
H(X) = -\sum_{i=1}^n p(X=x_i)\log p(X=x_i)\;.
\]</div>
<p>Similarly, we can express entropy in terms of the probabilities of the <strong>discrete events</strong> <span class="math notranslate nohighlight">\(p_i=p(X=x_i)\)</span>, i.e.</p>
<div class="math notranslate nohighlight">
\[
H(p_1,p_2,\ldots,p_n)=-\sum_{i=1}^n p_i\log p_i\;.
\]</div>
<p>Then, we have the following <strong>properties</strong>:</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(H\)</span> is continuous, concave and non-negative in <span class="math notranslate nohighlight">\(p_i\)</span>.</p></li>
<li><p>If all the <span class="math notranslate nohighlight">\(p_i\)</span> are equally likely, i.e. <span class="math notranslate nohighlight">\(p_i=1/n\)</span>, then entropy is <strong>maximal</strong> for this <span class="math notranslate nohighlight">\(n\)</span> and equal to <span class="math notranslate nohighlight">\(\log n\)</span>. The larger <span class="math notranslate nohighlight">\(n\)</span> the larger the <strong>uncertainty</strong> of the equally likely events.</p></li>
<li><p>If we have <span class="math notranslate nohighlight">\(\log_2\)</span> entropy is measured in <strong>bits</strong>, whereas if it is <span class="math notranslate nohighlight">\(\ln\)</span> it is measured in  <strong>nats</strong>.</p></li>
<li><p>Since <span class="math notranslate nohighlight">\(E(f(x))=\sum_x x\cdot f(x)\)</span> is the <strong>expectation</strong> of <span class="math notranslate nohighlight">\(f(x)\)</span>, then entropy is the expectation of the logarithm.</p></li>
</ol>
<p><strong>Entropy of Bernouilli</strong>. An interesting example is the measure of the entropy of <span class="math notranslate nohighlight">\(X\sim \text{Bernouilli}(p)\)</span>.</p>
<p><span class="math notranslate nohighlight">\(X\)</span> has value <span class="math notranslate nohighlight">\(x=1\)</span> with probability <span class="math notranslate nohighlight">\(p(X=1)=p\)</span> and <span class="math notranslate nohighlight">\(x=0\)</span> with probability <span class="math notranslate nohighlight">\(p(X=0)=q=1-p\)</span>.
Then:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
H(X) &amp;= -\sum_{x}p(X=x)\log p(X=x)\\
     &amp;= -p(X=0)\log p(X=0) - p(X=1)\log p(X=1)\\
     &amp;= -p\log p - q\log q\\
     &amp;= -p\log p - (1-p)\log (1-p)\;.
\end{align}
\end{split}\]</div>
<p>Therefore, the maximal entropy (uncertainty) of a Bernouilli variable is when <span class="math notranslate nohighlight">\(p=q=1/2\)</span> (for instance the probability of a fair coin):</p>
<div class="math notranslate nohighlight">
\[
H(X) = -p\log p -p\log p = -2p\log p = -\log\frac{1}{2} = -(\log 1 - \log 2) = \log 2\;.
\]</div>
<p>which is <span class="math notranslate nohighlight">\(\log_2 2=1\)</span> bits as we can see in <a class="reference internal" href="#km-entropy-bern"><span class="std std-numref">Fig. 2.28</span></a>. Note that the function is concave wrt <span class="math notranslate nohighlight">\(p\)</span>. Minimal entropy is achieved at the two extreme points: <span class="math notranslate nohighlight">\(p=0\)</span> and <span class="math notranslate nohighlight">\(p=1\)</span>, where the <strong>uncertainty is minimal</strong> (completely biased coin).</p>
<figure class="align-center" id="km-entropy-bern">
<a class="reference internal image-reference" href="_images/KM-entropy-Bern-removebg-preview.png"><img alt="_images/KM-entropy-Bern-removebg-preview.png" src="_images/KM-entropy-Bern-removebg-preview.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.28 </span><span class="caption-text">Entropy of Bernouilli wrt <span class="math notranslate nohighlight">\(p\)</span>.</span><a class="headerlink" href="#km-entropy-bern" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="entropy-and-coding">
<h4><span class="section-number">2.6.2.2. </span>Entropy and Coding<a class="headerlink" href="#entropy-and-coding" title="Permalink to this heading">#</a></h4>
<p>The relationship between entropy and codelength is key to understand why <span style="color:#f88146">entropy measures information content</span>.</p>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Morse_code">Morse code</a> follows the principle of <em>assigning less number of bits to more frequent letters than to less frequent ones</em>. Herein, the bits are clear: <span class="math notranslate nohighlight">\(0\)</span> for the dits “.” and <span class="math notranslate nohighlight">\(1\)</span> for the
dash “.”. For instance, following the frequencies of letters in English, the shorter “codewords” are those for <span class="math notranslate nohighlight">\(E=.\)</span> and <span class="math notranslate nohighlight">\(T=-\)</span>. The longer ones are those for the digits <span class="math notranslate nohighlight">\(0-9\)</span> (five bits all of them). The table below shows those lengths and probabilities.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp;\begin{array}{|c|c|c|c|}
\hline
\text{Letter} &amp; \text{Morse code} &amp; \text{codelength} &amp; \text{Probability} \\
\hline
A &amp; .- &amp; 2 &amp; 0.06381 \\
B &amp; -... &amp; 4 &amp; 0.01166 \\
C &amp; -.-. &amp; 4 &amp; 0.02173 \\
D &amp; -.. &amp; 3 &amp; 0.03323 \\
E &amp; . &amp; 1 &amp; 0.09924 \\
F &amp; ..-. &amp; 4 &amp; 0.01741 \\
G &amp; --. &amp; 3 &amp; 0.01574 \\
H &amp; .... &amp; 4 &amp; 0.04761 \\
I &amp; .. &amp; 2 &amp; 0.05442 \\
J &amp; .--- &amp; 4 &amp; 0.00120 \\
K &amp; -.- &amp; 3 &amp; 0.00603 \\
L &amp; .-.. &amp; 4 &amp; 0.03145 \\
M &amp; -- &amp; 2 &amp; 0.01880 \\
N &amp; -. &amp; 2 &amp; 0.05273 \\
O &amp; --- &amp; 3 &amp; 0.05865 \\
P &amp; .--. &amp; 4 &amp; 0.01507 \\
Q &amp; --.- &amp; 4 &amp; 0.00074 \\
R &amp; .-. &amp; 3 &amp; 0.04677 \\
S &amp; ... &amp; 3 &amp; 0.04943 \\
T &amp; - &amp; 1 &amp; 0.07075 \\
U &amp; ..- &amp; 3 &amp; 0.02155 \\
V &amp; ...- &amp; 4 &amp; 0.00764 \\
W &amp; .-- &amp; 3 &amp; 0.01844 \\
X &amp; -..- &amp; 4 &amp; 0.00117 \\
Y &amp; -.-- &amp; 4 &amp; 0.01542 \\
Z &amp; --.. &amp; 4 &amp; 0.00058 \\
0 &amp; ----- &amp; 5 &amp; 0.01563 \\
1 &amp; .---- &amp; 5 &amp; 0.05469 \\
2 &amp; ..--- &amp; 5 &amp; 0.02344 \\
3 &amp; ...-- &amp; 5 &amp; 0.02344 \\
4 &amp; ....- &amp; 5 &amp; 0.02344 \\
5 &amp; ..... &amp; 5 &amp; 0.01563 \\
6 &amp; -.... &amp; 5 &amp; 0.01563 \\
7 &amp; --... &amp; 5 &amp; 0.01563 \\
8 &amp; ---.. &amp; 5 &amp; 0.01563 \\
9 &amp; ----. &amp; 5 &amp; 0.01563 \\
\hline
\end{array}
\end{aligned}
\end{split}\]</div>
<p>Note that, due to traditional reasons it is not always happening that shorter codes correspond to highest frequencies (probabilities) but this is the global trend.</p>
<p>Of course, each message should have a space ‘ ‘ between letters in order to be decoded properly. For instance: “……-.. .-.. —   .– — .-. .-.. -..” means H E L L O W O R L D in Morse.</p>
<p><strong>Codes and Trees</strong>. One interesting way of characterizing codes (binary codes in particular) is to try to put the symbols to code in a tree. See for instance <a class="reference internal" href="#morse-tree"><span class="std std-numref">Fig. 2.29</span></a>, where the root is marked as “#’. We point out the following:</p>
<ul class="simple">
<li><p><span style="color:#f88146"><strong>Decoding means</strong></span> navigating through the tree top-to-bottom, making decisions (dit or slash for binary codes), i.e. building a “path”, until the desired symbol is reached. Such a path is the “codeword”.</p></li>
<li><p><span style="color:#f88146"><strong>The codeword length</strong></span> <span class="math notranslate nohighlight">\(l_i\)</span> is the number of decision taken to decode it, i.e. the depth of the symbol in the tree.</p></li>
<li><p><span style="color:#f88146"><strong>A code is comma-like</strong></span> if all the symbols are placed at the leaves of the tree. This is clearly not the case of Morse.</p></li>
<li><p><span style="color:#f88146"><strong>A code is prefix-like</strong></span> if any symbol is preceeded by a unique sequence of other codes (the prefix). For instace, to decode “O” in Morse, we should decode “T” and “M”. Thus, the prefix of “O” is “TM”.</p></li>
</ul>
<p>In the Morse code few letters are placed at the leaves of tree. Notably, they are the ones with the largest codeword lengths. Herein, we follow the recipe that assigning less frequent letters to deeper levels of the tree. The purpose of such strategy is twofold: (a) saving storage space, and (b) fast decoding.</p>
<p><strong>Expected codelength</strong>. Suppose that we have <span class="math notranslate nohighlight">\(n\)</span> letters, each one with frequency <span class="math notranslate nohighlight">\(p_i\)</span> and codelenth <span class="math notranslate nohighlight">\(l_i\)</span>, <span class="math notranslate nohighlight">\(i=1,\ldots,n\)</span>. Then, the expected codelength is</p>
<div class="math notranslate nohighlight">
\[
E(l) = \sum_{i}l_i p_i = l_1p_1 + l_2p_2 + \ldots + l_np_n\;.
\]</div>
<p>For the Morse code, <span class="math notranslate nohighlight">\(E_{Morse}(l)=3.0794539323542267\)</span>. Now, the tree in <a class="reference internal" href="#morse-tree"><span class="std std-numref">Fig. 2.29</span></a> is built under the constraint of placing more probable letters in the top of the (binary) tree. In other words, we may assume that</p>
<div class="math notranslate nohighlight">
\[
p_i \approx \frac{1}{2^{l_i}}\;. 
\]</div>
<p>If so, <span class="math notranslate nohighlight">\(E(l)\approx H(p_1,p_2,\ldots,p_n)\)</span> since</p>
<div class="math notranslate nohighlight">
\[
\log_2 p_i \approx \log_2 \frac{1}{2^{l_i}} = \log_2 1 - \log_2 2^{l_i} = - \log_2 2^{l_i} = - l_i\;.
\]</div>
<p>Then</p>
<div class="math notranslate nohighlight">
\[
-p_i\log_2 p_i \approx \frac{1}{2^{l_i}}l_i = \frac{l_i}{2^{l_i}}\;.
\]</div>
<p>Roughly speaking, <span style="color:#f88146"><strong>the expected codelegth matches entropy</strong></span>!</p>
<p>More precisely, for comma-like codes we have <span class="math notranslate nohighlight">\(E(l)\le H(p_1,p_2,\ldots,p_n)\)</span>. Although Morse is not comma-like it satisfies this bound since <span class="math notranslate nohighlight">\(E_{Morse}(l) = 3.0794539323542267\le H_{Morse} = 4.713102340698242\)</span>.</p>
<figure class="align-center" id="morse-tree">
<a class="reference internal image-reference" href="_images/Morse-Photoroom.png"><img alt="_images/Morse-Photoroom.png" src="_images/Morse-Photoroom.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.29 </span><span class="caption-text">Decoding tree for the Morse code.</span><a class="headerlink" href="#morse-tree" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><strong>Huffman Codes</strong>. As an alternative code, herein we highlight a <span style="color:#f88146"><strong>prefix code</strong></span> (no code is the prefix of another). Prefix codes are easily decodable and, in addition, they allow us (by definition) to suppress the space ” ” between words (see the Table below).</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\begin{array}{|c|c|c|c|}
\hline
\text{Letter} &amp; \text{Huffman Code} &amp; \text{Length} &amp; \text{Probability} \\
\hline
A &amp; 1010 &amp; 4 &amp; 0.06381 \\
B &amp; 001110 &amp; 6 &amp; 0.01166 \\
C &amp; 111001 &amp; 6 &amp; 0.02173 \\
D &amp; 10111 &amp; 5 &amp; 0.03323 \\
E &amp; 000 &amp; 3 &amp; 0.09924 \\
F &amp; 110101 &amp; 6 &amp; 0.01741 \\
G &amp; 100111 &amp; 6 &amp; 0.01574 \\
H &amp; 11111 &amp; 5 &amp; 0.04761 \\
I &amp; 0101 &amp; 4 &amp; 0.05442 \\
J &amp; 1101001011 &amp; 10 &amp; 0.00120 \\
K &amp; 11010011 &amp; 8 &amp; 0.00603 \\
L &amp; 10110 &amp; 5 &amp; 0.03145 \\
M &amp; 110111 &amp; 6 &amp; 0.01880 \\
N &amp; 0100 &amp; 4 &amp; 0.05273 \\
O &amp; 0111 &amp; 4 &amp; 0.05865 \\
P &amp; 001111 &amp; 6 &amp; 0.01507 \\
Q &amp; 1101001001 &amp; 10 &amp; 0.00074 \\
R &amp; 11101 &amp; 5 &amp; 0.04677 \\
S &amp; 0010 &amp; 4 &amp; 0.04943 \\
T &amp; 1100 &amp; 4 &amp; 0.07075 \\
U &amp; 111000 &amp; 6 &amp; 0.02155 \\
V &amp; 1101000 &amp; 7 &amp; 0.00764 \\
W &amp; 110110 &amp; 6 &amp; 0.01844 \\
X &amp; 1101001010 &amp; 10 &amp; 0.00117 \\
Y &amp; 100000 &amp; 6 &amp; 0.01542 \\
Z &amp; 1101001000 &amp; 10 &amp; 0.00058 \\
0 &amp; 100001 &amp; 6 &amp; 0.01563 \\
1 &amp; 0110 &amp; 4 &amp; 0.05469 \\
2 &amp; 111100 &amp; 6 &amp; 0.02344 \\
3 &amp; 111101 &amp; 6 &amp; 0.02344 \\
4 &amp; 00110 &amp; 5 &amp; 0.02344 \\
5 &amp; 100011 &amp; 6 &amp; 0.01563 \\
6 &amp; 100010 &amp; 6 &amp; 0.01563 \\
7 &amp; 100110 &amp; 6 &amp; 0.01563 \\
8 &amp; 100100 &amp; 6 &amp; 0.01563 \\
9 &amp; 100101 &amp; 6 &amp; 0.01563 \\
\hline
\end{array}
\end{aligned}
\end{split}\]</div>
<p>For instance, the Huffman code for HELLOW WORLD is</p>
<div class="math notranslate nohighlight">
\[
1111100010110101100111\;1101100111111011011010111
\]</div>
<p>Concerning <span class="math notranslate nohighlight">\(E_{Huffman}(l)\)</span> and <span class="math notranslate nohighlight">\(H_{Huffman}=\)</span>, they are identical: <span class="math notranslate nohighlight">\(4.7\)</span>. See the encoding tree in <a class="reference internal" href="#huffman-tree"><span class="std std-numref">Fig. 2.30</span></a></p>
<figure class="align-center" id="huffman-tree">
<a class="reference internal image-reference" href="_images/Huffman-Photoroom.png"><img alt="_images/Huffman-Photoroom.png" src="_images/Huffman-Photoroom.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.30 </span><span class="caption-text">Decoding tree for the Huffman code of the Morse frequencies.</span><a class="headerlink" href="#huffman-tree" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Finally, this code is not only useful for English but for any laguage such as Chinese.</p>
</section>
<section id="joint-vs-conditional-entropy">
<h4><span class="section-number">2.6.2.3. </span>Joint vs Conditional entropy<a class="headerlink" href="#joint-vs-conditional-entropy" title="Permalink to this heading">#</a></h4>
<p>Entropy is defined for any (discrete) probability function, and in particular for the <strong>joint probability</strong>. Thus, if <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are two discrete variables with respective values <span class="math notranslate nohighlight">\(a_1,\ldots, a_m\)</span> and <span class="math notranslate nohighlight">\(b_1,\ldots,b_n\)</span> and does exists the probability <span class="math notranslate nohighlight">\(p(A,B)\)</span>, the <span style="color:#f88146"><strong>joint entropy</strong></span> <span class="math notranslate nohighlight">\(H(A,B)\)</span> is defined as follows:</p>
<div class="math notranslate nohighlight">
\[
H(A,B) = -\sum_{a_i}\sum_{b_j}p(A=a_i,B=b_j)\log p(A=a_i,B=b_j)\;.
\]</div>
<p>Remember that the Bayes theorem leads to <span class="math notranslate nohighlight">\(p(A,B)=p(A|B)p(B)=p(B|A)p(A)\)</span>.
As a result, we may define entropies for <span class="math notranslate nohighlight">\(p(A|B)\)</span> and <span class="math notranslate nohighlight">\(p(B|A)\)</span>, i.e. <span style="color:#f88146"><strong>conditional entropies</strong></span>.</p>
<p>Remember that <em>entropy is an expectation</em>, then</p>
<div class="math notranslate nohighlight">
\[
H(A|B=b_j) = -\sum_{a_i}p(A=a_i|B=b_j)\log p(A=a_i|B=b_j)\;,
\]</div>
<p>is the <span style="color:#f88146"><strong>entropy of the conditional expectation</strong> of <span class="math notranslate nohighlight">\(A\)</span> wrt <span class="math notranslate nohighlight">\(B=b_j\)</span></span>. Now, if we average this quantity wrt all values  <span class="math notranslate nohighlight">\(b_j\)</span>, we have that the <em>conditional entropy</em> is given by following weigthed sum:</p>
<div class="math notranslate nohighlight">
\[
H(A|B) = \sum_{b_j}p(B=b_j)\cdot H(A|B=b_j)\;,
\]</div>
<p>and similarly for <span class="math notranslate nohighlight">\(H(B|A)\)</span>. Actually we have several <strong>properties</strong> linking conditional entropies and joint entropies:</p>
<ol class="arabic simple">
<li><p><strong>Zero-value</strong>: <span class="math notranslate nohighlight">\(H(A|B)=0\)</span> if the value of <span class="math notranslate nohighlight">\(A\)</span> is <em>completely determined</em> by <span class="math notranslate nohighlight">\(B\)</span>. In other words, <span class="math notranslate nohighlight">\(H(A|B)\)</span> measures how much uncertainty adds <span class="math notranslate nohighlight">\(B\)</span> to <span class="math notranslate nohighlight">\(A\)</span>. Then, if <span class="math notranslate nohighlight">\(p(A|B)=1\)</span> it is expected that knowing <span class="math notranslate nohighlight">\(B\)</span> is the same as knowing <span class="math notranslate nohighlight">\(A\)</span> itself.</p></li>
<li><p><strong>Independence</strong>: <span class="math notranslate nohighlight">\(H(A|B)=H(A)\)</span> and <span class="math notranslate nohighlight">\(H(B|A)=H(A)\)</span> iff <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are <em>independent</em>, as it happens with <span class="math notranslate nohighlight">\(p(A|B)=p(A)\)</span> and <span class="math notranslate nohighlight">\(p(B|A)=p(A)\)</span>.</p></li>
<li><p><strong>Chain rule</strong>: the conditional entropies can be derived from the joint entropy <span class="math notranslate nohighlight">\(H(A,B)\)</span> by subtracting the entropy of the conditioning variable:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
H(A|B) = H(A,B)-H(B)\;\;\text{and}\;\; H(B|A) = H(A,B)-H(A)\;.
\]</div>
<p><br></br>
<span style="color:#d94f0b">
<strong>Exercise</strong>. Given the discrete random variales <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>, in the previous exercise: <strong>a)</strong> determine the joint entropy and <strong>b)</strong> the conditional entropies. <strong>c)</strong> Interpret what is the uncertainty added or removed by each variable wrt to the other and the uncertainty removed from the joint entropy. <strong>d)</strong> Are <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> independent attending to their entropies?
</span>
<br></br>
<span style="color:#d94f0b">
<strong>a)</strong> First all, for the joint entropy we need the joint distribution:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|ccc}
         &amp; B=b_1 &amp; B=b_2 &amp; B=b_3 \\
  \hline
  A=a_1  &amp; 0.1   &amp; 0.2   &amp; 0.3\\
  A=a_2  &amp; 0.1   &amp; 0.2   &amp; 0.1\\  
  \hline
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
H(A,B) &amp;= -\sum_{a_i}\sum_{b_j}p(A=a_i,B=b_j)\log p(A=a_i,B=b_j)\\
       &amp;= -[3(0.1\log 0.1) + 2(0.2\log 0.2) + 0.3\log 0.3]\\
       &amp;= \mathbf{1.695}\;\text{nats}\;.
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Note that the maximum entropy (in this case with <span class="math notranslate nohighlight">\(m\cdot n=6\)</span> events) is given when
all events are equiprobable, i.e. <span class="math notranslate nohighlight">\(p(A=a_i,B=b_j)=\frac{1}{m\cdot n}=\frac{1}{2\cdot 3}=\frac{1}{6}\)</span>, and it is <span class="math notranslate nohighlight">\(H_{max}(A,B)=\log n = \log 6\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
H_{max}(A,B) &amp;= -\sum_{a_i}\sum_{b_j}\frac{1}{m\cdot n}\log \frac{1}{m\cdot n}\\
       &amp;= -6\cdot \frac{1}{6}\log\frac{1}{6}\\
       &amp;= -\log\frac{1}{6}\\
       &amp;= -(\log 1 - \log 6)\\
       &amp;= \log 6 = 1.791\;\text{nats}\;.
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Then <span class="math notranslate nohighlight">\(H(A,B)=1.695\)</span> is pretty close to <span class="math notranslate nohighlight">\(H_{max}(A,B)=1.791\)</span>.
</span>
<br></br>
<span style="color:#d94f0b">
<strong>b1)</strong> For <span class="math notranslate nohighlight">\(H(A|B)\)</span> we need the conditional distribution <span class="math notranslate nohighlight">\(p(A|B)\)</span>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|ccc}
                  &amp; B=b_1 &amp; B=b_2 &amp; B=b_3 \\
  \hline
  p(A=a_1|B=b_j)  &amp; \frac{0.1}{0.2}=0.5   &amp; \frac{0.2}{0.4}=0.5  &amp; \frac{0.3}{0.4}=0.75\\
  p(A=a_2|B=b_j)  &amp; \frac{0.1}{0.2}=0.5   &amp; \frac{0.2}{0.4}=0.5   &amp; \frac{0.1}{0.4}=0.25\\  
  \hline
                &amp; \sum = 1 &amp; \sum = 1 &amp; \sum=1\\
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Then, attending to the definition <span class="math notranslate nohighlight">\(H(A|B)=\sum_{b_j}p(B=b_j)H(A|B=b_j)\)</span>, we have:
</span>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
H(A|B=b_1) &amp;=  -\sum_{a_i}p(A=a_i|B=b_1)\log p(A=a_i|B=b_1)\\
           &amp;=  -(0.5\log 0.5 + 0.5\log 0.5) = 0.693\\
H(A|B=b_2) &amp;=  -\sum_{a_i}p(A=a_i|B=b_2)\log p(A=a_i|B=b_2)\\
           &amp;=  -(0.5\log 0.5 + 0.5\log 0.5) = 0.693\\
H(A|B=b_3) &amp;=  -\sum_{a_i}p(A=a_i|B=b_3)\log p(A=a_i|B=b_3)\\
           &amp;=  -(0.75\log 0.75 + 0.25\log 0.25) = 0.562\\
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Then, <span class="math notranslate nohighlight">\(H(A|B)\)</span> is given by a weighted average, where we need the marginals <span class="math notranslate nohighlight">\(p(B=b_j)=[0.2\;0.4\;0.4]\)</span> (see the corresponding exercise):
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
H(A|B) &amp;= \sum_{b_j}p(B=b_j)H(A|B=b_j)\\
       &amp;= p(B=b_1)H(A|B=b_1) + p(B=b_2)H(A|B=b_2) + p(B=b_3)H(A|B=b_3)\\
       &amp;= 0.2\cdot H(A|B=b_1) + 0.4\cdot H(A|B=b_2) + 0.4\cdot H(A|B=b_3)\\
       &amp;= 0.2\cdot 0.693 + 0.4\cdot 0.693 + 0.4\cdot 0.562\\
       &amp;= \mathbf{0.640}\;.
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<strong>b2)</strong> For <span class="math notranslate nohighlight">\(H(B|A)\)</span> we need the conditional distribution <span class="math notranslate nohighlight">\(p(B|A)\)</span>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|ccc|c}
                  &amp; p(B=b_1|A=a_i) &amp; p(B=b_2|A=a_i) &amp; p(B=b_3|A=a_i) \\
  \hline
  A=a_1  &amp; \frac{0.1}{0.6}=0.17   &amp; \frac{0.2}{0.6}=0.33  &amp; \frac{0.3}{0.6}=0.5 &amp; \sum = 1\\
  A=a_2  &amp; \frac{0.1}{0.4}=0.25   &amp; \frac{0.2}{0.4}=0.5   &amp; \frac{0.1}{0.4}=0.25 &amp; \sum = 1\\  
  \hline
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Then, attending to the definition <span class="math notranslate nohighlight">\(H(B|A)=\sum_{a_i}p(A=a_i)H(B|A=a_i)\)</span>, we have:
</span>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
H(B|A=a_1) &amp;=  -\sum_{b_j}p(B=b_j|A=a_1)\log p(B=b_j|A=a_1)\\
           &amp;=  -(0.17\log 0.17 + 0.33\log 0.33 + 0.5\log 0.5) = 1.013\\
H(B|A=a_2) &amp;=  -\sum_{b_j}p(B=b_j|A=a_2)\log p(B=b_j|A=a_2)\\
           &amp;=  -(0.25\log 0.25 + 0.5\log 0.5 + 0.25\log 0.25) = 1.039\\
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Then, <span class="math notranslate nohighlight">\(H(B|A)\)</span> is given by a weighted average, where we need the marginals <span class="math notranslate nohighlight">\(p(A=a_i)=[0.6\;0.4]\)</span> (see the corresponding exercise):
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
H(B|A) &amp;= \sum_{a_i}p(A=a_i)H(B|B=a_i)\\
       &amp;= p(A=a_1)H(B|A=a_1) + p(A=a_2)H(B|A=a_2)\\
       &amp;= 0.6\cdot H(B|A=a_1) + 0.4\cdot H(B|A=a_2)\\
       &amp;= 0.6\cdot 1.013 + 0.4\cdot 1.039 \\
       &amp;= \mathbf{1.023}\;.
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<strong>c)</strong> As a result <span class="math notranslate nohighlight">\(H(B|A)=\mathbf{1.023}&gt;H(A|B)=\mathbf{0.640}\)</span>. This means that <strong><span class="math notranslate nohighlight">\(B\)</span> holds more information about <span class="math notranslate nohighlight">\(A\)</span> than <span class="math notranslate nohighlight">\(A\)</span> holds about <span class="math notranslate nohighlight">\(B\)</span></strong>.
<br></br>
Finally, let us compute the individual entropies <span class="math notranslate nohighlight">\(H(A)\)</span> and <span class="math notranslate nohighlight">\(H(B)\)</span>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
H(A) &amp; = -\sum_{a_i}p(A=a_i)\log p(A=a_i)\\
       &amp; = -(0.6\log 0.6 + 0.4\log 0.4)\\
       &amp; = \mathbf{0.673}\;.\\
H(B) &amp; = -\sum_{b_j}p(B=b_j)\log p(B=b_j)\\
       &amp; = -(0.2\log 0.2 + 0.4\log 0.4 + 0.4\log 0.4)\\
       &amp; = \mathbf{1.054}\;.\\
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Since <span class="math notranslate nohighlight">\(H(A|B)=H(A,B)-H(B)\)</span> and <span class="math notranslate nohighlight">\(H(B|A)=H(A,B)-H(A)\)</span> and <span class="math notranslate nohighlight">\(H(B)&gt;H(A)\)</span> (<span class="math notranslate nohighlight">\(B\)</span> is more uncertain than <span class="math notranslate nohighlight">\(A\)</span>), then <span class="math notranslate nohighlight">\(H(B)\)</span> reduces more the uncertainty of <span class="math notranslate nohighlight">\(H(A,B)\)</span> than <span class="math notranslate nohighlight">\(H(A)\)</span>. This explains why <span class="math notranslate nohighlight">\(H(A|B)\ll H(B|A)\)</span>.
<br><br>
Let us check the calculus:
</span>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
H(A|B) = \mathbf{0.640} = 1.695 - 1.054\;\;\text{and}\;\; H(B|A) = \mathbf{1.023} = 1.695 - 0.673\;.
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<strong>d)</strong> Since <span class="math notranslate nohighlight">\(H(A|B)=0.640\approx H(A)= 0.673\)</span> and <span class="math notranslate nohighlight">\(H(B|A)=1.023\approx H(B)=1.054\)</span>, we conclude that <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are <em>close to be independent, although they are not</em>. This is consistent with the previous exercise on marginals.
<br></br>
<span style="color:#d94f0b">
Then, in this exercise we have illustrated how to compute the conditional entropies either directly or through the individual entropies and the joint entropy. However, the key of this exercixse is to <strong>interpret correctly what a conditional entropy is</strong>: <em>a quantification of how much information has one variable about the other</em>.
</span></p>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="topic1.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">1. </span>NP-Complete Problems</p>
      </div>
    </a>
    <a class="right-next"
       href="practice_1_1.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3. </span>Introduction to the practical part of TAB2026</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-common-subgraph">2.1. Maximum Common Subgraph</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-matching">2.2. Graph Matching</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#assignments-and-matchings">2.2.1. Assignments and Matchings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rectangle-rule-cost-function">2.2.2. Rectangle rule: Cost Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#integer-constraints-qap">2.2.3. Integer Constraints: QAP</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulated-annealing">2.3. Simulated Annealing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approximating-qap-with-sa">2.3.1. Approximating QAP with SA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation-of-sa">2.3.2. Interpretation of SA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gibbs-sampling">2.3.3. Gibbs Sampling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-of-sa">2.3.4. Limitations of SA</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#central-clustering">2.4. Central Clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clusters-and-prototypes">2.4.1. Clusters and Prototypes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cost-functions">2.4.2. Cost Functions</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#attractors">2.4.2.1. Attractors</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#independence">2.4.2.2. Independence</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#derivation">2.4.2.3. Derivation</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deterministic-annealing">2.4.3. Deterministic Annealing</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy-and-free-energy">2.4.3.1. Entropy and Free Energy</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-entropy">2.4.3.2. Maximum Entropy</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#softmax-for-graph-matching">2.5. SoftMax for Graph Matching</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#softmaxing">2.5.1. SoftMaxing</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#continuation-methods">2.5.1.1. Continuation Methods</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#softmax-operator">2.5.1.2. SoftMax operator</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#graduated-assignment">2.5.2. Graduated Assignment</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-assignment">2.5.2.1. Linear Assignment</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#softassign">2.5.2.2. SoftAssign</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#cleanup">2.5.2.3. Cleanup</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#appendix">2.6. Appendix</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">2.6.1. Independence</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy">2.6.2. Entropy</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#definition-and-properties">2.6.2.1. Definition and properties</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy-and-coding">2.6.2.2. Entropy and Coding</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#joint-vs-conditional-entropy">2.6.2.3. Joint vs Conditional entropy</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Francisco Javier Escolano Ruiz
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>