

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>2. Simulated and Deterministic Annealing &#8212; Técnicas y Algoritmos de Búsqueda IA</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'topic2';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="3. Introduction to the practical part of TAB2026" href="practice_1_1.html" />
    <link rel="prev" title="1. NP-Complete Problems" href="topic1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Técnicas y Algoritmos de Búsqueda IA - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Técnicas y Algoritmos de Búsqueda IA - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    TAB2026
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">NP-Hardness and Graph Matching</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="topic1.html">1. NP-Complete Problems</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">2. Simulated and Deterministic Annealing</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Practice 1</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="practice_1_1.html">3. Introduction to the practical part of TAB2026</a></li>
<li class="toctree-l1"><a class="reference internal" href="practice_1_2.html">4. Graph Construction for Matching</a></li>
<li class="toctree-l1"><a class="reference internal" href="practice_1_3.html">5. Graph Matching</a></li>
<li class="toctree-l1"><a class="reference internal" href="practice_1_4.html">6. Graph Matching with Topological Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="practice_1_5.html">7. SoftAssign</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Ftopic2.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/topic2.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Simulated and Deterministic Annealing</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-common-subgraph">2.1. Maximum Common Subgraph</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-matching">2.2. Graph Matching</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#assignments-and-matchings">2.2.1. Assignments and Matchings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rectangle-rule-cost-function">2.2.2. Rectangle rule: Cost Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#integer-constraints-qap">2.2.3. Integer Constraints: QAP</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulated-annealing">2.3. Simulated Annealing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approximating-qap-with-sa">2.3.1. Approximating QAP with SA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation-of-sa">2.3.2. Interpretation of SA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gibbs-sampling">2.3.3. Gibbs Sampling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-of-sa">2.3.4. Limitations of SA</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#softmax-for-graph-matching">2.4. SoftMax for Graph Matching</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#softmaxing">2.4.1. SoftMaxing</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#continuation-methods">2.4.1.1. Continuation Methods</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#softmax-operator">2.4.1.2. SoftMax operator</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#graduated-assignment">2.4.2. Graduated Assignment</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-assignment">2.4.2.1. Linear Assignment</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#softassign">2.4.2.2. SoftAssign</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">2.4.2.3. Overview</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#including-attributes">2.4.2.4. Including attributes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#cleanup">2.4.2.5. Cleanup</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#appendix">2.5. Appendix</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#independence">2.5.1. Independence</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy">2.5.2. Entropy</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#definition-and-properties">2.5.2.1. Definition and properties</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy-and-coding">2.5.2.2. Entropy and Coding</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#joint-vs-conditional-entropy">2.5.2.3. Joint vs Conditional entropy</a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="simulated-and-deterministic-annealing">
<h1><span class="section-number">2. </span>Simulated and Deterministic Annealing<a class="headerlink" href="#simulated-and-deterministic-annealing" title="Permalink to this heading">#</a></h1>
<section id="maximum-common-subgraph">
<h2><span class="section-number">2.1. </span>Maximum Common Subgraph<a class="headerlink" href="#maximum-common-subgraph" title="Permalink to this heading">#</a></h2>
<p><strong>Motivation</strong>. Chemical compounds exhibit structural patters shared between compounds of the same family. One of these patterns is the circular (hexagonal) structure formed by carbon (C) atoms linked by single or double bonds (see <a class="reference internal" href="#aspirin"><span class="std std-numref">Fig. 2.1</span></a>-Left and Center) where the non-labeled vertices denote C atoms. In this example, the presence of the hexagonal ring in the popular <a class="reference external" href="https://pubchem.ncbi.nlm.nih.gov/compound/Aspirin">Aspirin</a> (<a class="reference internal" href="#aspirin"><span class="std std-numref">Fig. 2.1</span></a>-Right) is well known.</p>
<p>The development of AI pattern matching techniques for detetecting substructures has powered the field of Bioinformatics. Nowadays, the analysis of exponentially growing datasets of proteins such as the Protein Data Bank <a class="reference external" href="https://www.wwpdb.org/">PDB</a> or of chemical compounds such as <a class="reference external" href="https://pubchem.ncbi.nlm.nih.gov/">PubChem</a> is a must in AI.</p>
<figure class="align-center" id="aspirin">
<a class="reference internal image-reference" href="_images/MCS-Aspirin-Photoroom.png"><img alt="_images/MCS-Aspirin-Photoroom.png" src="_images/MCS-Aspirin-Photoroom.png" style="width: 800px; height: 300px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.1 </span><span class="caption-text">Structure of the Aspirin.</span><a class="headerlink" href="#aspirin" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><strong>MCS</strong>. Comparing substructures is not an easy problem. Whereas comparing substrings is polynomial, comparing substrutures is a well-known NP problem called the <span style="color:#f88146">Maximum Common Subgraph</span> or MCS:</p>
<p><em>Given two graphs <span class="math notranslate nohighlight">\(G_1=(V_1,E_1)\)</span>  and <span class="math notranslate nohighlight">\(G_2=(V_2,E_2)\)</span>, what is the graph <span class="math notranslate nohighlight">\(H=(V,E)\)</span> that is <em>common</em> to <span class="math notranslate nohighlight">\(G_1\)</span> and <span class="math notranslate nohighlight">\(G_2\)</span> with the maximum number of nodes</em>?</p>
<p>Herein, <em>common</em> means the following: <span class="math notranslate nohighlight">\(V = V\subseteq V_1\)</span> and <span class="math notranslate nohighlight">\(E\subseteq E_1\)</span> and exists an injective (one-to-one) mapping <span class="math notranslate nohighlight">\(f:V\rightarrow V_2\)</span> such that <span class="math notranslate nohighlight">\((i,j)\in E\)</span> iff <span class="math notranslate nohighlight">\((f(i),f(j))\in E_2\)</span>.</p>
<p>This <span style="color:#f88146"><strong>subsetness flavor</strong></span> clarifies the fact that <span style="color:#f88146"><span class="math notranslate nohighlight">\(\text{MCS}\in \text{NP}\)</span></span>. Actually, MCS does not only search for one common subset but for <em>the subset with the maximum number of nodes</em>.</p>
<p>This is quite clear in the following <em>Breaking Bad</em> problem: <span style="color:#f88146">What is the structural coincidence between Ectasy and Amphetamine?</span>.</p>
<ul class="simple">
<li><p>According to PubChem, <a class="reference external" href="https://pubchem.ncbi.nlm.nih.gov/compound/3_4-Methylenedioxymethamphetamine">Ectasy</a> is derived from the <a class="reference external" href="https://pubchem.ncbi.nlm.nih.gov/compound/Amphetamine">Amphetamine</a>.</p></li>
<li><p>Looking at <a class="reference internal" href="#drugs"><span class="std std-numref">Fig. 2.2</span></a>-Center (Ectasy)
comes from removing an Hidrogen atom from Amphetamine (<a class="reference internal" href="#drugs"><span class="std std-numref">Fig. 2.2</span></a>-Right), adding a carbon and an oxigen-carbon pentagonal cycle.</p></li>
<li><p>The MCS is in <a class="reference internal" href="#drugs"><span class="std std-numref">Fig. 2.2</span></a>-Left.</p></li>
</ul>
<figure class="align-center" id="drugs">
<a class="reference internal image-reference" href="_images/Drugs-Photoroom.png"><img alt="_images/Drugs-Photoroom.png" src="_images/Drugs-Photoroom.png" style="width: 800px; height: 200px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.2 </span><span class="caption-text">Maximal Common Substructure (left) of two design drugs (center and right).</span><a class="headerlink" href="#drugs" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>All the figures have been generated by the <a class="reference external" href="https://www.rdkit.org/">RDKit: Open-Source Cheminformatics Software</a>.</p>
</section>
<section id="graph-matching">
<h2><span class="section-number">2.2. </span>Graph Matching<a class="headerlink" href="#graph-matching" title="Permalink to this heading">#</a></h2>
<p>Solving MCS via a polynomial approximation requires <em>finding the injective function</em> <span class="math notranslate nohighlight">\(f\)</span> between the vertices <span class="math notranslate nohighlight">\(V\)</span> of small graph <span class="math notranslate nohighlight">\(X=(V,E)\)</span> and those <span class="math notranslate nohighlight">\(V'\)</span> of larger graph <span class="math notranslate nohighlight">\(Y=(V',E')\)</span> in polynomial time.</p>
<section id="assignments-and-matchings">
<h3><span class="section-number">2.2.1. </span>Assignments and Matchings<a class="headerlink" href="#assignments-and-matchings" title="Permalink to this heading">#</a></h3>
<p><strong>Node assignments</strong>. Consider the (undirected) graphs:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp;\begin{array}{cll}
\text{Graph}  &amp; \text{Nodes} &amp; \text{Edges}\\
X &amp; V=\{a,b,c\} &amp; E=\{(a,b),(b,c)\}\\
Y &amp; V'=\{1,2,3,4,5\} &amp; E=\{(1,2),(1,3),(1,4),(3,4)\}\\
\end{array}
\end{aligned}
\end{split}\]</div>
<p>As we have <span class="math notranslate nohighlight">\(n=|V'|=5\)</span> and <span class="math notranslate nohighlight">\(r=|V|=3\)</span> we have <span class="math notranslate nohighlight">\(P(n,r)=n\cdot (n-1)\cdot (n-r + 1)\)</span> <strong>r-permutations</strong> i.e. one-to-one functions <span class="math notranslate nohighlight">\(f\)</span> or <span style="color:#f88146"><strong>node assignments</strong></span> that can be potential solutions to the MCS problem. In this case, we have <span class="math notranslate nohighlight">\(P(5,3)=5\cdot 4\cdot 3=60\)</span> different  assignments. Then, <span style="color:#f88146">what assignments provide the MCS between <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span></span>?</p>
<p>For the graphs <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> the size of the MCS is <span class="math notranslate nohighlight">\(2\)</span>, since <span class="math notranslate nohighlight">\(X\)</span> has only two edges and if it is a subgraph of <span class="math notranslate nohighlight">\(Y\)</span> (as it is really is), the size of the MCS has <span class="math notranslate nohighlight">\(|V|=3\)</span> nodes and |E|=2$ edges.</p>
<p>However, this depends on how good is the injective function <span class="math notranslate nohighlight">\(f\)</span>. For the one in <a class="reference internal" href="#matching"><span class="std std-numref">Fig. 2.3</span></a> we have:</p>
<div class="math notranslate nohighlight">
\[
f(a)=1,\; f(b)=2\;\text{and}\; f(c)=3\;.
\]</div>
<p>As we can see, <span class="math notranslate nohighlight">\((a,b)\in E\)</span> and <span class="math notranslate nohighlight">\((1=f(a),2=f(b))\in E'\)</span>. However, for the other edge <span class="math notranslate nohighlight">\((b,c)\in E\)</span> we have that <span class="math notranslate nohighlight">\((2=f(b),3=f(c))\not\in E'\)</span>: As a result <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> <span style="color:#f88146"><strong>do only have one common edge for <span class="math notranslate nohighlight">\(f\)</span></strong></span> (in magenta).</p>
<figure class="align-center" id="matching">
<a class="reference internal image-reference" href="_images/Matching1-Photoroom.png"><img alt="_images/Matching1-Photoroom.png" src="_images/Matching1-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.3 </span><span class="caption-text">non-Maximal Common Substructure.</span><a class="headerlink" href="#matching" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Consider now the assignment:</p>
<div class="math notranslate nohighlight">
\[
f(a)=1,\; f(b)=4\;\text{and}\; f(c)=5\;.
\]</div>
<p>which indeed leads to a MCS:</p>
<figure class="align-center" id="matching2">
<a class="reference internal image-reference" href="_images/Matching2-Photoroom.png"><img alt="_images/Matching2-Photoroom.png" src="_images/Matching2-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.4 </span><span class="caption-text">A Maximal Common Substructure.</span><a class="headerlink" href="#matching2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>However, this MCS assignment <strong>is not unique</strong>. Actually we have <span class="math notranslate nohighlight">\({5 \choose 3}=10\)</span> subgraphs of <span class="math notranslate nohighlight">\(Y\)</span> where we can <em>embed</em> <span class="math notranslate nohighlight">\(X\)</span> but only <span class="math notranslate nohighlight">\(8\)</span> of them lead to MCS assignments. In the above table, we encode each MCS injective function <span class="math notranslate nohighlight">\(f_i\)</span> as a list of <span style="color:#f88146"> <strong>pairwise matchings</strong> <span class="math notranslate nohighlight">\((v\in V, f_i(v)\in V')\)</span></span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp;\begin{array}{cl}
\text{Injection} &amp; \text{MCS Assignment} \\
f_1 &amp; [(a, 1), \mathbf{(b, 4)}, (c, 5)]\\
f_2 &amp; [(a, 2), \mathbf{(b, 1)}, (c, 3)]\\
f_3 &amp; [(a, 2), \mathbf{(b, 1)}, (c, 4)]\\
f_4 &amp; [(a, 3), \mathbf{(b, 1)}, (c, 2)]\\
f_5 &amp; [(a, 3), \mathbf{(b, 1)}, (c, 4)]\\
f_6 &amp; [(a, 4), \mathbf{(b, 1)}, (c, 2)]\\
f_7 &amp; [(a, 4), \mathbf{(b, 1)}, (c, 3)]\\
f_8 &amp; [(a, 5), \mathbf{(b, 4)}, (c, 1)]\\
\end{array}
\end{aligned}
\end{split}\]</div>
<p><strong>Notable vertices</strong>. In the above table, note that MCS assignments usually contain pairwise matchings between nodes with large degrees (notable vertices) in both graphs, namely <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{1}\)</span> or <span class="math notranslate nohighlight">\(\mathbf{4}\)</span> (in bold). These matchings are <span class="math notranslate nohighlight">\(\mathbf{(b,1)}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{(b,4)}\)</span>.</p>
<p>In the following exercise we emphasize the link between the subgraphs of <span class="math notranslate nohighlight">\(Y\)</span> and the MCS assignments, which is a fundamental concept in this topic.
<br></br>
<span style="color:#d94f0b">
<strong>Exercise</strong>. Identify the <span class="math notranslate nohighlight">\({5 \choose 3}=10\)</span> subgraphs of size <span class="math notranslate nohighlight">\(3\)</span> in <span class="math notranslate nohighlight">\(Y\)</span> (indicating both nodes and edges) and:<br />
<strong>a)</strong> Detect the ones which do correspond to a complete  embedding of <span class="math notranslate nohighlight">\(X\)</span> in <span class="math notranslate nohighlight">\(Y\)</span>.<strong>b)</strong> Identify these subgraphs in the <span class="math notranslate nohighlight">\(8\)</span> MCS assigmnets of the above table.
<br></br>
<strong>NOTE</strong>. Express always the edges in <strong>lexicographical order</strong> i.e. <span class="math notranslate nohighlight">\((i,j)\)</span> if <span class="math notranslate nohighlight">\(i&lt;j\)</span>.
<br></br>
Answer. <strong>a)</strong> The subgraphs are the <span class="math notranslate nohighlight">\(10\)</span> combinations of the <span class="math notranslate nohighlight">\(5\)</span> nodes <span class="math notranslate nohighlight">\(V'=\{1,2,3,4,5\}\)</span> in groups of <span class="math notranslate nohighlight">\(3\)</span> nodes (because <span class="math notranslate nohighlight">\(|V|=3\)</span>). However, only those subgraphs wich are connected can lead to a complete embeddding of <span class="math notranslate nohighlight">\(X\)</span> in <span class="math notranslate nohighlight">\(Y\)</span>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
&amp;\begin{array}{cclc}
\text{Subgraph} &amp; \text{Nodes} &amp; \text{Edges} &amp; \text{is Connected?}\\
s_1    &amp; V_1'=(1, 2, 3) &amp; E_1'=\{(1,2),(1,3)\} &amp; \checkmark \\
s_2    &amp; V_2'=(1, 2, 4) &amp; E_2'=\{(1,2),(1,3)\} &amp; \checkmark \\
s_3    &amp; V_3'=(1, 2, 5) &amp; E_3'=\{(1,2)\}&amp;\\
s_4    &amp; V_4'=(1, 3, 4) &amp; E_4'=\{(1,3),(1,4)\}&amp; \checkmark\\
s_5    &amp; V_5'=(1, 3, 5) &amp; E_5'=\{(1,3)\}&amp;\\
s_6    &amp; V_6'=(1, 4, 5) &amp; E_6'=\{(1,4),(1,5)\}&amp; \checkmark\\
s_7    &amp; V_7'=(2, 3, 4) &amp; E_7'=\emptyset &amp;\\
s_8    &amp; V_8'=(2, 3, 5) &amp; E_8'=\emptyset &amp;\\
s_9    &amp; V_9'=(2, 4, 5) &amp; E_9'=\{(4,5)\} &amp;\\
s_{10} &amp; V_{10}'=(3, 4, 5) &amp; E_{10}'=\{(4,5)\} &amp;\\
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<strong>b)</strong> We have that only subgraphs <span class="math notranslate nohighlight">\(s_1\)</span>, <span class="math notranslate nohighlight">\(s_2\)</span>, <span class="math notranslate nohighlight">\(s_4\)</span> and  <span class="math notranslate nohighlight">\(s_6\)</span> can accomodate the full graph <span class="math notranslate nohighlight">\(X\)</span>. In graph theory we say that these subgraphs are <strong>isomorphic</strong> to <span class="math notranslate nohighlight">\(Y\)</span>. Note that each of these subgraphs leads to <span class="math notranslate nohighlight">\(2\)</span> MCS assignments in the injection table above:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
V_1'&amp;=(1,2,3)\rightarrow f_2=[(a,2),(b,1),(c,3)],\; f_4=[(a,3),(b,1),(c,2)]\\
V_2'&amp;=(1,2,4)\rightarrow f_3=[(a,2),(b,1),(c,4)],\; f_6=[(a,4),(b,1),(c,2)]\\
V_4'&amp;=(1,3,4)\rightarrow f_5=[(a,3),(b,1),(c,4)],\; f_7=[(a,4),(b,1),(c,3)]\\
V_6'&amp;=(1,4,5)\rightarrow f_1=[(a,1),(b,4),(c,5)],\; f_5=[(a,5),(b,4),(c,1)]\\
\end{aligned}
\)</span>
</span>
<br></br></p>
</section>
<section id="rectangle-rule-cost-function">
<h3><span class="section-number">2.2.2. </span>Rectangle rule: Cost Function<a class="headerlink" href="#rectangle-rule-cost-function" title="Permalink to this heading">#</a></h3>
<p>So far, solving MCS revolves around the idea of <span style="color:#f88146"><strong>maximizing the number of pairwise matchings</strong></span> between graphs <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<p>For a human, is quite clear to adopt a <em>greedy strategy</em>:</p>
<ol class="arabic simple">
<li><p>Identify notable vertices in <span class="math notranslate nohighlight">\(V\)</span> and <span class="math notranslate nohighlight">\(V'\)</span>.</p></li>
<li><p>For each matching pair between notable nodes:</p></li>
</ol>
<ul class="simple">
<li><p>Extend the matching pairs to neighbors.</p></li>
<li><p>Increment the number of rectables accordingly.</p></li>
</ul>
<p>Machines need a more precise specification. Maximizing the number of rectangles, however, arises from the following procedure:</p>
<p><em>Given <span class="math notranslate nohighlight">\(a\in V\)</span> and <span class="math notranslate nohighlight">\(i\in V'\)</span>, a rectangle appears if:</em></p>
<ol class="arabic simple">
<li><p><em>We match <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(i\)</span></em></p></li>
<li><p><em>We match <span class="math notranslate nohighlight">\(b\)</span> and <span class="math notranslate nohighlight">\(j\)</span>, which are respective neighbors of <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(i\)</span>: <span class="math notranslate nohighlight">\(b\in {\cal N}_a\)</span> and <span class="math notranslate nohighlight">\(j\in {\cal N}_i\)</span>.</em></p></li>
</ol>
<p>In other words, a rectangle happens when we match two nodes and their respective neighbors do also match. This is exacly why we prefer pairwise matchings between notable vertices: because they are more likely to produce more rectangles.</p>
<p>This rationale leads to the <span style="color:#f88146"><strong>second-order flavor</strong></span> of MCS, also known as <span style="color:#f88146"><strong>Graph Matching</strong></span> inside the Pattern Recognition community. Indeed, posing the problem in matricial terms, we have:</p>
<ul class="simple">
<li><p>The adjacency matrices <span class="math notranslate nohighlight">\(\mathbf{X}\in\{0,1\}^{m\times m}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Y}\in\{0,1\}^{n\times n}\)</span> of graphs <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>.</p></li>
<li><p>The unknown <span style="color:#f88146"><strong>matching matrix</strong></span> <span class="math notranslate nohighlight">\(\mathbf{M}\in\{0,1\}^{n\times m}\)</span>, where <span class="math notranslate nohighlight">\(\mathbf{M}_{ia}=1\)</span> means that <span class="math notranslate nohighlight">\(i\in V\)</span> matches <span class="math notranslate nohighlight">\(a\in V'\)</span>.</p></li>
</ul>
<p>Therefore, a rectagle exists if <em>its four sides do exist</em>, i.e. if</p>
<div class="math notranslate nohighlight">
\[
\exists a,b\in V, \exists i,j\in V':\; \mathbf{M}_{ai}\mathbf{M}_{bj}\mathbf{X}_{ab}\mathbf{Y}_{ij}&gt;0\;,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{X}_{ab}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Y}_{ij}\)</span> encode the respective neighboring rules (sides of the rectangle) as we show in <a class="reference internal" href="#rectangle"><span class="std std-numref">Fig. 2.5</span></a>.</p>
<figure class="align-center" id="rectangle">
<a class="reference internal image-reference" href="_images/Rectangle-Photoroom.png"><img alt="_images/Rectangle-Photoroom.png" src="_images/Rectangle-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.5 </span><span class="caption-text">The Rectangle Rule in Graph Matching.</span><a class="headerlink" href="#rectangle" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><strong>Quadratic Cost function</strong>. A function that counts the number of rectangles given by a matching matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is simply:</p>
<div class="math notranslate nohighlight">
\[
F(\mathbf{M}) = \frac{1}{2}\sum_{a\in V}\sum_{i\in V'}\sum_{b\in V}\sum_{j\in V'}\mathbf{M}_{ai}\mathbf{M}_{bj}\mathbf{X}_{ab}\mathbf{Y}_{ij}\;,
\]</div>
<p>where <span class="math notranslate nohighlight">\(1/2\)</span> factor removes rectangles counted twice (see the explanation to follow).</p>
<p>Consider for instance the graphs <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> in the previous section (see <a class="reference internal" href="#matching"><span class="std std-numref">Fig. 2.3</span></a>). Let us count the number of rectangles por a particular matching using the matricial formulation and the above function.</p>
<p>Firstly, we have the adjacency matrices</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbf{X} = 
\begin{array}{l}
a\\
b\\
c\\
\end{array}
\begin{bmatrix}
0 &amp; 1 &amp; 0 \\
1 &amp; 0 &amp; 1 \\
0 &amp; 1 &amp; 0 \\
\end{bmatrix}
\;\; 
\mathbf{Y} = 
\begin{array}{l}
1\\
2\\
3\\
4\\
5\\
\end{array}
\begin{bmatrix}
0 &amp; 1 &amp; 1 &amp; 1 &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
\end{bmatrix}
\end{align}
\end{split}\]</div>
<p>The matching matrix for the assignment in <a class="reference internal" href="#matching2"><span class="std std-numref">Fig. 2.4</span></a> is given by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbf{M} = 
\begin{array}{l}
a\\
b\\
c\\
\end{array}
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
\end{bmatrix}
\;\;\text{where}\;\;
\mathbf{M}^T = 
\begin{array}{l}
1\\
2\\
3\\
4\\
5\\
\end{array}
\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\end{align}
\end{split}\]</div>
<p>Let us fix the matricial version of <span class="math notranslate nohighlight">\(F(\mathbf{M})\)</span>.</p>
<ol class="arabic simple">
<li><p><strong>Mapping</strong>. We commence by analyzing the product <span class="math notranslate nohighlight">\(\mathbf{X}\mathbf{M}\)</span> which maps the nodes in <span class="math notranslate nohighlight">\(X\)</span> to those in <span class="math notranslate nohighlight">\(Y\)</span> via the matching matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span>:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
(\mathbf{X}\mathbf{M})_{ai} = \mathbf{X}_{a:}\mathbf{M}_{:i} = \sum_{a}\sum_{b}\mathbf{X}_{ab}\mathbf{M}_{bi}
\]</div>
<p>In our example:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{X}\mathbf{M} = 
\begin{array}{l}
a\\
b\\
c\\
\end{array}
\begin{bmatrix}
0 &amp; 1 &amp; 0 \\
1 &amp; 0 &amp; 1 \\
0 &amp; 1 &amp; 0 \\
\end{bmatrix}
\cdot
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
\end{bmatrix}
=
\begin{bmatrix}
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
\end{bmatrix}
\end{split}\]</div>
<p>Each column of <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> has <em>at most</em> one <span class="math notranslate nohighlight">\(1\)</span>, we have:</p>
<div class="math notranslate nohighlight">
\[
(\mathbf{X}\mathbf{M})_{ai} = \mathbf{X}_{ab^{\ast}}\mathbf{M}_{b^{\ast}i}
\]</div>
<p>where <span class="math notranslate nohighlight">\(b^{\ast}\in {\cal N}_a\)</span> is the neighbor of <span class="math notranslate nohighlight">\(a\)</span> that matches <span class="math notranslate nohighlight">\(i\)</span>, if any. Therefore:</p>
<div class="math notranslate nohighlight">
\[
(\mathbf{X}\mathbf{M})_{ai} = \mathbf{X}_{ab^{\ast}}\mathbf{M}_{b^{\ast}i}=1\Rightarrow \exists\; \text{path}\; a\rightarrow b^{\ast}\rightarrow i\in {\cal M}\;,
\]</div>
<p>where <span class="math notranslate nohighlight">\({\cal M}\)</span> is the <span style="color:#f88146"><strong>matching graph</strong></span> (includes links of <span class="math notranslate nohighlight">\(X\)</span>, <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(M\)</span> as in <a class="reference internal" href="#matching2"><span class="std std-numref">Fig. 2.4</span></a>).</p>
<p>Therefore, <span class="math notranslate nohighlight">\(\mathbf{X}\mathbf{M}\)</span> has the following paths in <span class="math notranslate nohighlight">\({\cal M}\)</span> (one per each <span class="math notranslate nohighlight">\(1\)</span> in the matrix):</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
(\mathbf{X}\mathbf{M})_{a4}&amp;=a\rightarrow b\rightarrow 4\\
(\mathbf{X}\mathbf{M})_{b1}&amp;=b\rightarrow a\rightarrow 1\\
(\mathbf{X}\mathbf{M})_{b5}&amp;=b\rightarrow c\rightarrow 5\\
(\mathbf{X}\mathbf{M})_{c4}&amp;=c\rightarrow b\rightarrow 4\\
\end{align}
\end{split}\]</div>
<p>For instance, we show the above paths in <a class="reference internal" href="#mpaths1"><span class="std std-numref">Fig. 2.6</span></a> and <a class="reference internal" href="#mpaths2"><span class="std std-numref">Fig. 2.7</span></a>.</p>
<figure class="align-center" id="mpaths1">
<a class="reference internal image-reference" href="_images/MatchingPaths1-Photoroom.png"><img alt="_images/MatchingPaths1-Photoroom.png" src="_images/MatchingPaths1-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.6 </span><span class="caption-text">Matching paths <span class="math notranslate nohighlight">\(b\rightarrow a\rightarrow 1\)</span> and <span class="math notranslate nohighlight">\(b\rightarrow c\rightarrow 5\)</span>.</span><a class="headerlink" href="#mpaths1" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-center" id="mpaths2">
<a class="reference internal image-reference" href="_images/MatchingPaths2-Photoroom.png"><img alt="_images/MatchingPaths2-Photoroom.png" src="_images/MatchingPaths2-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.7 </span><span class="caption-text">Matching paths <span class="math notranslate nohighlight">\(a\rightarrow b\rightarrow 4\)</span> and <span class="math notranslate nohighlight">\(c\rightarrow b\rightarrow 4\)</span>.</span><a class="headerlink" href="#mpaths2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ol class="arabic simple" start="2">
<li><p><strong>Paths</strong>. We continue by analyzing the product <span class="math notranslate nohighlight">\((\mathbf{X}\mathbf{M})\mathbf{Y}\)</span>. Intuition: since <span class="math notranslate nohighlight">\(\mathbf{X}\mathbf{M}\)</span> provides paths in <span class="math notranslate nohighlight">\({\cal M}\)</span> between adjacent nodes in <span class="math notranslate nohighlight">\(X\)</span> and then crosses through the matching <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> reaching nodes in <span class="math notranslate nohighlight">\(Y\)</span>, the product <span class="math notranslate nohighlight">\((\mathbf{X}\mathbf{M})\mathbf{Y}\)</span> just <em>continues these paths</em>: some of them will end in <span class="math notranslate nohighlight">\(Y\)</span> <em>defining <span class="math notranslate nohighlight">\(3/4\)</span> sides of a rectangle</em> (see below) and some others just travel through <span class="math notranslate nohighlight">\(Y\)</span> without defining any rectangle.</p></li>
</ol>
<p>In our example:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
(\mathbf{X}\mathbf{M})\mathbf{Y} = 
\begin{array}{l}
a\\
b\\
c\\
\end{array}
\begin{bmatrix}
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
\end{bmatrix}
\cdot\;
\begin{array}{l}
1\\
2\\
3\\
4\\
5\\
\end{array}
\begin{bmatrix}
0 &amp; 1 &amp; 1 &amp; 1 &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
\end{bmatrix} = 
\begin{bmatrix}
\mathbf{1} &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
0 &amp; 1 &amp; 1 &amp; \mathbf{2} &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; \mathbf{1}\\
\end{bmatrix}
\end{split}\]</div>
<p>Then, the following paths <strong>do</strong> form <span class="math notranslate nohighlight">\(3/4\)</span> of a rectangle (in bold in <span class="math notranslate nohighlight">\((\mathbf{X}\mathbf{M})\mathbf{Y}\)</span>):</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
((\mathbf{X}\mathbf{M})\mathbf{Y})_{a1} &amp;= a\rightarrow b\rightarrow 4\rightarrow 1\\
((\mathbf{X}\mathbf{M})\mathbf{Y})_{b4} &amp;= b\rightarrow a\rightarrow 1\rightarrow 4 + b\rightarrow c\rightarrow 5\rightarrow 4\\
((\mathbf{X}\mathbf{M})\mathbf{Y})_{a1} &amp;= a\rightarrow b\rightarrow 4\rightarrow 1\\
\end{align}
\end{split}\]</div>
<p>where it is significant the <span class="math notranslate nohighlight">\(2\)</span> paths of <span class="math notranslate nohighlight">\(((\mathbf{X}\mathbf{M})\mathbf{Y})_{b4}\)</span> between nodes <span class="math notranslate nohighlight">\(b\in V\)</span> and <span class="math notranslate nohighlight">\(4\in V'\)</span> (see <a class="reference internal" href="#mpaths3"><span class="std std-numref">Fig. 2.8</span></a>):</p>
<figure class="align-center" id="mpaths3">
<a class="reference internal image-reference" href="_images/MatchingPaths3-Photoroom.png"><img alt="_images/MatchingPaths3-Photoroom.png" src="_images/MatchingPaths3-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.8 </span><span class="caption-text">Two <span class="math notranslate nohighlight">\(3/4\)</span> matching paths <span class="math notranslate nohighlight">\(b\rightarrow a\rightarrow 1\rightarrow 4\)</span> and <span class="math notranslate nohighlight">\(b\rightarrow c\rightarrow 5\rightarrow 4\)</span>.</span><a class="headerlink" href="#mpaths3" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>On the other hand, theses other paths <strong>do not</strong> form <span class="math notranslate nohighlight">\(3/4\)</span> of a rectangle:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
((\mathbf{X}\mathbf{M})\mathbf{Y})_{a5} &amp;= a\rightarrow b\rightarrow 4\rightarrow 5\\
((\mathbf{X}\mathbf{M})\mathbf{Y})_{b2} &amp;= b\rightarrow a\rightarrow 1\rightarrow 2\\
((\mathbf{X}\mathbf{M})\mathbf{Y})_{b3} &amp;= b\rightarrow a\rightarrow 1\rightarrow 3\\
((\mathbf{X}\mathbf{M})\mathbf{Y})_{c1} &amp;= c\rightarrow b\rightarrow 4\rightarrow 1\\
\end{align}
\end{split}\]</div>
<p>For instance, paths <span class="math notranslate nohighlight">\(a\gg b\rightarrow 4\gg 5\)</span> and <span class="math notranslate nohighlight">\(c\gg b\rightarrow 4\gg 1\)</span> diverge from rectangles
where the notation <span class="math notranslate nohighlight">\(\gg\)</span> denotes the first and last edges of the paths (see <a class="reference internal" href="#mpaths4"><span class="std std-numref">Fig. 2.9</span></a>).</p>
<figure class="align-center" id="mpaths4">
<a class="reference internal image-reference" href="_images/MPaths4-Photoroom.png"><img alt="_images/MPaths4-Photoroom.png" src="_images/MPaths4-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.9 </span><span class="caption-text">Paths <span class="math notranslate nohighlight">\(a\gg b\rightarrow 4\gg 5\)</span> and <span class="math notranslate nohighlight">\(c\gg b\rightarrow 4\gg 1\)</span> diverge from rectangles.</span><a class="headerlink" href="#mpaths4" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Similarly, paths <span class="math notranslate nohighlight">\(b\gg a\rightarrow 1\gg 2\)</span> and <span class="math notranslate nohighlight">\(b\gg a\rightarrow 1\gg 3\)</span> diverge even more clearly from ending up in rectangles (see <a class="reference internal" href="#mpaths5"><span class="std std-numref">Fig. 2.10</span></a>).</p>
<figure class="align-center" id="mpaths5">
<a class="reference internal image-reference" href="_images/MPaths5-Photoroom.png"><img alt="_images/MPaths5-Photoroom.png" src="_images/MPaths5-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.10 </span><span class="caption-text">Remaining diverging paths in <span class="math notranslate nohighlight">\({\cal M}\)</span>.</span><a class="headerlink" href="#mpaths5" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ol class="arabic simple" start="3">
<li><p><strong>Closing rectangles</strong>. Once we have <span class="math notranslate nohighlight">\((\mathbf{X}\mathbf{M})\mathbf{Y}\)</span> we simply perform a <em>pointwise</em> multiplication (Hadamard product) to close the rectangle:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
((\mathbf{X}\mathbf{M})\mathbf{Y})\odot \mathbf{M}\;.
\]</div>
<p>In our example:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
((\mathbf{X}\mathbf{M})\mathbf{Y})\odot \mathbf{M} = 
\begin{bmatrix}
\mathbf{1} &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
0 &amp; 1 &amp; 1 &amp; \mathbf{2} &amp; 0\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; \mathbf{1}\\
\end{bmatrix}\odot 
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
\end{bmatrix} = 
\begin{bmatrix}
\mathbf{1} &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; \mathbf{2} &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; \mathbf{1}\\
\end{bmatrix}
\end{split}\]</div>
<p>Note that <span class="math notranslate nohighlight">\(a\)</span> closes <span class="math notranslate nohighlight">\(1\)</span> rectangle, <span class="math notranslate nohighlight">\(c\)</span> closes <span class="math notranslate nohighlight">\(1\)</span> and <span class="math notranslate nohighlight">\(b\)</span> closes <span class="math notranslate nohighlight">\(2\)</span> (one for <span class="math notranslate nohighlight">\(a\)</span> and another one for <span class="math notranslate nohighlight">\(c\)</span>). Therefore the multiplication <span class="math notranslate nohighlight">\(((\mathbf{X}\mathbf{M})\mathbf{Y})\odot \mathbf{M}\)</span> simply <strong>filters out</strong> impossible rectangles. The result is in <a class="reference internal" href="#mpaths6"><span class="std std-numref">Fig. 2.11</span></a>.</p>
<figure class="align-center" id="mpaths6">
<a class="reference internal image-reference" href="_images/MPaths6-Photoroom.png"><img alt="_images/MPaths6-Photoroom.png" src="_images/MPaths6-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.11 </span><span class="caption-text">Final rectangles in <span class="math notranslate nohighlight">\({\cal M}\)</span>.</span><a class="headerlink" href="#mpaths6" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ol class="arabic simple" start="4">
<li><p><strong>Counting</strong>. Note that the number of rectangles comes naturally from</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
F(\mathbf{M}) = \frac{1}{2}\sum_{a}\sum_{i}(((\mathbf{X}\mathbf{M})\mathbf{Y})\odot \mathbf{M})_{ai}\;,
\]</div>
<p>which is <span class="math notranslate nohighlight">\(2\)</span> in this case, as expected! Let us review these concepts in the following exercise:</p>
<p><br></br>
<span style="color:#d94f0b">
<strong>Exercise</strong>. Given the following graphs <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
&amp;\begin{array}{cll}
\text{Graph}  &amp; \text{Nodes} &amp; \text{Edges}\\
X &amp; V=\{a,b,c\} &amp; E=\{(a,b),(b,c)\}\\
Y &amp; V'=\{1,2,3,4,5\} &amp; E=\{(1,2),(1,3),(2,4),(3,4),(1,5),(2,5)\}\\
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<strong>a)</strong> Draw them so that the assignment <span class="math notranslate nohighlight">\(f=[(a,1),(b,2),(c,3)]\)</span> is clearly visisble. Is <span class="math notranslate nohighlight">\(X\)</span> a subgraph of <span class="math notranslate nohighlight">\(Y\)</span>? If so, what is the maximal number of rectangles to close in <span class="math notranslate nohighlight">\({\cal M}(f^{\ast})\)</span> and find an optimal assignment <span class="math notranslate nohighlight">\(f^{\ast}\)</span>.
</span>
<br></br></p>
<figure class="align-center" id="mini">
<a class="reference internal image-reference" href="_images/MiniMatch-Photoroom.png"><img alt="_images/MiniMatch-Photoroom.png" src="_images/MiniMatch-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.12 </span><span class="caption-text">Matching graph <span class="math notranslate nohighlight">\({\cal M}\)</span> for <span class="math notranslate nohighlight">\(f=[(a,1),(b,2),(c,3)]\)</span>.</span><a class="headerlink" href="#mini" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><br></br>
<span style="color:#d94f0b">
In <a class="reference internal" href="#mini"><span class="std std-numref">Fig. 2.12</span></a>, we show a 3D projection of both graphs where the assignment is clearly visible. Clearly, <span class="math notranslate nohighlight">\(X\)</span> is a subgraph of <span class="math notranslate nohighlight">\(Y\)</span>. As a result, we can map all vertices and edges of <span class="math notranslate nohighlight">\(X\)</span> to <span class="math notranslate nohighlight">\(Y\)</span>, closing at most <span class="math notranslate nohighlight">\(3\)</span> rectangles.
</span>
<br></br>
<span style="color:#d94f0b">
<strong>b)</strong> Is that optimal assignment unique? Compute the maximum number of rectangles by matricially evaluating <span class="math notranslate nohighlight">\(M^{\ast}\)</span>, the matching matrix corresponding to an optimal assignment. Indicate the <strong>matching paths</strong> in each step.
</span>
<br></br>
<span style="color:#d94f0b">
In this case the optimal assignment is unique: it comes from matching the notable vertices between both graphs and it is <span class="math notranslate nohighlight">\(f=[(a,1),(b,2),(c,5)]\)</span> since this is the only way to embed <span class="math notranslate nohighlight">\(X\)</span> in <span class="math notranslate nohighlight">\(Y\)</span> completely (see <a class="reference internal" href="#mini2"><span class="std std-numref">Fig. 2.13</span></a>).
</span>
<br></br></p>
<figure class="align-center" id="mini2">
<a class="reference internal image-reference" href="_images/MiniMatch2-Photoroom.png"><img alt="_images/MiniMatch2-Photoroom.png" src="_images/MiniMatch2-Photoroom.png" style="width: 600px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.13 </span><span class="caption-text">Matching graph <span class="math notranslate nohighlight">\({\cal M}\)</span> for <span class="math notranslate nohighlight">\(f=[(a,1),(b,2),(c,5)]\)</span>.</span><a class="headerlink" href="#mini2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><br></br>
<span style="color:#d94f0b">
Matricially, we have
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
\mathbf{X} = 
\begin{array}{l}
a\\
b\\
c\\
\end{array}
\begin{bmatrix}
0 &amp; 1 &amp; 1 \\
1 &amp; 0 &amp; 1 \\
1 &amp; 1 &amp; 0 \\
\end{bmatrix}
\;\; 
\mathbf{Y} = 
\begin{array}{l}
1\\
2\\
3\\
4\\
5\\
\end{array}
\begin{bmatrix}
0 &amp; 1 &amp; 1 &amp; 0 &amp; 1\\
1 &amp; 0 &amp; 0 &amp; 1 &amp; 1\\
1 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 1 &amp; 1 &amp; 0 &amp; 0\\
1 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\
\end{bmatrix}
\;\;\text{and}\;\;
\mathbf{M}^{\ast} = \begin{array}{l}
a\\
b\\
c\\
\end{array}
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Then, we proceed to evaluate
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
F(\mathbf{M}^{\ast}) = \frac{1}{2}\sum_{a}\sum_{i}(((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})\odot \mathbf{M}^{\ast})_{ai}\;,
 \)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<strong>Step 1:</strong> Compute <span class="math notranslate nohighlight">\(\mathbf{X}\mathbf{M}^{\ast}\)</span>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
\mathbf{X}\mathbf{M}^{\ast} = 
\begin{array}{l}
a\\
b\\
c\\
\end{array}
\begin{bmatrix}
0 &amp; 1 &amp; 1 \\
1 &amp; 0 &amp; 1 \\
1 &amp; 1 &amp; 0 \\
\end{bmatrix}
\;\cdot \;
\begin{array}{l}
a\\
b\\
c\\
\end{array}
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix} = 
\begin{bmatrix}
0 &amp; 1 &amp; 0 &amp; 0 &amp; 1\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
1 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\
\end{bmatrix}
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
And the paths so far are:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
(\mathbf{X}\mathbf{M}^{\ast})_{a2} &amp;= a\rightarrow b\rightarrow 2\\
(\mathbf{X}\mathbf{M}^{\ast})_{a5} &amp;= a\rightarrow c\rightarrow 5\\
(\mathbf{X}\mathbf{M}^{\ast})_{b1} &amp;= b\rightarrow a\rightarrow 1\\
(\mathbf{X}\mathbf{M}^{\ast})_{b5} &amp;= b\rightarrow c\rightarrow 5\\
(\mathbf{X}\mathbf{M}^{\ast})_{c1} &amp;= c\rightarrow a\rightarrow 1\\
(\mathbf{X}\mathbf{M}^{\ast})_{c2} &amp;= c\rightarrow b\rightarrow 2\\
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<strong>Step 2:</strong> Compute <span class="math notranslate nohighlight">\((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y}\)</span>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
(\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y} = 
\begin{array}{l}
a\\
b\\
c\\
\end{array}
\begin{bmatrix}
0 &amp; 1 &amp; 0 &amp; 0 &amp; 1\\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
1 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\
\end{bmatrix}
\cdot\; 
\begin{array}{l}
1\\
2\\
3\\
4\\
5\\
\end{array}
\begin{bmatrix}
0 &amp; 1 &amp; 1 &amp; 0 &amp; 1\\
1 &amp; 0 &amp; 0 &amp; 1 &amp; 1\\
1 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 1 &amp; 1 &amp; 0 &amp; 0\\
1 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\
\end{bmatrix} = 
\begin{bmatrix}
2 &amp; 1 &amp; 0 &amp; 1 &amp; 1\\
1 &amp; 2 &amp; 1 &amp; 0 &amp; 1\\
1 &amp; 1 &amp; 1 &amp; 1 &amp; 2\\
\end{bmatrix}
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
And the <span class="math notranslate nohighlight">\(3/4\)</span>-rectangle paths are:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{a1} &amp;= a\rightarrow b\rightarrow 2\rightarrow 1 + a\rightarrow  c\rightarrow 5\rightarrow 1\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{a2} &amp;= a\rightarrow c\rightarrow 5\rightarrow 2\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{a4} &amp;= a\rightarrow b\rightarrow 2\rightarrow 4\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{a5} &amp;= a\rightarrow b\rightarrow 2\rightarrow 5\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{b1} &amp;= b\rightarrow c\rightarrow 5\rightarrow 1\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{b2} &amp;= b\rightarrow a\rightarrow 1\rightarrow 2 + 
b\rightarrow c\rightarrow 5\rightarrow 2\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{b3} &amp;= b\rightarrow a\rightarrow 1\rightarrow 3\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{b5} &amp;= b\rightarrow a\rightarrow 1\rightarrow 5\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{c1} &amp;= c\rightarrow b\rightarrow 2\rightarrow 1\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{c2} &amp;= c\rightarrow a\rightarrow 1\rightarrow 2\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{c3} &amp;= c\rightarrow a\rightarrow 1\rightarrow 3\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{c4} &amp;= c\rightarrow b\rightarrow 2\rightarrow 4\\
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})_{c5} &amp;= c\rightarrow a\rightarrow 1\rightarrow 5 + 
c\rightarrow b\rightarrow 2\rightarrow 5\\
\end{align}
\)</span>
</span>
<br><br>
<span style="color:#d94f0b">
<strong>Step 3</strong>. We higlight the correct matches and apply Hadamard product:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
((\mathbf{X}\mathbf{M}^{\ast})\mathbf{Y})\odot \mathbf{M}^{\ast} = 
\begin{bmatrix}
\mathbf{2} &amp; 1 &amp; 0 &amp; 1 &amp; 1\\
1 &amp; \mathbf{2} &amp; 1 &amp; 0 &amp; 1\\
1 &amp; 1 &amp; 1 &amp; 1 &amp; \mathbf{2}\\
\end{bmatrix}
\odot\; 
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Finally, if we sum all the components of the Hadamard product and divide by <span class="math notranslate nohighlight">\(2\)</span> we have <span class="math notranslate nohighlight">\(3\)</span> rectangles as shown in <a class="reference internal" href="#mini2"><span class="std std-numref">Fig. 2.13</span></a>. We are done!
</span></p>
</section>
<section id="integer-constraints-qap">
<h3><span class="section-number">2.2.3. </span>Integer Constraints: QAP<a class="headerlink" href="#integer-constraints-qap" title="Permalink to this heading">#</a></h3>
<p>We have clarified an objective function of MCS (graph matching) <span class="math notranslate nohighlight">\(F(\mathbf{M})\)</span> interpretation for a particular <span class="math notranslate nohighlight">\(\mathbf{M}\in\{0,1\}^{n\times m}\)</span> (number of rectangles). The function is <span style="color:#f88146"><strong>quadratic</strong> in <span class="math notranslate nohighlight">\(\mathbf{M}\)</span></span> since it requires two multiplications of the matching matrix for its evaluation, but evaluating it takes <span class="math notranslate nohighlight">\(O(n^4)\)</span>.</p>
<p>In addition, the structure of <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is not simply binary. Since each candidate assignment <span class="math notranslate nohighlight">\(f\)</span> encoded by this matrix must be an injective (one-to-one) function <span class="math notranslate nohighlight">\(f:V\rightarrow V'\)</span> we have that for <span class="math notranslate nohighlight">\(m\le n\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\forall a\in V:\sum_{i\in V'}\mathbf{M}_{ai}\le 1\;\text{and}\; \forall i\in V':\sum_{a\in V}\mathbf{M}_{ai}\le 1\;,
\]</div>
<p>i.e. each row/column cannot have more than one <span class="math notranslate nohighlight">\(1\)</span>. Some precisions:</p>
<ul class="simple">
<li><p>Formally, all row/column may be all-zeros but if they are, then we do not have a solution.</p></li>
<li><p>In particular, we need to match a coumple of vertices to close a single rectangle. Therefore we need at least to columns with a single one placed in different rows.</p></li>
<li><p>Thus, the above notation means that if one row/column is all-zeros there is only one of them which is not!</p></li>
<li><p>Ideally, for <span class="math notranslate nohighlight">\(m\le n\)</span> we should have <span class="math notranslate nohighlight">\(m\)</span> columns with a <span class="math notranslate nohighlight">\(1\)</span> all placed in different rows.</p></li>
</ul>
<p>This constrained nature of the so called <span style="color:#f88146"><strong>Quadratic Assignment Problem (QAP)</strong></span> is what makes it NP:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbf{M}^{\ast}= &amp; \arg\max_{{\cal P}}F(\mathbf{M}) = \frac{1}{2}\sum_{a\in V}\sum_{i\in V'}\sum_{b\in V}\sum_{j\in V'}\mathbf{M}_{ai}\mathbf{M}_{bj}\mathbf{X}_{ab}\mathbf{Y}_{ij}\\
{\cal P}=&amp;\left\{\mathbf{M}\in \{0,1\}^{m\times n}:\forall a\in V:\sum_{i\in V'}\mathbf{M}_{ai}\le 1\;\text{and}\; \forall i\in V':\sum_{a\in V}\mathbf{M}_{ai}\le 1\;\right\}
\end{align}
\end{split}\]</div>
<p>Therefore, the QAP (we use this name in the following) is originally posed in terms of <span style="color:#f88146"><strong>Integer Programming (IP)</strong></span>
since the <em>unknowns</em> to discover are binary <span class="math notranslate nohighlight">\(m\times n\)</span> matrices <span class="math notranslate nohighlight">\(\mathbf{M}\in\{0,1\}^{m\times n}\)</span> subject to be in <span class="math notranslate nohighlight">\({\cal P}\)</span>.</p>
<p>In particular, if <span class="math notranslate nohighlight">\(m=n\)</span> (both graphs have the same number of nodes), then:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\({\cal P}\)</span> becomes <span class="math notranslate nohighlight">\(\Pi_n\)</span>, the space of <em>permutations</em> of order <span class="math notranslate nohighlight">\(n\)</span> and we have <span class="math notranslate nohighlight">\(n!\)</span> <em>bijections</em> <span class="math notranslate nohighlight">\(f=\pi:V\rightarrow V'\)</span>.</p></li>
<li><p>Each matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> encodes a permutation <span class="math notranslate nohighlight">\(\pi(a),\pi(b),\ldots\)</span>, where <span class="math notranslate nohighlight">\(V=\{a,b,\ldots\}\)</span> with <span class="math notranslate nohighlight">\(|V|=n\)</span> are the rows of <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> (each one with a unique <span class="math notranslate nohighlight">\(1\)</span> at different columns.</p></li>
<li><p>Then <span class="math notranslate nohighlight">\(V'=\{\pi(i):i\in\{a,b,c,\ldots\}\}\)</span> with <span class="math notranslate nohighlight">\(|V'|=n\)</span> and <span class="math notranslate nohighlight">\(\pi^{-1}(i)\in V\)</span> does exist and it is unique.</p></li>
</ul>
<p>More formally:</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
\Pi_n=&amp;\left\{\mathbf{M}\in \{0,1\}^{m\times n}:\forall a\in V:\sum_{i\in V'}\mathbf{M}_{ai}= 1\;\text{and}\; \forall i\in V':\sum_{a\in V}\mathbf{M}_{ai}= 1\;\right\}
\end{align}
\]</div>
<p>where we have transformed the inequality constraints into equality ones!</p>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Permutohedron">Permutohedron</a> is a useful means of visualizing the space of solutions <span class="math notranslate nohighlight">\(\Pi_n\)</span>. Each point is a permutation <span class="math notranslate nohighlight">\(\pi\)</span> and it has <span class="math notranslate nohighlight">\(n-1\)</span> neighbors. Given <span class="math notranslate nohighlight">\(\pi\)</span>, its neighboring permutations <span class="math notranslate nohighlight">\(\pi'\in {\cal N}_{\pi}\)</span> differ from <span class="math notranslate nohighlight">\(\pi\)</span> in <em>one transposition</em>, i.e. one interchange between two components.</p>
<p>For instance, in <a class="reference internal" href="#pin"><span class="std std-numref">Fig. 2.14</span></a> we show <span class="math notranslate nohighlight">\(\Pi_4\)</span>. It has <span class="math notranslate nohighlight">\(n!=24\)</span> nodes with <span class="math notranslate nohighlight">\(n-1=3\)</span> neighbors each. For instance, the neighbors of <span class="math notranslate nohighlight">\(\pi=[3,4,2,1]\)</span> are <span class="math notranslate nohighlight">\({\cal N}_{\pi}=\{[2,4,3,1],[3,4,1,2],[4,3,2,1]\}\)</span>, where  <span class="math notranslate nohighlight">\(\pi'=[2,4,3,1]\)</span> is the result of interchanging (transposing) <span class="math notranslate nohighlight">\(2\)</span> and <span class="math notranslate nohighlight">\(3\)</span> in <span class="math notranslate nohighlight">\(\pi=[3,4,2,1]\)</span>.</p>
<figure class="align-center" id="pin">
<a class="reference internal image-reference" href="_images/PiN-Photoroom.png"><img alt="_images/PiN-Photoroom.png" src="_images/PiN-Photoroom.png" style="width: 600px; height: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.14 </span><span class="caption-text">Permutohedron for of order <span class="math notranslate nohighlight">\(n=4\)</span>. Please define the unlabeled nodes.</span><a class="headerlink" href="#pin" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="simulated-annealing">
<h2><span class="section-number">2.3. </span>Simulated Annealing<a class="headerlink" href="#simulated-annealing" title="Permalink to this heading">#</a></h2>
<p>The Permutohedron provides a glimpse of the <span style="color:#f88146"><strong>discrete seach space</strong></span>, specially because it highlighs its topology, i.e. its local structure.</p>
<p>With this instrument to hand, it is natural to <span style="color:#f88146">envision <strong>intelligent search</strong> as a random walk between an initial permutation <span class="math notranslate nohighlight">\(\pi^0\)</span> and a final one <span class="math notranslate nohighlight">\(\pi^{\ast}\)</span></span>:</p>
<ul class="simple">
<li><p>The <em>intelligence</em> is partially provided by the <strong>objective function</strong> <span class="math notranslate nohighlight">\(F(\pi)\)</span> that discriminates between good and bad solutions.</p></li>
<li><p>The <em>search strategy</em> is what exploits the knowledge provided by the objective function. One of the simplest strategies is that of a <strong>random walk (RW)</strong> <span class="math notranslate nohighlight">\(\pi^0\rightarrow\pi^1\rightarrow\ldots\rightarrow \pi^{\ast}\)</span> inside <span class="math notranslate nohighlight">\(\Pi_n\)</span>.</p></li>
</ul>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Simulated_annealing">Simulated Annealing (SA)</a> is a principled way of combining intelligence and RW-search. It works as follows:</p>
<p>Let <span class="math notranslate nohighlight">\(\Omega\)</span> be the <strong>search space</strong> and <span class="math notranslate nohighlight">\(\omega\in \Omega\)</span> a <strong>discrete state</strong>, then we define a <strong>Markov chain</strong> <span class="math notranslate nohighlight">\(X_0,X_1,\ldots\)</span> for a <em>maximization problem</em> as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
p(X_{t+1}=\omega'|X_{t}=\omega) =
\begin{cases}
     1 &amp;\;\text{if}\; \Delta F\ge 0 \\[2ex]
     \exp(\beta(t)\cdot \Delta F)&amp;\;\text{otherwise}\\[2ex]
\end{cases}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\Delta F:=F(\omega')-F(\omega)\)</span> and <span class="math notranslate nohighlight">\(\beta(t):=\frac{1}{T(t)}\)</span> where <span class="math notranslate nohighlight">\(T\)</span> is the <strong>computational temperature</strong>. Some explanations:</p>
<ul class="simple">
<li><p>Since we are maximizing <span class="math notranslate nohighlight">\(F\)</span>, having <span class="math notranslate nohighlight">\(\Delta F:=F(\omega')-F(\omega)\ge 0\)</span> for <span class="math notranslate nohighlight">\(\omega'\in {\cal N}_{\omega}\)</span> means that <span class="math notranslate nohighlight">\(F(\omega')\ge F(\omega)\)</span>, i.e. that we are in the <em>correct way</em> (or at least not in the wrong way!). In this case, we should <strong>accept</strong> (with probability <span class="math notranslate nohighlight">\(1\)</span>) <span class="math notranslate nohighlight">\(\omega'\)</span> as the new state of the search.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(F(\omega')&lt; F(\omega)\)</span>, a <strong>greedy method</strong> or a <strong>branch-and-bound</strong> should reject <span class="math notranslate nohighlight">\(\omega'\)</span> as a promising direction. However, SA gives a <strong>chance of acceptance</strong> which is proportional to how far is <span class="math notranslate nohighlight">\(\omega'\)</span> of being promising, which is <span class="math notranslate nohighlight">\(\Delta F = F(\omega')-F(\omega)&lt; 0\)</span>.</p></li>
</ul>
<p>However, if <span class="math notranslate nohighlight">\(F(\omega')&lt; F(\omega)\)</span>, the chance of accepting <span class="math notranslate nohighlight">\(\omega'\)</span> must depend of the <strong>stage of the search process</strong> where we take the decision. This stage is parameterized by the computational temperature <span class="math notranslate nohighlight">\(\beta(t)=\frac{1}{T(t)}\)</span></p>
<p>Suppose that the computational temperature is <span class="math notranslate nohighlight">\(T(t)\)</span> is a <strong>monotonic decreasing function</strong> with <span class="math notranslate nohighlight">\(t\)</span> such as <span class="math notranslate nohighlight">\(T(t)=\frac{1}{\log(1+t)}\)</span>. This is why this is called an <strong>annealing schedule</strong> Then:</p>
<ul class="simple">
<li><p>At <span class="math notranslate nohighlight">\(t\rightarrow 0\)</span> (early stages of the search) the chance should be hight. Then, we usually set <span class="math notranslate nohighlight">\(T(0)\rightarrow\infty\)</span> (high temperature). As <span class="math notranslate nohighlight">\(\Delta F&lt;0\)</span>, then <span class="math notranslate nohighlight">\(\exp(\beta(t)\cdot \Delta F)\)</span> does not decays too much, since it is attenuated. As a result, solutions <span class="math notranslate nohighlight">\(\omega'\)</span> with <span class="math notranslate nohighlight">\(\Delta F&lt;0\)</span> are typically accepted if <span class="math notranslate nohighlight">\(|\Delta F&lt;0|\)</span> is small enough. The larger <span class="math notranslate nohighlight">\(|\Delta F&lt;0|\)</span> the more probable that <span class="math notranslate nohighlight">\(\omega'\)</span> is consider an <strong>extremal event</strong> (part of the queue of the exponential) and thus discarded.</p></li>
<li><p>However, for <span class="math notranslate nohighlight">\(t\rightarrow \infty\)</span>, we have <span class="math notranslate nohighlight">\(T(t)\rightarrow 0\)</span> (low temperature). The same decrement <span class="math notranslate nohighlight">\(|\Delta F&lt;0|\)</span> that was admissible for smaller values of <span class="math notranslate nohighlight">\(t\)</span> is not yet accepted because SA behaves like a greedy method.</p></li>
</ul>
<div class="proof algorithm admonition" id="Metropolis">
<p class="admonition-title"><span class="caption-number">Algorithm 2.1 </span> (Metropolis-Hastings)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inputs</strong> Given a function <span class="math notranslate nohighlight">\(F(\omega)\)</span>, an annealing schedule <span class="math notranslate nohighlight">\(T(t)\)</span> and an inital state <span class="math notranslate nohighlight">\(\omega_0\)</span><br />
<strong>Output</strong> <span class="math notranslate nohighlight">\(\omega^{\ast}=\arg\max_{\omega\in\Omega} F(\omega)\)</span></p>
<ol class="arabic simple">
<li><p>convegence = False</p></li>
<li><p><span class="math notranslate nohighlight">\(\omega_{old}\leftarrow \omega_0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(t\leftarrow 0\)</span></p></li>
<li><p><strong>while</strong> <span class="math notranslate nohighlight">\(\neg\)</span> convergence:</p>
<ol class="arabic simple">
<li><p>Select <span class="math notranslate nohighlight">\(\omega'\in {\cal N}_{\omega}\)</span></p></li>
<li><p>Calculate <span class="math notranslate nohighlight">\(\Delta F=F(\omega')-F(\omega_{old})\)</span></p></li>
<li><p><strong>if</strong> <span class="math notranslate nohighlight">\(\Delta F\ge 0\)</span> <strong>then</strong> <span class="math notranslate nohighlight">\(\omega_{new}\leftarrow \omega'\)</span></p></li>
<li><p><strong>else</strong>:</p>
<ol class="arabic simple">
<li><p>Draw <span class="math notranslate nohighlight">\(p\in [0,1]\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(q\leftarrow \exp\left(\frac{\Delta F}{T(t)}\right)\)</span></p></li>
<li><p><strong>if</strong> <span class="math notranslate nohighlight">\(q\ge p\)</span> <strong>then</strong> <span class="math notranslate nohighlight">\(\omega_{new}\leftarrow \omega'\)</span></p></li>
</ol>
</li>
<li><p><span class="math notranslate nohighlight">\(t\leftarrow t+1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(T(t)\leftarrow \frac{1}{\log(1 + t)}\)</span></p></li>
<li><p>convergence = <span class="math notranslate nohighlight">\((T(t)&lt;T_{min})\)</span> <strong>or</strong> <span class="math notranslate nohighlight">\((t&gt;t_{max})\)</span></p></li>
</ol>
</li>
<li><p><strong>return</strong> <span class="math notranslate nohighlight">\(\omega_{new}\)</span></p></li>
</ol>
</section>
</div><section id="approximating-qap-with-sa">
<h3><span class="section-number">2.3.1. </span>Approximating QAP with SA<a class="headerlink" href="#approximating-qap-with-sa" title="Permalink to this heading">#</a></h3>
<p>Let us apply SA to approximate the QAP. To that end, we are going to <strong>match the Aspirin’s structure</strong> (see <a class="reference internal" href="#sa-aspirin"><span class="std std-numref">Fig. 2.16</span></a>-Left) with a random permutation of its vertices (<a class="reference internal" href="#sa-aspirin"><span class="std std-numref">Fig. 2.16</span></a>-Right). The left graph with nodes <span class="math notranslate nohighlight">\(V=\{a,b,\ldots,m\}\)</span> and links, mimics the structure of the Aspirin. In this first approach we discard, for the moment, both nodes (atom) labels (<span class="math notranslate nohighlight">\(\text{C}\)</span>,<span class="math notranslate nohighlight">\(\text{O}\)</span> and <span class="math notranslate nohighlight">\(\text{OH}\)</span>) and edges (bonds) labels (single, double).</p>
<p>On the right, the graph has nodes <span class="math notranslate nohighlight">\(V'=\{1,2,\ldots,13\}\)</span>. Since <span class="math notranslate nohighlight">\(|V|=|V'|=13\)</span>, there <strong>state space</strong> <span class="math notranslate nohighlight">\(\Omega\)</span> is given by the <span class="math notranslate nohighlight">\(\Pi_{n=13}\)</span> Permutohedron, with  <span class="math notranslate nohighlight">\(n!\approx 6\times 10^{9}\)</span> states, each one with <span class="math notranslate nohighlight">\(n-1=12\)</span> edges.</p>
<p>We know that the optimal permutation <span class="math notranslate nohighlight">\(\pi^{\ast}\)</span> is given by <span class="math notranslate nohighlight">\(\pi^{\ast}(a)=1,\pi^{\ast}(b)=2,\ldots, \pi^{\ast}(m)=13\)</span>, i.e. <span class="math notranslate nohighlight">\(\mathbf{M}^{\ast}=\mathbf{I}_n\)</span> is the identity matrix of dimension <span class="math notranslate nohighlight">\(n\)</span>. However, we assume a realistic case where the input permutation <span class="math notranslate nohighlight">\(\pi^0\)</span> is rather different from the optimal one:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\pi^0 = 
\begin{bmatrix}
\overbrace{7}^a &amp; \overbrace{12}^b &amp; \overbrace{5}^{c} &amp; \overbrace{11}^{d} &amp; \overbrace{3}^e &amp; \overbrace{9}^f &amp; \overbrace{2}^g &amp; \overbrace{8}^h &amp; \overbrace{10}^i &amp; \overbrace{4}^j &amp; \overbrace{1}^k &amp; \overbrace{6}^l &amp; \overbrace{13}^m\\
\end{bmatrix}
\end{split}\]</div>
<p><strong>1) Initial Matching</strong>. However, instead of starting SA with a random <span class="math notranslate nohighlight">\(\pi^0\)</span>, it is a good practice to compute a <span style="color:#f88146"><strong>greedy approximation</strong></span>. In the case of graph matching or QAP, a greedy algorithm may rely on matching <span class="math notranslate nohighlight">\(a,b,c,\ldots\)</span> with nodes <span class="math notranslate nohighlight">\(1,2,3,\ldots\)</span> in such a way that it is <span style="color:#f88146"><em>preferred to match nodes with the largest number of neighbors (degree) as possible</em></span>.</p>
<p>Then, the greedy matching leads to</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\pi^0 = 
\begin{bmatrix}
\overbrace{3}^a &amp; \overbrace{4}^b &amp; \underline{\overbrace{5}^{c}} &amp; \overbrace{9}^{d} &amp; \underline{\overbrace{1}^e} &amp; \overbrace{6}^f &amp; \overbrace{8}^g &amp; \overbrace{10}^h &amp; \overbrace{12}^i &amp; \overbrace{2}^j &amp; \overbrace{7}^k &amp; \overbrace{10}^l &amp; \overbrace{13}^m\\
\end{bmatrix}
\end{split}\]</div>
<p>We check <a class="reference internal" href="#sa-aspirin"><span class="std std-numref">Fig. 2.16</span></a>, where we plot the <em>final approximation of SA</em> with <span class="math notranslate nohighlight">\(10\)</span> closing rectangles, that the greedy <span class="math notranslate nohighlight">\(\pi^0\)</span> is consistent with matching nodes with mutually largerst degrees:</p>
<ul class="simple">
<li><p>We underlined the matchings with largest degrees (maximum degree is <span class="math notranslate nohighlight">\(3\)</span>): <span class="math notranslate nohighlight">\(c\rightarrow 5\)</span>, <span class="math notranslate nohighlight">\(e\rightarrow 1\)</span>.</p></li>
<li><p>One of the risks of greedy matching is that we may be <strong>stuck in a local maximum</strong>, which really happens (SA here recovers from <span class="math notranslate nohighlight">\(e\rightarrow 1\)</span> but not from <span class="math notranslate nohighlight">\(c\rightarrow 5\)</span>).</p></li>
<li><p>However, the proper annealing scheduling typically <strong>takes the search out of local optima</strong> in the early stages of the search.</p></li>
</ul>
<p><strong>2) Neighboring</strong>. The second aspect to define when applying SA to the QAP is how to <span style="color:#f88146"><strong>ensure proper neighborhoods <span class="math notranslate nohighlight">\({\cal N}_{\omega}\)</span></strong></span>. In other words, if given <span class="math notranslate nohighlight">\(\omega\)</span> we choose as <span class="math notranslate nohighlight">\(\omega'\)</span> an arbitrarily large  random variation, we <em><span style="color:#f88146">may miss the irreducibility property of the Markov chain (all states must be reached)</em></span>.</p>
<p>Then, a good way of navigating properly through the search space (the Permutohedron <span class="math notranslate nohighlight">\(\Pi_n\)</span> in this case) is to:</p>
<ol class="arabic simple">
<li><p><strong>Choose</strong> randomly if we are going to interchange rows or colums in <span class="math notranslate nohighlight">\(\mathbf{M}_{\omega}\)</span>.</p></li>
<li><p><strong>Interchange</strong> two rows (or columns) whose indexes are randomly chosen. The result is <span class="math notranslate nohighlight">\(\mathbf{M}_{\omega'}\)</span></p></li>
</ol>
<p>This is <strong>equivalent</strong> to perform a transposition in the Permutohedron <span class="math notranslate nohighlight">\(\Pi_n\)</span>.</p>
<p><strong>3)Annealing Schedule</strong>. The last ingredient to set is a <span style="color:#f88146"><strong>proper temperature cooling (annealing schedule)</strong></span> and the specific values <span class="math notranslate nohighlight">\(T_0\)</span> and <span class="math notranslate nohighlight">\(T_f\)</span>.</p>
<ul class="simple">
<li><p>In this example, we simply make <span class="math notranslate nohighlight">\(T(t+1)=T(t)-\alpha\cdot T(t)=(1-\alpha)\cdot T(t)\)</span> with <span class="math notranslate nohighlight">\(\alpha\ll 1\)</span>.</p></li>
<li><p>This leads to a neg-exponential decrease since:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
T(1)&amp;=(1-\alpha)\cdot T(0)\\
T(2)&amp;=(1-\alpha)\cdot T(1)=(1-\alpha)^2\cdot T(0)\\
    &amp;\vdots\\
T(n)&amp;=(1-\alpha)\cdot T(n-1)=(1-\alpha)^n\cdot T(0)\\
\end{align}
\end{split}\]</div>
<p>This succession is decreasing since we only multiply <span class="math notranslate nohighlight">\(T(0)\)</span> by a decreasing fraction. Actually, we have set <span class="math notranslate nohighlight">\(T(0)=1/5=0.2\)</span> and <span class="math notranslate nohighlight">\(\alpha = 1/1.075\approx 0.93\)</span>. The exponential decrease can be seen by looking at the <strong>logarithmic transformation</strong> (exponentials are lines in log space):</p>
<div class="math notranslate nohighlight">
\[
T(n) = (1-\alpha)^n\cdot T(0)\Rightarrow \log(T(n))=n\cdot log(1-\alpha) + \log T(0)\;.
\]</div>
<p>Since <span class="math notranslate nohighlight">\((1-\alpha)&lt;1\)</span> then its log is negative!</p>
<p>This schedule is a <strong>bit agressive</strong> but playing a bit with <span class="math notranslate nohighlight">\(\alpha\)</span> we can close <span class="math notranslate nohighlight">\(10-11\)</span> rectangles from <span class="math notranslate nohighlight">\(13\)</span> possible (this is the mumber of edges of the Aspirin graph).</p>
<p>In <a class="reference internal" href="#sa-curves"><span class="std std-numref">Fig. 2.15</span></a> we play with different values of <span class="math notranslate nohighlight">\(\alpha\)</span>. For the sake of clarity, herein we only represent the <strong>best cost obtained so far</strong>. Note that for different regimes we get different results, in this case between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(11\)</span> rectangles. It is interesting to note that:</p>
<ul class="simple">
<li><p>The best result is obtained with one of the smallest <span class="math notranslate nohighlight">\(\alpha\)</span>s (<span class="math notranslate nohighlight">\(\alpha=0.85\)</span>)</p></li>
<li><p>The annealing schedules tend to increase more the objective function <span class="math notranslate nohighlight">\(F\)</span> in the early stages of the seach where SA is more free to explore!</p></li>
<li><p>Note that the most strict schedule (<span class="math notranslate nohighlight">\(\alpha=0.93\)</span>) reaches <span class="math notranslate nohighlight">\(9\)</span> rectangles in the middle stages and finaly peaks <span class="math notranslate nohighlight">\(10\)</span> rectangles. This is the solution showed in <a class="reference internal" href="#sa-aspirin"><span class="std std-numref">Fig. 2.16</span></a>.</p></li>
</ul>
<p>The right image shows the negligible differences betweeen the annealing schedules in the log-log domain.</p>
<figure class="align-center" id="sa-curves">
<a class="reference internal image-reference" href="_images/SA-Curves-Photoroom.png"><img alt="_images/SA-Curves-Photoroom.png" src="_images/SA-Curves-Photoroom.png" style="width: 800px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.15 </span><span class="caption-text">Playing with <span class="math notranslate nohighlight">\(\alpha\)</span> for different annealing schedules.</span><a class="headerlink" href="#sa-curves" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><strong>4)Understanding the solution</strong>. Last, but by no  means least, we have to interpret to what extent our <span class="math notranslate nohighlight">\(F\)</span> reaches or not an <em>interesting solution</em>. Herein, <span style="color:#f88146"><em>interesting means</em> <strong>global</strong></span>. For instance:</p>
<ul class="simple">
<li><p>The solution in <a class="reference internal" href="#sa-aspirin"><span class="std std-numref">Fig. 2.16</span></a> captures mainly the central hexagon, although under a rotation around the <span class="math notranslate nohighlight">\(g-i\)</span> axis and a flipping or torsion wrt the vertical: edge <span class="math notranslate nohighlight">\(f-e\)</span> becomes <span class="math notranslate nohighlight">\(8-10\)</span>, but edge <span class="math notranslate nohighlight">\(h-i\)</span> becomes <span class="math notranslate nohighlight">\(3-9\)</span>.</p></li>
<li><p>The top part of the molecule in the Left  matches a bottom part of that of the Right, indicating a global deformation.</p></li>
<li><p>Also the bottom-left part of the molecule in the Left matches the top part of that in the Right (again a deformation).</p></li>
<li><p>Overall, the largest subgraphs are correctly matched but the smallest ones are misplaced.</p></li>
</ul>
<p>Therefore, althoug the solution obtained seems <strong>quantitatively global</strong> it is partially <strong>qualitatively global</strong>. This reveals a need of making the objective function <span style="color:#f88146"><strong>more informative</strong></span> (we will come back to this point later on).</p>
<figure class="align-center" id="sa-aspirin">
<a class="reference internal image-reference" href="_images/SA-Aspirin-Photoroom.png"><img alt="_images/SA-Aspirin-Photoroom.png" src="_images/SA-Aspirin-Photoroom.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.16 </span><span class="caption-text">Approximating the Aspirin’s Isomorphism with SA.</span><a class="headerlink" href="#sa-aspirin" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="interpretation-of-sa">
<h3><span class="section-number">2.3.2. </span>Interpretation of SA<a class="headerlink" href="#interpretation-of-sa" title="Permalink to this heading">#</a></h3>
<p><strong>Intuitive interpretation</strong>. From an intuitive point of view, SA can be described as follows <a class="reference external" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=645602">Hoffmann and Buhmann 1997</a>:</p>
<ol class="arabic simple">
<li><p>Cost differences between neighboring states act as a <strong>force field</strong>.</p></li>
<li><p>The effect of the computational temperature can be interpreted as a random force with an <strong>amplitude proportional to T</strong>.</p></li>
<li><p>Valleys and peaks with a cost difference less than T are smeared out and <strong>vanish</strong> in the stochastic search. Vanishing is more likely to happen in the early stages of the search where we need to scape from local (subobtimal) solutions.</p></li>
</ol>
<p><strong>Methodological Interpretation</strong>. In the AI jargon, <span class="math notranslate nohighlight">\(F\)</span> is considered an <span style="color:#f88146"><strong>heuristic</strong></span> and SA is considered a <span style="color:#f88146"><strong>meta-heuristic</strong></span>:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Heuristic">Heuristic</a>. This term was introduced by Herbert Simon and it loosely means “seach shortcut”, i.e. some mechanism for deciding what solution is interesting and what is not in a potentially large space of solutions. This concept is our subject. Herein, it is the number of rectangles.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Metaheuristic">Meta-Heuristic</a> are procedures that “modulate the application of a heuristic”. SA is a metaheuristic because it decides when the search is more stochastic and when it becomes more greedy.</p></li>
</ul>
<p><strong>Formal interpretation</strong>. Remember that the <a class="reference external" href="https://arxiv.org/pdf/1504.01896">Metropolis Algorithm</a> implements an irreducible Markov chain <span class="math notranslate nohighlight">\(X_0,X_1,\ldots,X_t\)</span> along <span class="math notranslate nohighlight">\(\Omega\)</span>. This Markov chain is <strong>stationary</strong> i.e. it converges to a given probability distribution <span class="math notranslate nohighlight">\(G\)</span> which means that after a given time step <span class="math notranslate nohighlight">\(t\)</span> if <span class="math notranslate nohighlight">\(X_{t}\sim G(\omega)\)</span> then also <span class="math notranslate nohighlight">\(X_{t+1}\sim G(\omega)\)</span>. The stationary distribution is</p>
<div class="math notranslate nohighlight">
\[
\lim_{t\rightarrow\infty}p(X^{t+1}|X^{t})=G(\omega)\;,
\]</div>
<p>independently of the choose of <span class="math notranslate nohighlight">\(X_0\)</span>. In this case, the stationary distribution <span class="math notranslate nohighlight">\(G(\omega)\)</span> is</p>
<div class="math notranslate nohighlight">
\[
G(\omega) = \frac{\exp(\beta\cdot F(\omega))}{Z},\;\; \text{with}\;\; Z = \sum_{\omega\in\Omega}\exp(\beta\cdot F(\omega))\;,
\]</div>
<p>which is known as the <span style="color:#f88146"><strong>Gibbs distribution</strong></span>. Look, for instance, at the <span class="math notranslate nohighlight">\(q\)</span> variable at the step <span class="math notranslate nohighlight">\(4.2.\)</span> of the Metropolis-Hastings algorithm:</p>
<div class="math notranslate nohighlight">
\[
q\leftarrow \exp\left(\frac{\Delta F}{T(t)}\right) = 
\exp\left(\beta(t)\Delta F\right) = \frac{\exp\left(\beta(t)F(\omega')\right)}{\exp\left(\beta(t) F(\omega_{old})\right)} = \frac{\frac{\exp\left(\beta(t)F(\omega')\right)}{Z(t)}}{\frac{\left(\beta(t) F(\omega_{old})\right)}{Z(t)}}=\frac{G(\omega')}{G(\omega_{old})}\;.
\]</div>
<p>Therefore, the so-called <strong>acceptance probability</strong> is a ratio between two “Gibbsian” probabilities!. Note that in the Gibbs distribution, for a given <span class="math notranslate nohighlight">\(\beta\)</span> the states <span class="math notranslate nohighlight">\(\omega\in \Omega\)</span> with larger <span class="math notranslate nohighlight">\(F(\omega)\)</span> are more probable. As a result, <span class="math notranslate nohighlight">\(q\)</span> is the largest possible when <span class="math notranslate nohighlight">\(F(\omega')\gg F(\omega_{old})\)</span> (of course for this <span class="math notranslate nohighlight">\(\beta\)</span>).</p>
<p>Consequently, SA can be seen as a <span style="color:#f88146"><strong>sampling process</strong> that converges to the global optimal <span class="math notranslate nohighlight">\(\omega^{\ast}\)</span> of <span class="math notranslate nohighlight">\(F(\omega)\)</span></span> if the annealing schedule is a proper one. However, what is the <strong>fomal role</strong> of the temperature (or its inverse: <span class="math notranslate nohighlight">\(\beta\)</span>)? Solving this question is a good excuse to dive into <strong>Information Theory</strong>, a mathematical discipline which is built on top of Probability and it is fundamental to undestanding intelligent search.</p>
</section>
<section id="gibbs-sampling">
<h3><span class="section-number">2.3.3. </span>Gibbs Sampling<a class="headerlink" href="#gibbs-sampling" title="Permalink to this heading">#</a></h3>
<p>SA shows that intelligent search can be seen as deploying random walks for exploring combinatorial spaces such as <span class="math notranslate nohighlight">\(\Pi_n\)</span>. For this section, we need a key probabilistic concept: the expectation of a random variable.</p>
<p>Remember that the <strong>expectation</strong> of a discrete random variable <span class="math notranslate nohighlight">\(\omega\)</span> is defined as follows:</p>
<div class="math notranslate nohighlight">
\[
E(X)=\sum_{\omega\in \Omega}\omega\cdot p(X=\omega)\;.
\]</div>
<p>Expectation gives us an idea of the <strong>spatial concentration</strong> of the values <span class="math notranslate nohighlight">\(\omega\in\Omega\)</span> attending to <span class="math notranslate nohighlight">\(p(X=\omega)\)</span>. Actually <span class="math notranslate nohighlight">\(E(X)\)</span> can be seen as <em>the most representative</em> of this values (i.e. the <em>most likely</em> of them).</p>
<p>For determining <span class="math notranslate nohighlight">\(E(X)\)</span> it is mandatory to know all the probabilities <span class="math notranslate nohighlight">\(p(X=\omega)\)</span>.</p>
<p>However, <span style="color:#f88146">what if <span class="math notranslate nohighlight">\(p(X=\omega)=G(X)\)</span>, i.e. if <span class="math notranslate nohighlight">\(X\)</span> is <strong>Gibbsian</strong>?</span>. This is the case of <span class="math notranslate nohighlight">\(X=F(\omega)\)</span>, the value of the cost function. In this latter case,</p>
<div class="math notranslate nohighlight">
\[
E(X) = \sum_{\omega\in \Omega}\omega\cdot G(X=\omega) = \sum_{\omega\in \Omega}\omega\cdot \frac{\exp\left(\beta\cdot F(\omega)\right)}{Z}\;,
\]</div>
<p>is the <strong>expected cost</strong>. Can we really calculate it? Well, it is impossible to do it analitically because:</p>
<ol class="arabic simple">
<li><p>We should know all the values <span class="math notranslate nohighlight">\(F(\omega)\)</span>. This is equivalent to solve the problem encoded by this cost function by means of <strong>brute force</strong>. Remember that for the QAP this implies to evaluate <strong>all the states of the Permutohedron</strong>, i.e. <span class="math notranslate nohighlight">\(n!\)</span> states whose individual evaluation takes <span class="math notranslate nohighlight">\(O(n^4)\)</span>.</p></li>
<li><p>The Gibbs distribution seems to be restricted to a given <span class="math notranslate nohighlight">\(\beta\)</span>. We should evaluate <span class="math notranslate nohighlight">\(Z=\sum_{\omega\in\Omega}G(\omega)\)</span>, a very large sum, for that particular <span class="math notranslate nohighlight">\(\beta\)</span>. Therefore, <span class="math notranslate nohighlight">\(E(X)\)</span> seems to be <span class="math notranslate nohighlight">\(\beta-\)</span>dependent as well.</p></li>
</ol>
<p>Instead, the Metropolis-Hastings algorithm allows us to <strong>approximate</strong> <span class="math notranslate nohighlight">\(E(X)\)</span> as follows:</p>
<div class="math notranslate nohighlight">
\[
E(X)\approx \frac{1}{R}\sum_{r=1}^{R}F(\omega_r)\;,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\omega_1,\omega_2,\ldots, \omega_r\)</span> are the states visited by the algorithm when it follows an <strong>admisible anneling schedule</strong> such as <span class="math notranslate nohighlight">\(T(t)=\frac{C}{\log(1+t)}\)</span> where <span class="math notranslate nohighlight">\(C\)</span> is a constant. This means that <span class="math notranslate nohighlight">\(\omega_r\)</span> is <strong>accepted</strong> at <span class="math notranslate nohighlight">\(T(r)\)</span>.</p>
<p>Some related considerations:</p>
<ol class="arabic simple">
<li><p>The sequence <span class="math notranslate nohighlight">\(\omega_1,\omega_2,\ldots,\)</span> is a <strong>random walk</strong> along <span class="math notranslate nohighlight">\(\Omega\)</span> which is driven by <span class="math notranslate nohighlight">\(F(\omega)\)</span> and converges to the Gibbs probability.</p></li>
<li><p>The lower the temperature <span class="math notranslate nohighlight">\(T(t)\)</span> the closer we become to the Gibbs distribution. Therefore <span style="color:#f88146">the computational temperature works as a <strong>Lagrange parameter</strong> to enforce the convergence</span> towards the Gibbs distribution.</p></li>
<li><p>Formally, not all the <strong>samples</strong> <span class="math notranslate nohighlight">\(\omega_1,\omega_2,\ldots,\omega_r\)</span> are generated by <span class="math notranslate nohighlight">\(G(\omega)\)</span> since every random walk has a <strong>transient period</strong> (unstable values) and we do not know exactly at what time instant we have the convergence, i.e. <span class="math notranslate nohighlight">\(\omega_t\)</span> become proper samples of <span class="math notranslate nohighlight">\(G(\omega)\)</span>.</p></li>
<li><p>Following <a class="reference external" href="https://eml.berkeley.edu/reprints/misc/understanding.pdf">Understanding Gibbs Sampling</a>, a good strategy is to start different random walks at different <span class="math notranslate nohighlight">\(X_0\)</span>s (initial permutations in QAP) and track the samples until we can observe some <strong>consensus</strong>.</p></li>
</ol>
<p>In <a class="reference internal" href="#sa-expectations"><span class="std std-numref">Fig. 2.17</span></a>, we show three random walks generated from different <span class="math notranslate nohighlight">\(X_0\)</span>s, for the admisible annealing (inverse log) with <span class="math notranslate nohighlight">\(C=3\)</span>. None of them reaches the global optimum in <span class="math notranslate nohighlight">\(R=7,000\)</span> iterations. Actually their approximate expectations <span class="math notranslate nohighlight">\(E(X)\)</span> are respectively <span class="math notranslate nohighlight">\(8.637\)</span>, <span class="math notranslate nohighlight">\(8.178\)</span> and
<span class="math notranslate nohighlight">\(9.371\)</span> if we remove the first <span class="math notranslate nohighlight">\(1,000\)</span> samples (considered as transient regime), whereas we have <span class="math notranslate nohighlight">\(9.051\)</span>, <span class="math notranslate nohighlight">\(8.466\)</span>, and <span class="math notranslate nohighlight">\(9.791\)</span> if all the samples are included.</p>
<p>What is interesting here is that <span style="color:#f88146"><strong>it is quite difficult to reach the global optimum</strong></span> since:</p>
<ol class="arabic simple">
<li><p>There are fewer states with that value in general and most of them are sub-optimal. This is indiated by the fact that <span class="math notranslate nohighlight">\(E(X)\ll \omega^{\ast}\)</span> for <span class="math notranslate nohighlight">\(X=F(\omega)\)</span>.</p></li>
<li><p>In combinatorial problems such as QAP, the cost function has a discrete number of <strong>energy levels</strong> and this usually leads to <strong>plateaus</strong> (regions of constast cost) as cooling progresses. For instance, in <a class="reference internal" href="#sa-expectations"><span class="std std-numref">Fig. 2.17</span></a> random search seems blocked in a sub-optimal state, at least for such number of iterations <span class="math notranslate nohighlight">\(R\)</span>.</p></li>
</ol>
<figure class="align-center" id="sa-expectations">
<a class="reference internal image-reference" href="_images/SA-Expectations-Photoroom.png"><img alt="_images/SA-Expectations-Photoroom.png" src="_images/SA-Expectations-Photoroom.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.17 </span><span class="caption-text">Three random walks along <span class="math notranslate nohighlight">\(\Pi_n\)</span> with differernt <span class="math notranslate nohighlight">\(X_0\)</span>s.</span><a class="headerlink" href="#sa-expectations" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Note also that herein we have highlighted the main features of SA. Please check the beautiful paper of the Geman’s brothers: Stochastic Relaxation, <a class="reference external" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=4767596">Gibss Distribution and the Bayesian Restoration of Images</a> one of the most influential papers in all times.</p>
</section>
<section id="limitations-of-sa">
<h3><span class="section-number">2.3.4. </span>Limitations of SA<a class="headerlink" href="#limitations-of-sa" title="Permalink to this heading">#</a></h3>
<p>SA is appealing for AI since it allows us to track the global optimum in a sort of random walk. However:</p>
<ol class="arabic simple">
<li><p>The quality or “intelligence” of the random walk relies on <span style="color:#f88146"><strong>how informative</strong></span> is the cost function. How is information measured? We will address this question later on.</p></li>
<li><p>The <span style="color:#f88146">global optimum is only guaranteed for a <strong>slow</strong> annealing</span> <span class="math notranslate nohighlight">\(T(t)=\frac{C}{\log(1+t)}\rightarrow 0\)</span>. SA has to be slow enough to not missing that global optimum; otherwise SA becomes greedy prematurely. This is an <strong>important limitation</strong> of SA: remember that for QAP we have to evaluate <span class="math notranslate nohighlight">\(F(\omega)\)</span> at each time <span class="math notranslate nohighlight">\(t\)</span> and it takes <span class="math notranslate nohighlight">\(O(n^4)\)</span>.</p></li>
</ol>
<!--
## Central Clustering
**Deterministic Annealing** (DA) emerges as a faster method than SA. In order to motivate this technique it is more convenient to visit another NP problem. This problem is **central clustering** (or <span style="color:#f88146">**$k-$centrer clustering**</span>) and it is formulated as follows: 

*Given a set ${\cal X}=\{\mathbf{x}_1,\mathbf{x_2},\ldots,\mathbf{x}_m\}\subset \mathbb{R}^d$ ($d-$dimensional points)  and an integer parameter $k>1$, *find a set of $k$ centers* ${\cal C}=\{\mathbf{c}_1,\mathbf{c}_2,\ldots,\mathbf{c}_k\}\subset \mathbb{R}^d$ such that so that the Euclidean distance $D(\mathbf{x},\mathbf{c})$ of each point $\mathbf{x}_a$ to its closest center $\mathbf{c}_i$ is minimal.*


### Clusters and Prototypes
A more intuitive formulation is as follows. Let 

$$
\text{cluster}(\mathbf{c}_i) = \{\mathbf{x}_a\in{\cal X}: D(\mathbf{x}_a,\mathbf{c}_i)\le D(\mathbf{x}_a,\mathbf{c}_j),j\neq i\}\;,
$$

be a <span style="color:#f88146">**cluster**</span>, i.e. a subset of ${\cal X}$ where its elements $\mathbf{x}_a$ are closer to the cluster's <span style="color:#f88146">**prototype**</span> $\mathbf{c}_i$ than to any other. Then, the problem is also formulated as follows: 

*Partition ${\cal X}$ in $k$ (disjoint) clusters such that the sum of distances between the points and the prototypes is minimal.*

Some clarifications: 
1) The problem is a <span style="color:#f88146">**chicken-and-egg**</span> problem: a) We need to know the $k$ centers $\mathbf{c}_i$ beforehand in order to determine the clusters $\text{cluster}(\mathbf{c}_i)$ but b) the prototypes have to be determined once the clusters are done according with the criterion of minimal distances. 

2) The NP-hardness of the problem is given by the <span style="color:#f88146">**partitioning flavor**</span>. Actually, the worst case complexity is $O(k^m)$ since each of the $m$ different points can be exclusively assigned to $k$ centers (**r-permutations with repetition** $P_{\sigma}(m,k)=k^m)$. 

3) The prototypes $\mathbf{c}_i$ <span style="color:#f88146">**do not necessarily belong to**</span> ${\cal X}$ and they must be discovered. 

See for instance a well defined problem in {numref}`KM-clusters` where the red dots are ideal centers $\mathbf{c}_i$ which are the expectations $\mu_i$ of bidimensional Gaussians $N(\mu_i,\sigma\mathbf{I})$ with $\sigma=0.5$.

```{figure} ./images/Topic2/KM-clusters-Photoroom.png
---
name: KM-clusters
width: 800px
align: center
height: 600px
---
Clusters and estimated prototypes in $\mathbb{R}^2$. 
```

### Cost Functions
#### Attractors
A first compact cost function could be:  

$$
F({\cal C}) = \sum_{a=1}^m\min_{1\le i\le k}D(\mathbf{x}_a,\mathbf{c}_i)\;. 
$$

where we are interested in ${\cal C}^{\ast}$, the set $k$ centers/prototypes  <span style="color:#f88146">**minimizing the total distance**</span>. 

In {numref}`KM-clusters`, two centers $\mathbf{c}_1=[-1,-1]^T$ and $\mathbf{c}_2=[1,-1]^T$ and mutually closer than the third one $\mathbf{c}_3=[0,2]^T$. Then, if we represent the individual cost of each point $\mathbf{x}_a$ wrt each center, i.e. $min_{1\le i\le k}D(\mathbf{x}_a,\mathbf{c}_i)$ (see {numref}`KM-dist`) note that there is well-defined minimum at $\mathbf{c}_1=[-1,-1]^T$ which we interpret as an <span style="color:#f88146">**attractor** or **meta-stable state**</span>, since it distorts the locations of the other two minima. Note also, that the cost function is clearly **non convex** and it has many **saddle points** (see for instance the 3D view in {numref}`KM-dist3D`)


```{figure} ./images/Topic2/KM-dist-removebg-preview.png
---
name: KM-dist
width: 800px
align: center
height: 600px
---
Individual cost wrt closest centers. 
```

```{figure} ./images/Topic2/KM-dist3D-removebg-preview.png
---
name: KM-dist3D
width: 800px
align: center
height: 600px
---
Individual cost wrt closest centers (3D view). 
```

However, if we also include the point-to-cluster <span style="color:#f88146">**assignment variables**</span> $\mathbf{M}_{ai}$, we aim to **jointly** minimize:   

$$
F({\cal C},\mathbf{M}) = \sum_{a=1}^m\mathbf{M}_{ai}D(\mathbf{x}_a,\mathbf{c}_i)\;,\text{s.t.}\;\sum_{i=1}^k\mathbf{M}_{ai}=1\;,\forall a\in \{1,\ldots,m\}\;,
$$

where each point can be only assigned to a single cluster and all points must be assigned (each row has a single $1$).


#### Independence 
Note that the Gibbs distribution for $F({\cal C},\mathbf{M})$ is

$$
G({\cal C},\mathbf{M})=\frac{\exp(-\beta F({\cal C},\mathbf{M}))}{Z}\;\;\text{with}\;\;\; Z=\sum_{{\cal C},\mathbf{M}}\exp(-\beta F({\cal C},\mathbf{M}))\;,
$$

where the negative exponential means that <span style="color:#f88146">the probability of a solution **decays exponentially with the distances**</span> beween the points and the cluster centers or prototypes.


Instead of sampling $\Omega={\cal C}\times{\cal P}$ with SA, where

$$
{\cal P} =\left\{\mathbf{M}\in \{0,1\}^{m\times k}:\forall a\in\{1,\ldots,m\}:\sum_{i=1}^k\mathbf{M}_{ai}=1,\right\} 
$$

we are going to <span style="color:#f88146">assume that the variables ${\cal C}$ and $\mathbf{M}$ are **statitically indepedendent**</span>. Then, following the **Appendix**, we compute the **marginal** of the Gibbs distribution wrt the assignment matrices: 

$$
\begin{align}
G({\cal C})&=\sum_{\mathbf{M}\in{\cal P}} G({\cal C},\mathbf{M})\\
           &=\frac{1}{Z}\sum_{\mathbf{M}\in{\cal P}}\exp(-\beta F({\cal C},\mathbf{M}))\\
           &=\frac{1}{Z}\sum_{\mathbf{M}\in{\cal P}}\exp\left(-\beta \sum_{a=1}^m\sum_{i=1}^k\mathbf{M}_{ai}D(\mathbf{x}_a,\mathbf{c}_i)\right)\\
           &=\frac{1}{Z}\sum_{\mathbf{M}\in{\cal P}}Q(\mathbf{M})\;.
\end{align}
$$

Now, looking at the sum of neg-exponentials, we observe that the sum is over the <span style="color:#f88146">**legal assignment matrices**</span> $\mathbf{M}\in{\cal P}$ (each point must be assigned to a unique prototype). This means that any **legal** matrix will be a collection of rows ratisfying:   

$$
\text{rows}(\mathbf{M})\in {\cal C}_k=\overbrace{\{\underbrace{(1,0,\ldots,0)}_{I_1:k\;\text{elements}},\underbrace{(0,1,\ldots,0)}_{I_2:k\;\text{elements}},\ldots,\underbrace{(0,0,\ldots,1)}_{I_k:k\;\text{elements}}\}}^{m\;\text{elements}}\;.
$$

This means that for each of the $m$ rows of $\mathbf{M}$ we have $k$ options for $m$ positions, leading to $k^m$ **total legal matrices**, i.e. terms in $\sum_{\mathbf{M}\in {\cal P}}Q(\mathbf{M})$. However, this number can be reduced if we perform a <span style="color:#f88146">**second independence assumption**: the assignmnet of a point to a cluster is independent to that of another point</span> (logically this is not true for nearby points but this simplifies the calculations).

This allows us to express the neg-exp sum as the following sum, implementing a logical $\lor$:

$$
\sum_{\mathbf{M}\in{\cal P}} Q(\mathbf{M})=\sum_{\text{rows}(\mathbf{M}^{(1)})}\sum_{\text{rows}(\mathbf{M}^{(2)})}\ldots\sum_{\text{rows}(\mathbf{M}^{(m)})}Q(\mathbf{M})
$$

where $\mathbf{M}^{(1)},\mathbf{M}^{(2)},\ldots,\mathbf{M}^{(m)}$ are the assignment matrices that can be chosen for any particular point $\mathbf{x}_1,\mathbf{x}_2,\ldots,\mathbf{x}_m$. 

Since **independence means factorization** we have $\sum\sum\ldots\sum = \sum\cdot\sum\ldots\sum$ as in multiple integration, i.e.: 

$$
Z = \sum_{\mathbf{M}\in{\cal P}} Q(\mathbf{M})=\prod_{a=1}^m\sum_{\text{rows}(\mathbf{M}^{(a)})}Q(\mathbf{M}^{(a)}) = \prod_{a=1}^m\sum_{\text{rows}(\mathbf{M}^{(a)})}\exp\left(-\beta\sum_{i=1}^k\mathbf{M}^{(a)}_{ai}D(\mathbf{x}_a,\mathbf{c}_i)\right)\;.
$$

where the product $\prod_{a=1}^m$ absorbs the sums $\sum_{a=1}^m$ inside each exponential.  

Now *pay attention!* This the point where we use the fact that $\sum_{i=1}^k\mathbf{M}^{(a)}_{ai}=1,\forall a$ (for each row!), i.e. only one cluster will be chosen. Actually, we have an XOR! This leads us to: 

$$
Z=\sum_{\mathbf{M}\in{\cal P}} Q(\mathbf{M})=\prod_{a=1}^m\sum_{\text{rows}(\mathbf{M}^{(a)})}Q(\mathbf{M}^{(a)}) = \prod_{a=1}^m\sum_{i=1}^k\exp\left(-\beta D(\mathbf{x}_a,\mathbf{c}_i)\right)\;.
$$

**Final result**. Then, in order to capture the above factorization, the original cost function $F({\cal C},\mathbf{M})$ must be transformed as follows

$$
F_{\beta}({\cal C}) = -\frac{1}{\beta}\log Z = -\frac{1}{\beta}\sum_{a=1}^m \log\sum_{i=1}^k \exp\left(-\beta D(\mathbf{x}_a,\mathbf{c}_i)\right)\;.
$$

which can be computed in $O(nk)$. Actually, $F_{\beta} = -\frac{1}{\beta}\log Z$ is usally called the [Free Energy](https://en.wikipedia.org/wiki/Gibbs_free_energy#:~:text=In%20traditional%20use%2C%20the%20term,non%2Dpressure%2Dvolume%20work). 

#### Derivation 
The below DA algorithm for central clustering results from the **minimization of the Free energy** as follows: 

Let us compute the derivative of 

$$
F_{\beta}({\cal C})=-\frac{1}{\beta}\sum_{a=1}^m \log\underbrace{\sum_{i=1}^k \exp\left(-\beta D(\mathbf{x}_a,\mathbf{c}_i)\right)}_{Q(\mathbf{x}_a)}
$$ 


wrt each center $\mathbf{c}_i$: 

$$
\begin{align}
\frac{\partial F_{\beta}}{\partial \mathbf{c}_i} &= -\frac{1}{\beta} \sum_{a=1}^m\frac{\partial \log Q(\mathbf{x}_a)}{\partial \mathbf{c}_i}\\
&= -\frac{1}{\beta}\sum_{a=1}^m\frac{1}{Q(\mathbf{x}_a)}\cdot \frac{\partial Q(\mathbf{x}_a)}{\partial \mathbf{c}_i}\\
&= -\frac{1}{\beta}\sum_{a=1}^m\frac{1}{Q(\mathbf{x}_a)}\cdot \left(-e^{-\beta D(\mathbf{x}_a,\mathbf{c}_i)}\right)\cdot\frac{\partial D(\mathbf{x}_a,\mathbf{c}_i)}{\mathbf{c}_i}\;.\\
\end{align}
$$

For $D(\mathbf{x}_a,\mathbf{c}_i)=||\mathbf{x}_a-\mathbf{c}_i||^2$ we have: 

$$
\begin{align}
\frac{\partial D(\mathbf{x}_a,\mathbf{c}_i)}{\mathbf{c}_i}=2(\mathbf{x}_a-\mathbf{c}_i)
\end{align}
$$

Then, plugging this derivative in the main formula, and expanding the $Q(\mathbf{x}_a)$, we obtain: 

$$
\begin{align}
\frac{\partial F_{\beta}}{\partial \mathbf{c}_i} &= -\frac{1}{\beta}\sum_{a=1}^m\frac{1}{Q(\mathbf{x}_a)}\cdot \left(-e^{-\beta D(\mathbf{x}_a,\mathbf{c}_i)}\right)\cdot 2(\mathbf{x}_a-\mathbf{c}_i)\\
&= \frac{2}{\beta}\sum_{a=1}^m\frac{e^{-\beta D(\mathbf{x}_a,\mathbf{c}_i)}}{\sum_{i'=1}^k e^{-\beta D(\mathbf{x}_a,\mathbf{c}_{i'})}}\cdot (\mathbf{x}_a-\mathbf{c}_i)\;.
\end{align}
$$

Note that 

$$
\langle \mathbf{M}_{ai} \rangle = \frac{e^{-\beta D(\mathbf{x}_a,\mathbf{c}_i)}}{\sum_{i'=1}^k e^{-\beta D(\mathbf{x}_a,\mathbf{c}_{i'})}}\;.
$$

Then, 

$$
\begin{align}
\frac{\partial F_{\beta}}{\partial \mathbf{c}_i} &= 
\frac{2}{\beta}\sum_{a=1}^m\langle \mathbf{M}_{ai} \rangle\cdot (\mathbf{x}_a-\mathbf{c}_i)\;.
\end{align}
$$

Since the optimum is obtained when the gradient is zero, we have: 

$$
\frac{\partial F_{\beta}}{\partial \mathbf{c}_i} = \mathbf{0}\Rightarrow \sum_{a=1}^m\langle \mathbf{M}_{ai} \rangle\cdot (\mathbf{x}_a-\mathbf{c}_i)=\mathbf{0}\Rightarrow 
\mathbf{c}_i = \frac{1}{\sum_{a=1}^m\langle \mathbf{M}_{ai} \rangle}\sum_{a=1}^m\mathbf{x}_a\langle \mathbf{M}_{ai} \rangle\;.
$$

Therefore, the DA algorithm for central clustering is simply derived from the gradient of the free energy. Summarizing, DA consists in <span style="color:#f88146">**performing gradient descent** wrt to each inverse temperature $\beta$</span>. 


### Deterministic Annealing
[Deterministic Annealing (DA)](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=726788) is a search technique easily applicable to the central clustering problem (see more details in [Keneth Rose's PhD Thesis](https://thesis.library.caltech.edu/2858/1/Rose_k_1991.pdf)). 

The basic idea of DA is that for each value of $\beta=\frac{1}{T}$ we <span style="color:#f88146">**interate two phases**</span> for minimizing
the free energy $F_{\beta}({\cal C})$:

1) **Expectation**. For <ins>fixed centers</ins> $\mathbf{c}_i$, we estimate the <span style="color:#f88146">**probability**</span> that any point $\mathbf{x}_a$ "belongs" to each cluster ("membership"). We denote such probabilities as $\langle \mathbf{M}_{ai} \rangle$ and they are given by: 

$$
\langle \mathbf{M}_{ai} \rangle = \frac{\exp(-\beta D(\mathbf{x}_a,\mathbf{c}_i))}{\sum_{i'=1}^k \exp(-\beta D(\mathbf{x}_a,\mathbf{c}_{i'}))}\;.
$$

2) **Update**. For <ins>fixed probabilities</ins> $\langle \mathbf{M}_{ai} \rangle$, we update the <span style="color:#f88146">**centers**</span>. If $D(\mathbf{x}_a,\mathbf{c}_i)=||\mathbf{x}_q-\mathbf{c}_i||^2$ (squared Euclidean distance), then we have 

$$
\mathbf{c}_i =  \frac{\sum_{a=1}^m \mathbf{x}_a \langle \mathbf{M}_{ai}\rangle}{\sum_{a=1}^m\langle \mathbf{M}_{ai}\rangle}\;,
$$

i.e. the new ("fuzzy") centers are the expected centers according to the fixed probabilities or ("memberships"). 


```{prf:algorithm} Deterministic Annealing [Clustering]
:label: DA-alg

**Inputs** Given a set of points ${\cal X}=\{\mathbf{x}_1,\ldots,\mathbf{x}_m\}$, the free energy $F_{\beta}({\cal C})$, an annealing schedule $\beta =1/T(t)$ and an inital state ${\cal C}^0=(\mathbf{c}^0_1,\ldots,\mathbf{c}^0_k)$\
**Outputs** ${\cal C}^{\ast}=\arg\min_{{\cal C}\in\Omega} F_{\beta\rightarrow\infty}({\cal C})$ and $\langle \mathbf{M}^{\ast}_{ai}\rangle$

1. convegence = False
2. $\langle \mathbf{M}^{old}_{ai}\rangle\leftarrow 1$
3. $t\leftarrow 0$
4. **while** $\neg$ convergence:
    
    1. **for** $\mathbf{x}_a\in {\cal X}$, $\mathbf{c}_i\in {\cal C}$: 

       $
       \langle \mathbf{M}_{ai} \rangle = \frac{\exp(-\beta D(\mathbf{x}_a,\mathbf{c}_i))}{\sum_{i'=1}^k \exp(-\beta D(\mathbf{x}_a,\mathbf{c}_{i'}))}
       $

    2. **for** $\mathbf{c}_i\in {\cal C}$: 

       $
       \mathbf{c}_i =  \frac{\sum_{a=1}^m \mathbf{x}_a \langle \mathbf{M}_{ai}\rangle}{\sum_{a=1}^m\langle \mathbf{M}_{ai}\rangle}
       $

    3. $t\leftarrow t+1$
    4. $T(t)\leftarrow \frac{1}{\log(1 + t)}$
    5. convergence = $(T(t)<T_{min})$ **or** $(t>t_{max})$ **or** $(\sum_{ai}|\langle \mathbf{M}_{ai}\rangle - \langle \mathbf{M}^{old}_{ai}\rangle|\le\epsilon )$
    6. $\langle \mathbf{M}^{old}_{ai}\rangle\leftarrow \langle \mathbf{M}_{ai}\rangle$
5. **return** ${\cal C}^{\ast}$, $\langle M^{\ast}\rangle$
```



Some considerations about the above algorithm: 
- It is **deterministic**, i.e. we do not draw random numbers at any step of the algoorithm.
- The **initial (inverse) temperature** $\beta=1/T_{max}$, where $T_{max}=T(0)$, is used as in SA, to make all the assignments almost equally probable: note that $e^{-\beta D(\mathbf{x}_a,\mathbf{c}_i)}\rightarrow 1$, if $\beta\rightarrow 0$. Under these conditions, we have $\langle M_{ai}\rangle\approx 1/k$.
- **Initialization**. $T_{max}$ is set to the maximum variance $\sigma^2_{max}$ of  the data. If the data is multidimensional, as it happens usually, $\sigma^2_{max}$ has an spectral interpretation (PCA).
- However, as the algorithm evolves, $\beta$ increases and the **exponential decay becomes more selective**: given $D(\mathbf{x}_a,\mathbf{c}_i)\le D(\mathbf{x}_a,\mathbf{c}_j)+\alpha$, the second distance decays exponentially faster than the first as $\beta$ increases.
- **Alternating Expectation and Update**. Given the probabilities $\langle M_{ai}\rangle$ we update the centers $\mathbf{c}_i$ and then we re-compute the probabilities until a "fixed point" (stable assignment/centers) is reached. 
- **Convervence**. The algorithm converges to the nearest local optimum of the free energy to the initialization point ${\cal C}^0$. We add the condition $\sum_{ai}|\langle \mathbf{M}_{ai}\rangle - \langle \mathbf{M}^{old}_{ai}\rangle|\le\epsilon$ with $\epsilon>0$, which means that the algorithm stops if the $\langle \mathbf{M}_{ai}\rangle$ are stable enough. For instance, if we start by setting $\langle M_{ai}\rangle\approx 1/k$, the algorithm only performs a single iteration. Why? Because the centers in step 4.2. are not modified at all.
- **Complexity**. Each iteration takes $O(mk)$ and the number of iterations can be accelerated by a faster annealing schedule. 
- **Outputs**. The algorithm returns the best centers ${\cal C}^{\ast}$ and the optimal assignments $\langle \mathbf{M}_{ai}^{\ast}\rangle$ where a point $\mathbf{x}_a$ is assigned to the cluster centered at $\mathbf{c}_{i'}$ if: 

$$
i' = \arg\max_{1\le i\le k}\langle \mathbf{M}_{ai}^{\ast}\rangle\;.
$$

We show how the algorithm works in one-dimensional points in the following exercise: 
<br></br>
<span style="color:#d94f0b"> 
**Exercise**. Given the following points ${\cal X}=\{1,2,3,7,7.5,8.25\}$ in $\mathbb{R}$, cluster them with $k=2$, starting from a unique cluster. Use the following inverse-temperature scheduling: $\beta(t+1)=\beta(t)\beta_r$, with $\beta_r = 1.075$. 
<br><br>
Answer. We have then a $(m=6,k=2)$ instance of central clustering. Firstly, we analize the data. The mean and standard deviation of the data are respectively $\mu=4.79$ and $\sigma=2.87$. We may use the mean to encode the unique center, for instance: $c^0_1=c^0_2=\mu$. However, this would result in terminating the algorithm in a single iteration with $\langle \mathbf{M}_{ai}\rangle = 0.5,\forall a,i$. 
<br></br>
A simple way to avoid the $50/50$ setting is to make $c^0_1=\mu + 0.01,\;\; c^0_2=\mu$. Then the initial centers are $c_1^0 = \mathbf{4.801}$ and $c_2^0 = \mathbf{4.791}$.
<br></br>
Regarding $\beta(0)=1/T_{max}$ we make $T_{max}=\sigma$ which results in $\beta(0)=1/2.87=0.34$. 
</span>
<br></br>
<span style="color:#d94f0b">
<ins>Iteration 1</ins>. At each iteration we recompute the (transposed) **squared distances** matrix $\mathbf{D}$ where $\mathbf{D}_{ia}=(c_i-x_a)^2$ with $a\in\{1,\ldots,6\}$ and $i\in\{1,2\}$. We transpose it to better visualize how far is each center from each data point. Better seen in tabular form: 
</span>
<br></br>
<span style="color:#d94f0b">
$
\begin{aligned}
\begin{array}{c|ccc}
  \mathbf{D}^{(1)} & x_1     & x_2    & x_3    & x_4   & x_5   & x_6\\
  \hline
  c_1        & 14.452  & 7.849  &  3.246 & 4.832 & 7.281 & 11.891 \\
  c_2        & 14.376  & 7.793  &  3.210 & 4.876 & 7.335 & 11.960 \\  
  \hline
\end{array}
\end{aligned}
$
</span>
<br></br>
<span style="color:#d94f0b">
Then we calculate the (transposed) neg-exponentials and the sum of each column for later normalization:
<br></br>
<span style="color:#d94f0b">
$
\begin{aligned}
\begin{array}{c|cccccc}
  \exp(-\beta(0)\mathbf{D}^{(1)}) & x_1     & x_2    & x_3    & x_4   & x_5   & x_6\\
  \hline
  c_1        & 0.007  & 0.069 & 0.331 & 0.193 & 0.084 & 0.017 \\
  c_2        & 0.007  & 0.070 & 0.335 & 0.190 & 0.082 & 0.017 \\  
  \hline
  \sum       & 0.014  & 0.139 & 0.666 & 0.383 & 0.166 & 0.034 \\
\end{array}
\end{aligned}
$
</span>
<br></br>
<span style="color:#d94f0b">
Then we proceed to normalize the columns, and also sum the resuling rows for preparing the computation of the new centers: 
</span>
<br></br>
<span style="color:#d94f0b">
$
\begin{aligned}
\begin{array}{c|cccccc|c}
 \langle \mathbf{M}^{(1)}\rangle  & x_1     & x_2    & x_3    & x_4   & x_5   & x_6 &\sum_{a=1}^m  \langle \mathbf{M}^{(1)}_{ai}\rangle\\
  \hline
  c_1        & 0.493  & 0.495 & 0.496 & 0.503 & 0.504 & 0.505 &  2.996 \\
  c_2        & 0.506  & 0.504 & 0.503 & 0.496 & 0.495 & 0.494 &  2.998 \\  
  \hline
\end{array}
\end{aligned}
$
</span>
<br></br>
<span style="color:#d94f0b">
Then the new centers become: 
</span>
<br></br>
<span style="color:#d94f0b">
$
\begin{align}
\mathbf{c}_1^{(1)} &= \frac{1}{2.996}\left(\mathbf{1}\cdot 0.493 + \mathbf{2}\cdot 0.495 + \ldots + \mathbf{8.25}\cdot 0.505\right) = \mathbf{4.819}\\
\mathbf{c}_2^{(1)} &= \frac{1}{2.998}\left(\mathbf{1}\cdot 0.506 + \mathbf{2}\cdot 0.504 + \ldots + \mathbf{8.25}\cdot 0.494\right) = \mathbf{4.763}
\end{align}
$
</span>
<br></br>
<span style="color:#d94f0b">
where the first center $c_1$ starts to attract the largest values of ${\cal X}$ and $c_2$ attracts the lowest ones. 
</span>
<br></br>
<span style="color:#d94f0b">
<ins>Iteration 2</ins>. Given the new centers, we recompute their distances wrt  all the points in ${\cal X}$. The new (transposed) distance is: 
</span>
<br></br>
<span style="color:#d94f0b">
$
\begin{aligned}
\begin{array}{c|cccccc}
  \mathbf{D}^{(2)} & x_1     & x_2    & x_3    & x_4   & x_5   & x_6\\
  \hline
  c_1        & 14.590  & 7.950  & 3.311  & 4.753  & 7.183  & 11.766 \\
  c_2        & 14.164  & 7.637  & 3.110  & 5.001  & 7.487  & 12.155 \\  
  \hline
\end{array}
\end{aligned}
$
</span>
<br></br>
<span style="color:#d94f0b">
Then, the normalized neg-exponetials for $\beta(2)=0.365$ are: 
</span>
<br></br>
<span style="color:#d94f0b">
$
\begin{aligned}
\begin{array}{c|cccccc|c}
 \langle \mathbf{M}^{(2)}\rangle  & x_1     & x_2    & x_3    & x_4   & x_5   & x_6 &\sum_{a=1}^m  \langle \mathbf{M}^{(2)}_{ai}\rangle\\
  \hline
  c_1        & 0.461 & 0.471 & 0.481 & 0.522 & 0.527 & 0.535 &  2.997 \\
  c_2        & 0.538 & 0.528 & 0.518 & 0.477 & 0.472 & 0.464 &  2.997 \\  
  \hline
\end{array}
\end{aligned}
$
</span>
<br></br>
<span style="color:#d94f0b">
Then the new centers become: 
</span>
<br></br>
<span style="color:#d94f0b">
$
\begin{align}
\mathbf{c}_1^{(2)} &= \frac{1}{2.997}\left(\mathbf{1}\cdot 0.461 + \mathbf{2}\cdot 0.471 + \ldots + \mathbf{8.25}\cdot 0.535\right) = \mathbf{4.960}\\
\mathbf{c}_2^{(2)} &= \frac{1}{2.997}\left(\mathbf{1}\cdot 0.538 + \mathbf{2}\cdot 0.528 + \ldots + \mathbf{8.25}\cdot 0.464\right) = \mathbf{4.622}
\end{align}
$
</span>
<br></br>
<span style="color:#d94f0b">
<ins>Iteration 3</ins>. This is the **most informative iteration** so far because the two centers are clearly separated. They define what we later call a **phase change**. The distances give a hint of this: 
</span>
<br></br>
<span style="color:#d94f0b">
$
\begin{aligned}
\begin{array}{c|cccccc}
  \mathbf{D}^{(3)} & x_1     & x_2    & x_3    & x_4   & x_5   & x_6\\
  \hline
  c_1        & 15.689  & 8.767  & 3.845  & 4.157  & \mathbf{6.446}  &  10.817\\
  c_2        & 13.121  & \mathbf{6.876}  & 2.632  & 5.653  & 8.280  &  13.159\\  
  \hline
\end{array}
\end{aligned}
$
</span>
<br></br>
<span style="color:#d94f0b">
where the largest values are attracted by $c_2$ and the smallest ones by $c_2$ (see for instances the data in bold).
Then, the normalized neg-exponetials for $\beta(3)=0.392$ are: 
</span>
<br></br>
<span style="color:#d94f0b">
$
\begin{aligned}
\begin{array}{c|cccccc|c}
 \langle \mathbf{M}^{(3)}\rangle  & x_1     & x_2    & x_3    & x_4   & x_5   & x_6 &\sum_{a=1}^m  \langle \mathbf{M}^{(3)}_{ai}\rangle\\
  \hline
  c_1        & 0.267 & 0.322 & 0.383 & 0.642 & \mathbf{0.672} & 0.715 &  3.001 \\
  c_2        & 0.732 & \mathbf{0.677} & 0.616 & 0.357 & 0.327 & 0.284 &  2.993 \\  
  \hline
\end{array}
\end{aligned}
$
</span>
<br></br>
<span style="color:#d94f0b">
and then the new centers more "polarized": 
</span>
<br></br>
<span style="color:#d94f0b">
$
\begin{align}
\mathbf{c}_1^{(3)} &= \frac{1}{3.001}\left(\mathbf{1}\cdot 0.267 + \mathbf{2}\cdot 0.322 + \ldots + \mathbf{8.25}\cdot 0.715\right) = \mathbf{5.828}\\
\mathbf{c}_2^{(3)} &= \frac{1}{2.993}\left(\mathbf{1}\cdot 0.732 + \mathbf{2}\cdot 0.677 + \ldots + \mathbf{8.25}\cdot 0.284\right) = \mathbf{3.752}
\end{align}
$
</span>
<br></br>
<span style="color:#d94f0b">
<ins>Iterations 4 and 5</ins>. In these iterations, "intra-cluster" distances in bold) get small and stabilized  
</span>
<br></br>
<span style="color:#d94f0b">
$
\begin{aligned}
\begin{array}{c|cccccc}
  \mathbf{D}^{(4)} & x_1     & x_2    & x_3    & x_4   & x_5   & x_6\\
  \hline
  c_1        & 23.317  & 14.659  & 8.002  & \mathbf{1.371}   & \mathbf{2.792}  &  \mathbf{5.862} \\
  c_2        & \mathbf{7.575}   & \mathbf{3.070}   & \mathbf{0.565}  & 10.547  & 14.045  & 20.229\\  
  \hline
\end{array}
\end{aligned}
$
</span>
<br></br>
<span style="color:#d94f0b">
$
\begin{aligned}
\begin{array}{c|cccccc}
  \mathbf{D}^{(5)} & x_1     & x_2    & x_3    & x_4   & x_5   & x_6\\
  \hline
  c_1        & 42.347  & 30.332  & 20.317  & \mathbf{0.257}   & \mathbf{0.000}  &  \mathbf{0.551} \\
  c_2        & \mathbf{1.0841}  & \mathbf{0.001}   & \mathbf{0.919}   & 24.589   & 29.798  & 38.548  \\  
  \hline
\end{array}
\end{aligned}
$
</span>
<br></br>
<span style="color:#d94f0b">
and the centers are respectively
</span>
<br></br>
<span style="color:#d94f0b">
$
\begin{align}
c_1^{(4)}&=7.507,\; c_2^{(4)}=2.041\\
c_1^{(5)}&=7.583,\; c_2^{(5)}=1.999\\
\end{align}
$
<span>
<br></br>
<span style="color:#d94f0b">
<ins>Last iteration</ins>. Interestingly, at the end of iteration 5 we have the following assignment matrix: 
</span>
<br></br>
<span style="color:#d94f0b">
$
\begin{aligned}
\begin{array}{c|cccccc|c}
 \langle \mathbf{M}^{(5)}\rangle  & x_1     & x_2    & x_3    & x_4   & x_5   & x_6 &\sum_{a=1}^m  \langle \mathbf{M}^{(5)}_{ai}\rangle\\
  \hline
  c_1        & 0.000 & 0.000 & 0.000 & 0.999 & 0.999 & 0.999 & 2.997  \\
  c_2        & 0.999 & 0.999 & 0.999 & 0.000 & 0.000 & 0.000 & 2.997  \\  
  \hline
\end{array}
\end{aligned}
$
</span>
<br></br>
<span style="color:#d94f0b">
Note that the first 3 points belong to cluster 2 and the second 3 points belong to cluster 1. Is this enough to converge? Let us see. First of all we recompute the distances: 
</span>
<br></br>
$
\begin{aligned}
\begin{array}{c|cccccc}
  \mathbf{D}^{(6)} & x_1     & x_2    & x_3    & x_4   & x_5   & x_6\\
  \hline
  c_1        & 43.337  & 31.171  & 21.004  & 0.340    &  0.006   &  0.444 \\
  c_2        & 0.999   & 0.000   & 1.000   & 25.000   &  30.250  &  39.062 \\  
  \hline
\end{array}
\end{aligned}
$
</span>
<br></br>
<span style="color:#d94f0b">
Then, the normalized neg-exponentials for $\beta(6)=0.488$ are: 
</span>
<br></br>
<span style="color:#d94f0b">
$
\begin{aligned}
\begin{array}{c|cccccc|c}
 \langle \mathbf{M}^{(6)}\rangle  & x_1     & x_2    & x_3    & x_4   & x_5   & x_6 &\sum_{a=1}^m  \langle \mathbf{M}^{(3)}_{ai}\rangle\\
  \hline
  c_1        & 0.000 & 0.000 & 0.000 & 0.999 & 0.999  & 0.999  & 2.997   \\
  c_2        & 0.999 & 0.999 & 0.999 & 0.000 & 0.000  &  0.000 & 2.997   \\  
  \hline
\end{array}
\end{aligned}
$
</span>
<br></br>
<span style="color:#d94f0b">
Which is clearly "stabilized" wrt $\langle \mathbf{M}^{(5)}\rangle$ (it is identical). As a result, **the cluster centers will be identical** and the algorithm **converges** returning these cluster centers $c_1^{(6)}=c_1^{(5)}$, $c_2^{(6)}=c_2^{(5)}$ and $\langle \mathbf{M}^{\ast}\rangle=\langle \mathbf{M}^{(6)}\rangle$.
</span>
<br></br>


#### Entropy and Free Energy
Deterministic Annealing (DA) relies on the following **theorem**: 

*Minimizing the Free Energy $F(\omega)=-\frac{1}{\beta}\log Z$ is equivalent to maximizing the Entropy $H(G)$ of the Gibbs distribution $G(\omega)=\exp(-\beta{\cal E}(\omega))/Z$, where ${\cal E}(\omega)$ is a cost (energy) function, as follows:*

$$
F(\omega) = \langle {\cal E}(\omega) \rangle - \frac{1}{\beta}H(G)\;.  
$$

**Proof**. We start by expanding the definition of entropy (see the **Appendix**): 

$$
\begin{align}
H(G) &:=-\sum_{\omega}G(\omega)\log G(\omega)\\
     &= -\sum_{\omega}\frac{\exp(-\beta{\cal E}(\omega))}{Z}\log \frac{\exp(-\beta{\cal E}(\omega))}{Z}\\
     &= -\sum_{\omega}\frac{\exp(-\beta{\cal E}(\omega))}{Z}\left[-\beta {\cal E}(\omega) - \log Z\right]\\
     &= -\sum_{\omega}G(\omega)\left[-\beta {\cal E}(\omega) - \log Z\right]\;.\\
\end{align}
$$

Since, $\langle {\cal E}(\omega) \rangle$ is the expectation

$$
\langle {\cal E}(\omega) \rangle = \sum_{\omega}G(\omega){\cal E}(\omega)\;,
$$

we have

$$
\begin{align}
H(G) &= -\sum_{\omega}G(\omega)\left[-\beta {\cal E}(\omega) - \log Z\right]\\
     &= \beta\langle {\cal E}(\omega) \rangle + \sum_{\omega}G(\omega)\log Z\;.\\
\end{align}
$$

Since $G(\omega)$ is a probability distribution, we have $\sum_{\omega}G(\omega)=1$ and therefore 

$$
H(G) = \beta\langle {\cal E}(\omega) \rangle + \log Z\;,
$$

and finally, 

$$
\begin{align}
-\log Z &= \beta\langle {\cal E}(\omega) \rangle - H(G)\\
-\frac{1}{\beta}\log Z &= \langle {\cal E}(\omega) \rangle -\frac{1}{\beta}H(G)\\
F(\omega) &= \langle {\cal E}(\omega)\rangle -\frac{1}{\beta}H(G)\;.\\
\end{align}
$$

Consequently, since $H(G)\ge 0$, we have that minimizing $F(\omega)$ implies minimizing  $\langle {\cal E}(\omega)\rangle$ (known as <span style="color:#f88146">**average cost**</span> or <span style="color:#f88146">**average distortion**</span>) as well as maximizing (i.e. -minimizing) the entropy $H(G)$ if the average cost is kept constant. 

#### Maximum Entropy 
The expansion of Free energy $F(\omega)$ as 

$$
F(\omega) = \langle {\cal E}(\omega) \rangle - \frac{1}{\beta}H(G)\;.  
$$

suggests how it is minimized:
1) In the beginning, where we have $T_{max}$ and $\beta\rightarrow 0$, we have that the dominant term is the negative of entropy $-H(G)$. This means that in the early stages of the algorithm, **entropy is maximized**. 

2) [Maximum Entropy](https://en.wikipedia.org/wiki/Principle_of_maximum_entropy) is a fundamental principle in Information Theory. It states that: *<span style="color:#f88146">of all the probability distributions that satisfy a given set of constraints, choose the one that maximizes the entropy*</span>.

3) Membership probabilities, $\langle\mathbf{M}_{ai}\rangle$ can be interpreted as **conditional probabilities**  

$$
\langle\mathbf{M}_{ai}\rangle = p(\mathbf{x}_a\in \text{cluster}(\mathbf{c}_i))=p(C=
i|X=a)\;,
$$ 

i.e., given a point $\mathbf{x}_a$, $p(C=
i|X=a)$ denotes <span style="color:#f88146">*how likely is $\mathbf{c}_i$ to be the true center for this point*</span>. This is usually called <span style="color:#f88146">**likelihood**</span>: how good is this center for be a <span style="color:#f88146">**codeword**</span> of that point. 

4) As a result, the **conditional entropy** $H(C|X)$ is maximized in the early stages of DA: 

$$
\begin{align}
H(C|X)&= \sum_{\mathbf{x}_a}p(X=a)H(C|X=a)\\
      &\approx \frac{1}{m}\sum_{\mathbf{x}_a}H(C|X=a)\\
      &= -\frac{1}{m}\sum_{\mathbf{x}_a}\sum_{\mathbf{c}_i}p(C=i|X=a)\log p(C=i|X=a)\\
      &= -\frac{1}{m}\sum_{a}\sum_{i}\langle\mathbf{M}_{ai}\rangle\log \langle\mathbf{M}_{ai}\rangle\\
\end{align}
$$

However, should be interesting to compute also the conditional entropy $H(X|C)$ so that we can visualize the **entropy per cluster** instead of the **entropy per point** as in $H(C|X)$. To this end, look at the Bayes theorem:

$$
p(X|C)=\frac{p(C|X)p(X)}{p(C)}\;.
$$

We assume $p(X=a)=\frac{1}{m}$ since we don't know how probable is a specific data in advance. But, how to estimate $p(C)$ we exploit the following property: 

$$
\begin{align}
p(C=i) &= \sum_{\mathbf{x}_a}p(X=a)p(C=i|X=a)\\ 
       &= \frac{1}{m}\sum_{\mathbf{x}_a}p(C=i|X=a)\\
       &= \frac{1}{m}\sum_{a}\langle\mathbf{M}_{ai}\rangle\\
\end{align}
$$

Then, we have that

$$
p(X=a|C=i)=\frac{\frac{1}{m}\langle\mathbf{M}_{ai}\rangle}{\frac{1}{m}\sum_{a}\langle\mathbf{M}_{ai}\rangle} = \frac{\langle\mathbf{M}_{ai}\rangle}{\sum_{a}\langle\mathbf{M}_{ai}\rangle}
$$

And finally

$$
\begin{align}
H(X|C) &= \sum_{\mathbf{c}_i}p(C=i)H(X|C=i)\\
       &\approx \frac{1}{m}\sum_{\mathbf{c}_i}\sum_{a}\langle\mathbf{M}_{ai}\rangle H(X|C=i)\;,\\
\end{align}
$$

where

$$
H(X|C=i) &= -\sum_{\mathbf{x}_a}p(X=a|C=i)\log p(X=a|C=i)\\
         &= -\sum_{a}\frac{\langle\mathbf{M}_{ai}\rangle}{\sum_{a}\langle\mathbf{M}_{ai}\rangle}\log \frac{\langle\mathbf{M}_{ai}\rangle}{\sum_{a}\langle\mathbf{M}_{ai}\rangle}\;.
$$

is the <span style="color:#f88146">**entropy per cluster** $i$</span> and it is a good quantity to analyze the **convergence of the algorithm**. 

Look, for instance, at {numref}`KM-entropy-example` for the solutions of the above exercise where $\langle M_{ai}\rangle$ behave like Bernouilli variables when we have two clusters. At the last iteration, the **maximal entropy per cluster** is lower than the initial one: it is around $1$ bit (i.e. $\log 3=1.09$ nats) because half of the points belong to each cluster and half of them do not. This **indicates good convergence**

```{figure} ./images/Topic2/KM-entropy-example-removebg-preview.png
---
name: KM-entropy-example
width: 800px
align: center
height: 600px
---
DA as entropy minimization in the exercise example. 
```

However, as we show in {numref}`KM-entropy-example-K3` in the motivating example for $k=3$ clusters, the final **maximal entropy per cluster** is around $4-5$ bits (i.e. $\log 102 = 4.62$ nats). This indicates that the data is <span style="color:#f88146">**not well quantized**</span> with $k=3$ centers.


```{figure} ./images/Topic2/KM-entropy-example-K3-removebg-preview.png
---
name: KM-entropy-example-K3
width: 800px
align: center
height: 600px
---
DA as entropy minimization the motivating example (K=3). 
```

However, as we show in {numref}`KM-entropy-example-K2` in the motivating example for $k=3$ clusters, the final **maximal entropy per cluster** is around $5$ bits (i.e. $\log 201 = 5.30$ nats). This indicates that the data is <span style="color:#f88146">**better quantized**</span> with $k=2$ centers: <span style="color:#f88146">we get (nearly) the same entropy with less centers!</span>

```{figure} ./images/Topic2/KM-entropy-example-K2-removebg-preview.png
---
name: KM-entropy-example-K2
width: 800px
align: center
height: 600px
---
DA as entropy minimization the motivating example (K=2). 
```

Actually, the new centers are $\mathbf{c}_1=[0,-1]^T$ and $\mathbf{c}_2=[0,2]^T$ (see {numref}`KM-clusters-K2`). 

```{figure} ./images/Topic2/KM-clusters-K2-removebg-preview.png
---
name: KM-clusters-K2
width: 800px
align: center
height: 600px
---
Clusters and estimated prototypes in $\mathbb{R}^2$ (K=2). 
```

As a result, <span style="color:#f88146">**entropy is crucial** for the interpretation of clustering problems!</span>
-->
</section>
</section>
<section id="softmax-for-graph-matching">
<h2><span class="section-number">2.4. </span>SoftMax for Graph Matching<a class="headerlink" href="#softmax-for-graph-matching" title="Permalink to this heading">#</a></h2>
<section id="softmaxing">
<h3><span class="section-number">2.4.1. </span>SoftMaxing<a class="headerlink" href="#softmaxing" title="Permalink to this heading">#</a></h3>
<section id="continuation-methods">
<h4><span class="section-number">2.4.1.1. </span>Continuation Methods<a class="headerlink" href="#continuation-methods" title="Permalink to this heading">#</a></h4>
<p>Back to the graph matching problem or MCS (Maximum Common Subgraph), we have formulated it in
<span style="color:#f88146"><strong>discrete terms</strong> via SA</span>:</p>
<ol class="arabic simple">
<li><p>The search space <span class="math notranslate nohighlight">\({\cal P}\)</span> is the set of <strong>binary matrices</strong>
<span class="math notranslate nohighlight">\(\mathbf{M}\in\{0,1\}^{m\times n}\)</span> whose rows and columns have a unique <span class="math notranslate nohighlight">\(1\)</span>. When <span class="math notranslate nohighlight">\(m=n\)</span> we have that the search space is
the Permuthoedron <span class="math notranslate nohighlight">\(\Pi_n\)</span>, i.e. the set of <strong>permutation matrices</strong>.</p></li>
<li><p>SA explores the search space via <strong>random walks</strong> that eventually hit the <strong>global maximum</strong>
under a <strong>slow annealing schedule</strong>. Each iteration takes <span class="math notranslate nohighlight">\(O(n^4)\)</span> for evaluating the
quadratic cost function <span class="math notranslate nohighlight">\(F(\mathbf{M})\)</span>.</p></li>
</ol>
<!--
We have seen that central clustering can be posed, however, in <span style="color:#f88146">**continuous terms** via DA</span>:
1) The search space is $\mathbb{R}^d\times {\cal P}$: we have to jointly find $k$ centers 
$\mathbf{c}_i\in\mathbb{R}^d$ and a binary matrix $\mathbf{M}\in\{0,1\}^{m\times k}$ indicating 
how the $m$ points $\mathbf{x}_a\in\mathbb{R}^d$ are assigned to the most probable cluster.

2) DA **decouples the optimization** of the Free energy $F({\cal C},\mathbf{M})$: given a high-entropic 
(almost uniform) initial assignment we alternate **expectation** (update the assignments while
the centers are fixed) and **update** the centers. Each iteration takes $O(m\times k)$ and 
it **allows faster annealing schedules**. 

3) <span style="color:#f88146">**Remember**</span> that DA's success relies on the possibility of evaluating $Z$ 
(the Gibbs partition function) thanks to the **independence assumption**: points are assumed to 
be independently assigned to any cluster.  

-->
<p>In the <a class="reference external" href="https://gurobi-optimods.readthedocs.io/en/latest/index.html">Gurobi framework </a>,
for optimization, where graph matching is seen as a Maximmum Clique, many combinatorial algorithm share
the following features with DA:</p>
<ol class="arabic simple">
<li><p><strong>Transforming</strong> the original discrete problem into a continuous one.</p></li>
<li><p><strong>Optimize</strong> the objective function in the continuous space by means of a polynomial method.</p></li>
<li><p><strong>Revert</strong> the result to the discrete space through a <em>clean-up</em> heuristic.</p></li>
</ol>
<p>These methods are called <span style="color:#f88146"><strong>continuation method</strong></span>.</p>
</section>
<section id="softmax-operator">
<h4><span class="section-number">2.4.1.2. </span>SoftMax operator<a class="headerlink" href="#softmax-operator" title="Permalink to this heading">#</a></h4>
<p>In 1996, <a class="reference external" href="https://www.cise.ufl.edu/~anand/pdf/pamigm3.pdf">Steven Gold and Anand Rangarajan</a>
exploited the following <strong>simple algorithm</strong> for finding the maximum element in a list
of numbers:</p>
<div class="proof algorithm admonition" id="Softmax-alg">
<p class="admonition-title"><span class="caption-number">Algorithm 2.2 </span> (Soft Maximum)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inputs</strong> A list of elements <span class="math notranslate nohighlight">\(L=[X_1,\ldots,X_m]\)</span> with <span class="math notranslate nohighlight">\(X_i\in\mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(\beta_0&gt;0\)</span><br />
<strong>Outputs</strong> <span class="math notranslate nohighlight">\(m_i&gt;0\)</span> if <span class="math notranslate nohighlight">\(X_i=\max_{L}\)</span> and <span class="math notranslate nohighlight">\(0\)</span> otherwise.</p>
<ol class="arabic">
<li><p>Initialize <span class="math notranslate nohighlight">\(\beta\leftarrow \beta_0\)</span></p></li>
<li><p><strong>while</strong> <span class="math notranslate nohighlight">\(\beta &lt; \beta_f\)</span>:</p>
<ol class="arabic">
<li><p><strong>for</strong> <span class="math notranslate nohighlight">\(i=1,\ldots, m\)</span>:</p>
<p><span class="math notranslate nohighlight">\(m_i\leftarrow \exp(\beta X_i)\)</span></p>
</li>
<li><p><strong>for</strong> <span class="math notranslate nohighlight">\(i=1,\ldots, m\)</span>:</p>
<p><span class="math notranslate nohighlight">\(m_i\leftarrow \frac{m_i}{\sum_{i=1}^m m_i}\)</span></p>
</li>
<li><p>Update <span class="math notranslate nohighlight">\(X_i\)</span></p></li>
<li><p>Increase <span class="math notranslate nohighlight">\(\beta\)</span></p></li>
</ol>
</li>
<li><p><strong>return</strong> <span class="math notranslate nohighlight">\(\{m_i\}\)</span> where <span class="math notranslate nohighlight">\(\sum_{i=1}^m m_i=1\)</span></p></li>
</ol>
</section>
</div><p>This algorithm is equivalent to give the <span class="math notranslate nohighlight">\(\{m_i\}\)</span> which maximize
<span class="math notranslate nohighlight">\(\sum_{i=1}^m m_iX_i\)</span>, now formulated in continuous terms via the <strong>control parameter</strong>
<span class="math notranslate nohighlight">\(\beta&gt;0\)</span>. This is the <strong>softmax</strong> operator:</p>
<div class="math notranslate nohighlight">
\[
m_j = \frac{\exp(\beta X_j)}{\sum_{i=1}^m\exp(\beta X_i)}\;,
\]</div>
<p>which is the classical mechanism to select class-membership in the last layer of a neural network!</p>
<p>We show this mechanism in <a class="reference internal" href="#daexample"><span class="std std-numref">Fig. 2.18</span></a>. As we increase <span class="math notranslate nohighlight">\(\beta\)</span>, the <span class="math notranslate nohighlight">\(m_i\)</span> corresponding to the maximum <span class="math notranslate nohighlight">\(X_i\)</span>
(note that there may be many maximal values) tend to <span class="math notranslate nohighlight">\(1\)</span>, whereas the <span class="math notranslate nohighlight">\(m_i\)</span> for the non-maximal values drop to <span class="math notranslate nohighlight">\(0\)</span>.
In the neural-network jargon, this mechanism is dubbed as <strong>winner takes all</strong> or <strong>WTA</strong>.</p>
<figure class="align-center" id="daexample">
<a class="reference internal image-reference" href="_images/DAExample-Photoroom.png"><img alt="_images/DAExample-Photoroom.png" src="_images/DAExample-Photoroom.png" style="width: 800px; height: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.18 </span><span class="caption-text">Softmaxing a list of real-valued elements. Herein, <span class="math notranslate nohighlight">\(X_i\)</span> are not updated per iteration, to show the role of <span class="math notranslate nohighlight">\(m_i\)</span>.</span><a class="headerlink" href="#daexample" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="graduated-assignment">
<h3><span class="section-number">2.4.2. </span>Graduated Assignment<a class="headerlink" href="#graduated-assignment" title="Permalink to this heading">#</a></h3>
<section id="linear-assignment">
<h4><span class="section-number">2.4.2.1. </span>Linear Assignment<a class="headerlink" href="#linear-assignment" title="Permalink to this heading">#</a></h4>
<p>Linear Assignment (LA) is polinomial problem with many applications in Computer Science and AI.
Given a <strong>bipartite graph</strong> <span class="math notranslate nohighlight">\(G=(V,E)\)</span> where: a) <span class="math notranslate nohighlight">\(V = V_1\cup V_2\)</span>,<span class="math notranslate nohighlight">\(V_1\cap V_2=\emptyset\)</span> is
a vertex partition and b) <span class="math notranslate nohighlight">\(E=V_1\times V_2\)</span>, i.e. there are only edges between <span class="math notranslate nohighlight">\(V_1\)</span> and <span class="math notranslate nohighlight">\(V_2\)</span>.
In addition, the graph is <strong>weighted</strong> since we are given a matrix of variables
<span class="math notranslate nohighlight">\(\mathbf{X}\in\mathbb{R}^{m\times n}\)</span>, with <span class="math notranslate nohighlight">\(m=|V_1|\)</span>, <span class="math notranslate nohighlight">\(n=|V_2|\)</span>, where <span class="math notranslate nohighlight">\(\mathbf{X}_{ai}\)</span> measures the <strong>affinity</strong>
between <span class="math notranslate nohighlight">\(i\in V_1\)</span> and <span class="math notranslate nohighlight">\(j\in V_2\)</span> and its meaning depends on the problem (compatibility between processes and
CPUs, local similarity between points of two shapes, etc).</p>
<p>The <span style="color:#f88146"><strong>discrete</strong> (original) version</span> of LA is kind of obvious:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbf{M}^{\ast} &amp;= \arg\max_{{\cal P}} E(\mathbf{M})=\sum_{a\in V_1}\sum_{i\in V_2}\mathbf{M}_{ai}\mathbf{X}_{ai}\\
{\cal P}=&amp;\left\{\mathbf{M}\in \{0,1\}^{m\times n}:\forall a\in V_1:\sum_{i\in V_2}\mathbf{M}_{ai}\le 1\;\text{and}\; \forall i\in V_2:\sum_{a\in V_1}\mathbf{M}_{ai}\le 1\;\right\}
\end{align}
\end{split}\]</div>
<p>In other words, <span style="color:#f88146">LA is the <strong>linear version</strong> of QAP</span> where <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> is <strong>real-valued</strong>
instead of being an adjacency matrix. Concerning the search space, if <span class="math notranslate nohighlight">\(m=n\)</span> then <span class="math notranslate nohighlight">\({\cal P}=\Pi_n\)</span>
space is the Permuthoedron. However, it is not in NP and actually it can be solved in <span class="math notranslate nohighlight">\(O(n^3)\)</span> with
the so called <a class="reference external" href="https://en.wikipedia.org/wiki/Hungarian_algorithm">Hungarian algorithm</a>.</p>
<p>However, herein we are going to introduce the <span style="color:#f88146"><strong>soft/continuous</strong> version</span> which
is basically an extension of <strong>SoftMax</strong> incorporating:</p>
<ul class="simple">
<li><p><strong>Continuous assingments</strong>. Instead of <span class="math notranslate nohighlight">\(\mathbf{M}\in \{0,1\}^{m\times n}\)</span> we have <span class="math notranslate nohighlight">\(\mathbf{M}\in [0,1]^{m\times n}\)</span>.</p></li>
<li><p><strong>Two-way constraints</strong>. Each <span class="math notranslate nohighlight">\(i\in V_1\)</span> has a <strong>probability</strong> of being assigned to <span class="math notranslate nohighlight">\(a\in V_2\)</span> and viceversa. Therefore:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\forall a:\sum_{i=1}^n\mathbf{M}_{ai}=1\;\;\text{and}\;\;\forall i:\sum_{a=1}^m\mathbf{M}_{ai}=1\;.
\]</div>
<p>i.e. our search space is a matricial generalization of the <span style="color:#f88146">(vectorial) <strong>simplex</strong></span>:</p>
<div class="math notranslate nohighlight">
\[
\Delta_n =\left\{\{m_i\}\in\mathbb{R}^n:\sum_{i=1}^nm_i=1\right\}\;.
\]</div>
<p>Actually, if <span class="math notranslate nohighlight">\(m=n\)</span> the search space is not the Permuthoedron <span class="math notranslate nohighlight">\(\Pi_n\)</span> but the
<a class="reference external" href="https://en.wikipedia.org/wiki/Doubly_stochastic_matrix">Birkhoff polytope</a> <span class="math notranslate nohighlight">\(\mathbb{B}_n\)</span>. In matricial
terms, <span class="math notranslate nohighlight">\(\mathbb{B}_n\)</span> is the set of <strong>doubly stochastic</strong> matrices (matrices whose rows and columns add <span class="math notranslate nohighlight">\(1\)</span>).
In this regard, remember that <span class="math notranslate nohighlight">\(\Pi_n\subset \mathbb{B}_n\)</span> since every permutation matrix is doubly stochastic.
Therefore, the vertices of the Birkhoff polytope are the elements of <span class="math notranslate nohighlight">\(\Pi_n\)</span> (solutions to the discrete problem)
but during the resolution of the problem <span style="color:#f88146"><strong>continuous solutions</strong> lying in the
edges and sides of the polytope are <strong>allowed</strong></span>.</p>
<p>Algorithmically, the <strong>SoftLA</strong> needs to <strong>enforce the two-way constraints</strong> in every iteration as follows:</p>
<div class="proof algorithm admonition" id="SoftLA-alg">
<p class="admonition-title"><span class="caption-number">Algorithm 2.3 </span> (SoftLA)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inputs</strong> Affinity matrix <span class="math notranslate nohighlight">\(\mathbf{X}\in\mathbb{R}^{m\times n}\)</span>, <span class="math notranslate nohighlight">\(\beta_0&gt;0\)</span><br />
<strong>Outputs</strong> <span class="math notranslate nohighlight">\(\mathbf{M}^{\ast}\)</span> maximal assignment.</p>
<ol class="arabic simple">
<li><p>Initialize <span class="math notranslate nohighlight">\(\beta\leftarrow \beta_0\)</span></p></li>
<li><p>Initialize <span class="math notranslate nohighlight">\(\mathbf{M}_{ai}\leftarrow (1+\epsilon)\)</span></p></li>
<li><p><strong>while</strong> <span class="math notranslate nohighlight">\(\beta &lt; \beta_f\)</span>:</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{Q}_{ai}\leftarrow \mathbf{M}_{ai}\mathbf{X}_{ai}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}_{ai}\leftarrow \exp(\beta \mathbf{Q}_{ai})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\leftarrow\text{Sinkhorn}(\mathbf{M})\)</span></p></li>
<li><p>Increase <span class="math notranslate nohighlight">\(\beta\)</span></p></li>
</ol>
</li>
<li><p><strong>return</strong> <span class="math notranslate nohighlight">\(\mathbf{M}^{\ast}\)</span> optimal doubly-stochastic matrix.</p></li>
</ol>
</section>
</div><p>where <span class="math notranslate nohighlight">\(\text{Sinkhorn}(\mathbf{M})\)</span> is an iterative row-col normalization process which
converges to a stochastic matrix:</p>
<div class="proof algorithm admonition" id="Sinkhorn-alg">
<p class="admonition-title"><span class="caption-number">Algorithm 2.4 </span> (Sinkhorn)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inputs</strong> Exponential assignment matrix: <span class="math notranslate nohighlight">\(\mathbf{M}=\exp(\beta\mathbf{X})\)</span><br />
<strong>Outputs</strong> <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> doubly-stochastic matrix.</p>
<ol class="arabic">
<li><p><span class="math notranslate nohighlight">\(t\leftarrow 0\)</span></p></li>
<li><p>convergence<span class="math notranslate nohighlight">\(\leftarrow\)</span> False</p></li>
<li><p><strong>while</strong> <span class="math notranslate nohighlight">\(\neg\)</span>convergence:</p>
<ol class="arabic">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}^{old}_{ai}\leftarrow \mathbf{M}_{ai}\)</span></p></li>
<li><p><strong>for</strong> <span class="math notranslate nohighlight">\(a=1,2,\ldots,m\)</span> (Normalize rows)</p>
<p><span class="math notranslate nohighlight">\(\mathbf{M}_{ai}\leftarrow \frac{\mathbf{M}_{ai}}{\sum_{i=1}^n \mathbf{M}_{ai}}\)</span></p>
</li>
<li><p><strong>for</strong> <span class="math notranslate nohighlight">\(i=1,2,\ldots,n\)</span> (Normalize cols)</p>
<p><span class="math notranslate nohighlight">\(\mathbf{M}_{ai}\leftarrow \frac{\mathbf{M}_{ai}}{\sum_{i=a}^m \mathbf{M}_{ai}}\)</span></p>
</li>
<li><p><span class="math notranslate nohighlight">\(t\leftarrow t + 1\)</span></p></li>
<li><p>convergence = <span class="math notranslate nohighlight">\((t&gt;t_{max})\)</span> <strong>or</strong> <span class="math notranslate nohighlight">\((\sum_{ai}|\mathbf{M}_{ai}- \mathbf{M}^{old}_{ai}|\le\epsilon )\)</span></p></li>
</ol>
</li>
<li><p><strong>return</strong> <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> doubly-stochastic matrix.</p></li>
</ol>
</section>
</div><p>Interestingly, the structure of <span class="math notranslate nohighlight">\(\text{SoftLa}\)</span> is rather simple and essentially is the similar to that
of <span class="math notranslate nohighlight">\(\text{SoftMax}\)</span> but for matrices, taking <span class="math notranslate nohighlight">\(O(n^2)\)</span> instead of <span class="math notranslate nohighlight">\(O(n^3)\)</span> as the Hungarian algorithm.</p>
<p>In <a class="reference internal" href="#hungarian"><span class="std std-numref">Fig. 2.19</span></a> we show how <span class="math notranslate nohighlight">\(\text{SoftLa}\)</span> solves a problem in a couple of
iterations</p>
<figure class="align-center" id="hungarian">
<a class="reference internal image-reference" href="_images/SA-Hungarian-removebg-preview.png"><img alt="_images/SA-Hungarian-removebg-preview.png" src="_images/SA-Hungarian-removebg-preview.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.19 </span><span class="caption-text">SoftLA solution for a <span class="math notranslate nohighlight">\(m=n=5\)</span> instance with random costs.</span><a class="headerlink" href="#hungarian" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Note that:</p>
<ol class="arabic simple">
<li><p>The general initialization is the matrix of ones with a slight perturbation: <span class="math notranslate nohighlight">\(\mathbf{M}^0_{ai}=1+\epsilon\)</span>. This
initialization is known as <strong>baricenter</strong> or <strong>neutral</strong>.</p></li>
<li><p>In the above example, <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> is drawn from <span class="math notranslate nohighlight">\(n\times n\)</span> <strong>random</strong> integers between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(n^2-1\)</span>.</p></li>
<li><p>The role of <span class="math notranslate nohighlight">\(\text{Sinkhorn}\)</span> is to enforce the two-way constraints and sometimes it may lead
to a very entropic doubly-stochastic matrix as we show in the following exercise.
<br></br>
<span style="color:#d94f0b">
<strong>Exercise</strong>. Prove that applying <span class="math notranslate nohighlight">\(\text{Sinkhorn}\)</span> to the exponentiation of the above matrix
converges to a maximum entropy assignment. Do not use <span class="math notranslate nohighlight">\(\beta\)</span>. Explain <strong>why</strong>.
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\mathbf{X}=
\begin{bmatrix}
x          &amp; x+\epsilon\\
x-\epsilon &amp; x\\
\end{bmatrix}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
A priori, it seems that the optimal assignment is <span class="math notranslate nohighlight">\((a=1)\rightarrow (i=2)\)</span> and <span class="math notranslate nohighlight">\((a=2)\rightarrow (i=2)\)</span>
but this is not possible due to the two-way constraint. Let us apply the exponential:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\mathbf{M}=
\begin{bmatrix}
e^x          &amp; e^{x+\epsilon}\\
e^{x-\epsilon} &amp; e^x\\
\end{bmatrix}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<ins>Row normalization</ins> makes things independent of <span class="math notranslate nohighlight">\(x\)</span>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
\mathbf{M} &amp;=
\begin{bmatrix}
\frac{e^x}{e^x + e^{x+\epsilon}}   &amp; \frac{e^{x+\epsilon}}{e^x + e^{x+\epsilon}}\\
\frac{e^{x-\epsilon}}{e^x + e^{x-\epsilon}} &amp; \frac{e^x}{e^x + e^{x-\epsilon}}\\
\end{bmatrix}
=\begin{bmatrix}
\frac{1}{1 + e^{\epsilon}}   &amp; \frac{e^{\epsilon}}{1 + e^{\epsilon}}\\
\frac{e^{-\epsilon}}{1 + e^{-\epsilon}} &amp; \frac{1}{1 + e^{-\epsilon}}\\
\end{bmatrix}
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<ins>Column normalization</ins>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
\mathbf{M}_{:1} &amp;= \frac{1}{1 + e^{\epsilon}}  + \frac{e^{-\epsilon}}{1 + e^{-\epsilon}} 
              = \frac{(1 + e^{-\epsilon})+e^{-\epsilon}(1 + e^{\epsilon})}{(1 + e^{\epsilon})(1 + e^{-\epsilon})}
              = \frac{(1 + e^{-\epsilon}) + (1 + e^{-\epsilon})}{(1 + e^{\epsilon})(1 + e^{-\epsilon})}
              = \frac{2}{1 + e^{\epsilon}}\\
\mathbf{M}_{:2} &amp;= \frac{e^{\epsilon}}{1 + e^{\epsilon}} + \frac{1}{1 + e^{-\epsilon}}
              = \frac{e^{\epsilon}(1 + e^{-\epsilon}) + (1 + e^{\epsilon})}{(1 + e^{\epsilon})(1 + e^{-\epsilon})}
              = \frac{(1 + e^{\epsilon}) + (1 + e^{\epsilon})}{(1 + e^{\epsilon})(1 + e^{-\epsilon})}
              = \frac{2}{1 + e^{-\epsilon}}
\end{align}   
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
\mathbf{M} &amp;=
\begin{bmatrix}
\frac{\mathbf{M}_{a1}}{\mathbf{M}_{:1}}   &amp; \frac{\mathbf{M}_{a2}}{\mathbf{M}_{:2}} \\
\frac{\mathbf{M}_{b1}}{\mathbf{M}_{:1}}   &amp; \frac{\mathbf{M}_{b2}}{\mathbf{M}_{:2}} \\
\end{bmatrix} 
= \begin{bmatrix}
\frac{1}{1 + e^{\epsilon}}:\frac{2}{1 + e^{\epsilon}}              &amp; \frac{e^{\epsilon}}{1 + e^{\epsilon}}:\frac{2}{1 + e^{-\epsilon}}\\
\frac{e^{-\epsilon}}{1 + e^{-\epsilon}}:\frac{2}{1 + e^{\epsilon}} &amp; \frac{1}{1 + e^{-\epsilon}}:\frac{2}{1 + e^{-\epsilon}}\\
\end{bmatrix}
= \begin{bmatrix}
\frac{1}{2}   &amp; \frac{1}{2}\\
\frac{1}{2}   &amp; \frac{1}{2}\\
\end{bmatrix}
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
which proves the statement. <strong>Why</strong>? Well, adding an <span class="math notranslate nohighlight">\(\epsilon\)</span> in one column and
subracting it in the opposite column leads to maximal uncertainty wrt the diagonal
which is preserved. This is not obvious, and even <strong>counter-ituitive</strong>, but it is a bit clarified by the removal of
<span class="math notranslate nohighlight">\(x\)</span> after row normalization.
</span>
<br></br></p></li>
</ol>
</section>
<section id="softassign">
<h4><span class="section-number">2.4.2.2. </span>SoftAssign<a class="headerlink" href="#softassign" title="Permalink to this heading">#</a></h4>
<p>The extension of <span class="math notranslate nohighlight">\(\text{SoftLa}\)</span> to graph matching is almost straight. Now, instead of
having a linear cost function, the graph-matching cost function is <strong>quadratic</strong> in <span class="math notranslate nohighlight">\(\mathbf{M}\)</span>
(it is the QAP-Quadratic Assignment Problem). Then, the <span style="color:#f88146"><strong>relaxed QAP</strong></span> becomes</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbf{M}^{\ast}= &amp; \arg\max_{{\cal B}}F(\mathbf{M}) = \frac{1}{2}\sum_{a\in V}\sum_{i\in V'}\sum_{b\in V}\sum_{j\in V'}\mathbf{M}_{ai}\mathbf{M}_{bj}\mathbf{X}_{ab}\mathbf{Y}_{ij}\\
{\cal B}=&amp;\left\{\mathbf{M}\in [0,1]^{(m+1)\times (n+1)}:\forall a\in V:\sum_{i\in V'}\mathbf{M}_{ai}=1\;\text{and}\; \forall i\in V':\sum_{a\in V}\mathbf{M}_{ai}=1\;\right\}
\end{align}
\end{split}\]</div>
<p>where</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\({\cal B}\)</span> is the set of doubly-stochastic matrices of dimension <span class="math notranslate nohighlight">\((m+1)\times (n+1)\)</span>, and
the Birkhoff polytope or order <span class="math notranslate nohighlight">\(n+1\)</span>, i.e. <span class="math notranslate nohighlight">\({\cal B}_{n+1}\)</span>, if <span class="math notranslate nohighlight">\(m=n\)</span>.</p></li>
<li><p>Why an <strong>extra dimension</strong>? If <span class="math notranslate nohighlight">\(m&lt;n\)</span>, for instance, we can only have <span class="math notranslate nohighlight">\(m\)</span> one-to-one assignments
and <span class="math notranslate nohighlight">\(n-m\)</span> un-assigned nodes. In order to deal with this, we assume that these un-asigned nodes
match a <span style="color:#f88146"><strong>slack</strong> or <strong>virtual</strong> node</span>.
Therefore, adding an extra dimension accomodates two virtual
nodes (one per graph). Similar reasoning for <span class="math notranslate nohighlight">\(m&gt;n\)</span>.</p></li>
</ol>
<p>Note that <span class="math notranslate nohighlight">\(\text{SoftLA}\)</span> is just a Deterministic Annealing (DA) applied to linear assignment.
If so, one of the driving features of DA is to <span style="color:#f88146">assume <strong>assignment independence</strong></span>,
i.e. we may assume that the <em>assignment of <span class="math notranslate nohighlight">\(a\in V\)</span> to <span class="math notranslate nohighlight">\(i\in V'\)</span> is independent of that of
another <span class="math notranslate nohighlight">\(a'\in V\)</span> to <span class="math notranslate nohighlight">\(i'\in V'\)</span></em>.</p>
<p><strong>Taylor Expansion</strong>. <a class="reference external" href="https://www.cise.ufl.edu/~anand/pdf/pamigm3.pdf">Steven Gold and Anand Rangarajan</a> used a similar principle
to approximate the quadratic cost function. Note that <span class="math notranslate nohighlight">\(f(x)\approx f(a) + f'(a)(x-a)\)</span> is
the first order Taylor expansion. Then</p>
<div class="math notranslate nohighlight">
\[
F(\mathbf{M})\approx F(\mathbf{M}^0) + F'(\mathbf{M}^0)\cdot\sum_{a\in V}\sum_{i\in V}(\mathbf{M}_{ai}-\mathbf{M}^0_{ai})\;.
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}
F'(\mathbf{M}^0):={\frac{\partial F}{\partial\mathbf{M}_{a_i}}}\bigg|_{\mathbf{M}^0}=\underbrace{\sum_{b\in V}\sum_{j\in V'}\mathbf{M}_{bj}\mathbf{X}_{ab}\mathbf{Y}_{ij}}_{\mathbf{Q}_{ai}}\\
\end{split}\]</div>
<p>i.e. the derivative of a quadratic function is a linear one! Then, for a fixed <span class="math notranslate nohighlight">\(\mathbf{M}^0\)</span>, we
have that</p>
<div class="math notranslate nohighlight">
\[
\max F(\mathbf{M}) = \max \sum_{a\in V}\sum_{i\in V}\mathbf{M}_{ai}\mathbf{Q}_{ai}\;,
\]</div>
<p>i.e. a <strong>linear assignment problem</strong>.
In other words:</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{Q}_{ai}=\sum_{b\in V}\sum_{j\in V'}\mathbf{M}_{bj}\mathbf{X}_{ab}\mathbf{Y}_{ij}\)</span> works as
a <strong>temporary affinity matrix</strong> for each <span class="math notranslate nohighlight">\(\beta\)</span>.</p></li>
<li><p>Given <span class="math notranslate nohighlight">\(\mathbf{Q}_{ai}\)</span> we iterate to get the best (maximal) assignment <span class="math notranslate nohighlight">\(\mathbf{M}_{ai}\)</span> for this
<span class="math notranslate nohighlight">\(\beta\)</span>, i.e. we solve a <strong>new assignment problem</strong>.</p></li>
<li><p>Increase <span class="math notranslate nohighlight">\(\beta\)</span> and start again!</p></li>
</ol>
<p>This is the typical <strong>decoupled structure</strong> of DA problems and it leads to the
<span class="math notranslate nohighlight">\(\text{SoftAssign}\)</span> algorithm detailed below.</p>
<div class="proof algorithm admonition" id="SoftAssign-alg">
<p class="admonition-title"><span class="caption-number">Algorithm 2.5 </span> (SoftAssign)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inputs</strong> Adjacency matrices <span class="math notranslate nohighlight">\(\mathbf{X}\in\{0,1\}^{m\times m}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{Y}\in\{0,1\}^{n\times n}\)</span>,  <span class="math notranslate nohighlight">\(\beta_0&gt;0\)</span><br />
<strong>Outputs</strong> <span class="math notranslate nohighlight">\(\hat{\mathbf{M}}^{\ast}\)</span> (extended) maximal quadratic assignment.</p>
<ol class="arabic simple">
<li><p>Initialize <span class="math notranslate nohighlight">\(\beta\leftarrow \beta_0\)</span></p></li>
<li><p>Initialize <span class="math notranslate nohighlight">\(\mathbf{M}_{ai}\leftarrow 1+\epsilon\)</span></p></li>
<li><p><strong>while</strong> <span class="math notranslate nohighlight">\(\beta &lt; \beta_f\)</span>:</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(t\leftarrow 0\)</span></p></li>
<li><p>convergence<span class="math notranslate nohighlight">\(\leftarrow\)</span> False</p></li>
<li><p><strong>while</strong> <span class="math notranslate nohighlight">\(\neg\)</span>convergence:</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}^{old}_{ai}\leftarrow \mathbf{M}_{ai}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{Q}_{ai}\leftarrow \sum_{b=1}^m\sum_{j=1}^n\mathbf{M}_{bj}\mathbf{X}_{ab}\mathbf{Y}_{ij}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}^0_{ai}\leftarrow \exp(\beta \mathbf{Q}_{ai})\)</span></p></li>
<li><p>Expand <span class="math notranslate nohighlight">\(\mathbf{M}^0\rightarrow \hat{\mathbf{M}}^0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{\mathbf{M}}^0\leftarrow\text{Sinkhorn}(\hat{\mathbf{M}}^0)\)</span></p></li>
<li><p>De-expand <span class="math notranslate nohighlight">\(\mathbf{M}\leftarrow \hat{\mathbf{M}}^0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(t\leftarrow t + 1\)</span></p></li>
<li><p>convergence = <span class="math notranslate nohighlight">\((t&gt;t_{max})\)</span> <strong>or</strong> <span class="math notranslate nohighlight">\((\sum_{ai}|\mathbf{M}_{ai}- \mathbf{M}^{old}_{ai}|\le\epsilon' )\)</span></p></li>
</ol>
</li>
<li><p>Increase <span class="math notranslate nohighlight">\(\beta\)</span></p></li>
</ol>
</li>
<li><p><strong>return</strong> <span class="math notranslate nohighlight">\(\hat{\mathbf{M}}^{\ast}\)</span> optimal doubly-stochastic matrix.</p></li>
</ol>
</section>
</div><p>Some notes:</p>
<ol class="arabic simple">
<li><p>If <span class="math notranslate nohighlight">\(m\neq n\)</span> we always assume <span class="math notranslate nohighlight">\(m\le n\)</span>, i.e. <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> is the smallest graph.</p></li>
<li><p>In step <span class="math notranslate nohighlight">\(3.4\)</span> we expand explicitly <span class="math notranslate nohighlight">\(\mathbf{M}^0\)</span> by incorporating an additiona row and column
of zeros. Note that <span class="math notranslate nohighlight">\(\text{Sinkhorn}\)</span> <strong>always needs</strong> a <span class="math notranslate nohighlight">\((m+1)\times (n+1)\)</span> matrix if <span class="math notranslate nohighlight">\(m\neq n\)</span>!</p></li>
</ol>
<p><strong>Complexity</strong>. It is not difficult to see that the complexity of <span class="math notranslate nohighlight">\(\text{SoftAssign}\)</span> is
roughtly <span class="math notranslate nohighlight">\(O(n^3)\)</span>, or more precisely <span class="math notranslate nohighlight">\(O(|E|n)\)</span>, if <span class="math notranslate nohighlight">\(m=n\)</span> and <span class="math notranslate nohighlight">\(|E|\)</span> is the number of edges.
Such a complexity is due to step 3.2 (the computation of <span class="math notranslate nohighlight">\(\mathbf{Q}\)</span> which involves the
product of 3 matrices).</p>
</section>
<section id="overview">
<h4><span class="section-number">2.4.2.3. </span>Overview<a class="headerlink" href="#overview" title="Permalink to this heading">#</a></h4>
<p>Note that, conceptually speaking, the SoftAssign (or Graduated Assignment Algorithm) for graphs can be seen as a SoftLA where the features <span class="math notranslate nohighlight">\(\mathbf{X}_{ai}\)</span> correspond to <span class="math notranslate nohighlight">\(\mathbf{Q}_{ai}\)</span>, the number of rectangles we can close with the neighbors of <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(i\)</span> if the matching <span class="math notranslate nohighlight">\(\mathbf{M}_{ai}\)</span> is activated. This is encoded by <span class="math notranslate nohighlight">\(\mathbf{C}_{aibj}\)</span>.</p>
<p>This rationale is illustrated in <a class="reference internal" href="#id1"><span class="std std-numref">Fig. 2.20</span></a>.</p>
<figure class="align-center" id="id1">
<a class="reference internal image-reference" href="_images/Overview-nobag.png"><img alt="_images/Overview-nobag.png" src="_images/Overview-nobag.png" style="width: 800px; height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.20 </span><span class="caption-text">Overview of the SoftAssign algorithm as a SoftLA.</span><a class="headerlink" href="#id1" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="including-attributes">
<h4><span class="section-number">2.4.2.4. </span>Including attributes<a class="headerlink" href="#including-attributes" title="Permalink to this heading">#</a></h4>
<p>A feasible way of including attributes, for instance in nodes, is to define a node-2-node compabilility (binary) matrix <span class="math notranslate nohighlight">\(C_{ai}\)</span> of size <span class="math notranslate nohighlight">\(m\times n\)</span>, so that <span class="math notranslate nohighlight">\(C_{ai}=1\)</span> means that node <span class="math notranslate nohighlight">\(a\)</span> in <span class="math notranslate nohighlight">\(X\)</span> is <strong>compatible</strong> with node <span class="math notranslate nohighlight">\(i\)</span> in <span class="math notranslate nohighlight">\(Y\)</span>, and <span class="math notranslate nohighlight">\(C_{ai}=0\)</span> otherwise.</p>
<p>For instance, in <a class="reference internal" href="#alternative"><span class="std std-numref">Fig. 2.21</span></a>, a way of forcing an alternative matching to those of the notable vertices is to impose that <span class="math notranslate nohighlight">\(a\)</span> can be matching with anyother, but <span class="math notranslate nohighlight">\(b\)</span> can be only matched with <span class="math notranslate nohighlight">\(4\)</span> and <span class="math notranslate nohighlight">\(c\)</span> with <span class="math notranslate nohighlight">\(1\)</span>.</p>
<figure class="align-center" id="alternative">
<a class="reference internal image-reference" href="_images/Alternative-nbg.png"><img alt="_images/Alternative-nbg.png" src="_images/Alternative-nbg.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.21 </span><span class="caption-text">Proposing alterative matching based on node compatibility constraints.</span><a class="headerlink" href="#alternative" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>In terms of the cost function, we have that</p>
<div class="math notranslate nohighlight">
\[
\mathbf{Q}=\mathbf{X}^T(\mathbf{C}\odot\mathbf{M}[:m,:n])\mathbf{Y}\;.
\]</div>
</section>
<section id="cleanup">
<h4><span class="section-number">2.4.2.5. </span>Cleanup<a class="headerlink" href="#cleanup" title="Permalink to this heading">#</a></h4>
<p>Remember that continuation methods are <strong>solved in the continuum</strong> but our <strong>original
is discrete</strong>. Given the <span class="math notranslate nohighlight">\(\text{SoftAssign}\)</span> solution <span class="math notranslate nohighlight">\(\hat{\mathbf{M}}^{\ast}\)</span>, which can
be very entropic, we must recover the closest discrete matrix (which is not unique, in general).
This task is performed by a <span style="color:#f88146"><strong>cleanup heuristic</strong> or algorithm</span> like the one detailed
below:</p>
<div class="proof algorithm admonition" id="Cleanup-alg">
<p class="admonition-title"><span class="caption-number">Algorithm 2.6 </span> (Cleanup)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inputs</strong> <span class="math notranslate nohighlight">\(\hat{\mathbf{M}}\in[0,1]^{(m+1)\times (n+1)}\)</span> optimal doubly-stochastic matrix<br />
<strong>Outputs</strong> Closest discrete matrix <span class="math notranslate nohighlight">\(\mathbf{M}\in\{0,1\}^{(m+1)\times (n+1)}\)</span></p>
<ol class="arabic">
<li><p>yet_asigned <span class="math notranslate nohighlight">\(\leftarrow 0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}[a,i]\leftarrow 0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\epsilon \leftarrow 10^{-6}\)</span></p></li>
<li><p><strong>while</strong> yet_asigned<span class="math notranslate nohighlight">\(&lt; m\)</span>:</p>
<ol class="arabic">
<li><p>changes_done<span class="math notranslate nohighlight">\(\leftarrow\)</span> False</p></li>
<li><p><strong>for</strong> <span class="math notranslate nohighlight">\(a\in\{1,2,\ldots,m+1\}\)</span>:</p>
<ol class="arabic">
<li><p>candidates <span class="math notranslate nohighlight">\(\leftarrow \emptyset\)</span></p></li>
<li><p>max_row <span class="math notranslate nohighlight">\(\leftarrow \max\:\hat{\mathbf{M}}[a,:]\)</span></p></li>
<li><p>row_capacity <span class="math notranslate nohighlight">\(\leftarrow\)</span> max_row <span class="math notranslate nohighlight">\(- \epsilon\)</span></p></li>
<li><p><strong>for</strong> <span class="math notranslate nohighlight">\(i\in\{1,2,\ldots,n+1\}\)</span>:</p>
<ol class="arabic">
<li><p>max_col <span class="math notranslate nohighlight">\(\leftarrow \max\;\hat{\mathbf{M}}[i,:]\)</span></p></li>
<li><p>col_capacity <span class="math notranslate nohighlight">\(\leftarrow\)</span> max_col <span class="math notranslate nohighlight">\(- \epsilon\)</span></p></li>
<li><p><strong>if</strong> <span class="math notranslate nohighlight">\((\mathbf{M}[a,i]&gt;\)</span>row_capacity<span class="math notranslate nohighlight">\()\)</span> <strong>and</strong> <span class="math notranslate nohighlight">\((\mathbf{M}[a,i]&gt;\)</span>col_capacity<span class="math notranslate nohighlight">\()\)</span>:</p>
<p>candidates <span class="math notranslate nohighlight">\(\leftarrow\)</span> candidates <span class="math notranslate nohighlight">\(\cup \{i\}\)</span></p>
</li>
</ol>
</li>
<li><p><strong>if</strong> <span class="math notranslate nohighlight">\(|\)</span>candidates<span class="math notranslate nohighlight">\(|\)</span>&gt;0:</p>
<ol class="arabic simple">
<li><p>max_val <span class="math notranslate nohighlight">\(\leftarrow\)</span> <span class="math notranslate nohighlight">\(\max \mathbf{M}[a,\)</span>candidates<span class="math notranslate nohighlight">\(]\)</span></p></li>
<li><p>selection <span class="math notranslate nohighlight">\(\leftarrow\)</span> <span class="math notranslate nohighlight">\(\arg\max\)</span> <span class="math notranslate nohighlight">\(\mathbf{M}[a,\)</span>candidates<span class="math notranslate nohighlight">\(]\)</span></p></li>
<li><p>col <span class="math notranslate nohighlight">\(\leftarrow\)</span> candidates[selection]</p></li>
<li><p>yet_assigned <span class="math notranslate nohighlight">\(\leftarrow\)</span> yet_assigned + 1</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}[a,\)</span>col<span class="math notranslate nohighlight">\(]\leftarrow\)</span> 1</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}[a,:]\leftarrow-\infty\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}[:,col]\leftarrow-\infty\)</span></p></li>
<li><p>changes_done <span class="math notranslate nohighlight">\(\leftarrow\)</span> True</p></li>
</ol>
</li>
</ol>
</li>
<li><p><strong>if</strong> <span class="math notranslate nohighlight">\(\neg\)</span> changes_done:</p>
<p><strong>break</strong></p>
</li>
</ol>
</li>
<li><p><strong>return</strong> <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> binary matrix.</p></li>
</ol>
</section>
</div><p>The algorithm, basically a <span style="color:#f88146"><strong>greedy</strong> version of the Hungarian algorithm</span>, proceeds as follows:</p>
<ol class="arabic simple">
<li><p><ins>Steps 2.1-2.4</ins>. For every row <span class="math notranslate nohighlight">\(a\)</span>, we build a list of <em>candidates</em> keeping track of both the row and col
capacities.</p></li>
<li><p><ins>Step 2.5</ins>. If the list of candidates is not empty, we proceed to get the best of them (step 5.5) and then we proceed
to exclude the corresponding row and column (steps 5.6 and 5.7).</p></li>
</ol>
<p>This takes <span class="math notranslate nohighlight">\(O(n^2)\)</span> and could be replaced by a run of <span class="math notranslate nohighlight">\(\text{SoftLA}\)</span>. Remember that if the algorithm
finds any match to a slack vertex these machings should be cleared.</p>
<p><strong>Results</strong>. Coming back to the Aspirin Isomorphism, we use the setting recommended
in Gold and Rangarajan’s paper: <span class="math notranslate nohighlight">\(\epsilon = 0.1\)</span>, <span class="math notranslate nohighlight">\(\epsilon'=0.5\)</span>, <span class="math notranslate nohighlight">\(\beta_0=0.5\)</span>,
<span class="math notranslate nohighlight">\(\beta_f=10.0\)</span>, <span class="math notranslate nohighlight">\(\beta_r=1.075\)</span> and <span class="math notranslate nohighlight">\(I_0=4\)</span>, <span class="math notranslate nohighlight">\(I_1=30\)</span>, where the last two numbers
are the maximal iterations of the internal <strong>while</strong> loop and <span class="math notranslate nohighlight">\(\text{Sinkhorn}\)</span>,
respectively.</p>
<p>The result in <a class="reference internal" href="#da-aspirin"><span class="std std-numref">Fig. 2.22</span></a> is nearly perfect and we can claim that Aspirin
is isomorphic wrt to a permutation of itself!</p>
<figure class="align-center" id="da-aspirin">
<a class="reference internal image-reference" href="_images/DA-Aspirnin-removebg-preview.png"><img alt="_images/DA-Aspirnin-removebg-preview.png" src="_images/DA-Aspirnin-removebg-preview.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.22 </span><span class="caption-text">Detecting the Aspirin’s Isomorphism with DA.</span><a class="headerlink" href="#da-aspirin" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>We leave to the practice lessons the extension of the algorithm for incorporating
both <span style="color:#f88146">node and edge <strong>attributtes</strong></span>.</p>
</section>
</section>
</section>
<section id="appendix">
<h2><span class="section-number">2.5. </span>Appendix<a class="headerlink" href="#appendix" title="Permalink to this heading">#</a></h2>
<section id="independence">
<h3><span class="section-number">2.5.1. </span>Independence<a class="headerlink" href="#independence" title="Permalink to this heading">#</a></h3>
<p><strong>Statistical independence</strong>. It is well known that two random variables <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are <strong>independent</strong> iff:</p>
<div class="math notranslate nohighlight">
\[
p(A,B) = p(A)\cdot p(B)\;.
\]</div>
<p>Or, in other words, applying the Bayes theorem we have that <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are independent iff</p>
<div class="math notranslate nohighlight">
\[
p(A,B) = p(B|A)p(A) = p(A|B)p(B)\Rightarrow p(B|A)=p(B)\;\text{and}\;p(A|B)=p(A)\;.
\]</div>
<p>In other words:</p>
<ul class="simple">
<li><p>Independence implies factorizing the joint distribution <span class="math notranslate nohighlight">\(p(A,B)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are indendent if the knowledge of one of them does not influence the probability of the other, i.e. <span class="math notranslate nohighlight">\(p(A|B)=p(A)\)</span> and <span class="math notranslate nohighlight">\(p(B|A)=p(B)\)</span>.</p></li>
</ul>
<p><strong>Marginalization</strong>. Alternatively, we may define statistical independence by checking the marginal probabilities. Let <span class="math notranslate nohighlight">\(a_1,a_2,\ldots,a_m\)</span> the discrete values of <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(b_1,b_2,\ldots,b_n\)</span> similarly for <span class="math notranslate nohighlight">\(B\)</span>. Then:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
&amp;&amp;\sum_{a_i}\sum_{b_j}p(A=a_i,B=b_j)=1\;\text{total probability}\\
&amp;&amp; p(A=a_i)=\sum_{b_j}p(A=a_i,B=b_j)\;\text{marginal wrt}\; A\\
&amp;&amp; p(B=b_i)=\sum_{a_i}p(A=a_i,B=b_j)\;\text{marginal wrt}\; B\\
\end{align}
\end{split}\]</div>
<p>Then, <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are independent if we can write a joint distribution as the product of two marginal distributions:</p>
<div class="math notranslate nohighlight">
\[
p(A=a_i,B=b_j) = p(A=a_i)\cdot p(B=b_j)\;\forall a_i,b_j\;.
\]</div>
<p>Let us practice a bit this concept in the following exercise.</p>
<p><br></br>
<span style="color:#d94f0b">
<strong>Exercise</strong>. Given the above table representing the joint distribution of two discrete random variables <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>, determine where they are indepedent or not. <strong>a)</strong> Usign the marginals. <strong>b)</strong> Using the conditional probabities.
</span>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|ccc}
         &amp; B=b_1 &amp; B=b_2 &amp; B=b_3 \\
  \hline
  A=a_1  &amp; 0.1   &amp; 0.2   &amp; 0.3\\
  A=a_2  &amp; 0.1   &amp; 0.2   &amp; 0.1\\  
  \hline
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<strong>a)</strong> First all, note that <span class="math notranslate nohighlight">\(\sum_{a_i,b_j}p(A=a_i,B=b_j)=1\)</span>. Now, let us compute the marginals summing the rows for <span class="math notranslate nohighlight">\(A\)</span> and the columns for <span class="math notranslate nohighlight">\(B\)</span>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
p(A=a_1) &amp;= \sum_{b_j}p(A=a_1,B=b_j)=0.1 + 0.2 + 0.3 = \mathbf{0.6}\\
p(A=a_2) &amp;= \sum_{b_j}p(A=a_2,B=b_j)=0.1 + 0.2 + 0.1 = \mathbf{0.4}\\
p(B=b_1) &amp;= \sum_{a_i}p(A=a_i,B=b_1)=0.1 + 0.1 = \mathbf{0.2}\\
p(B=b_2) &amp;= \sum_{a_i}p(A=a_i,B=b_2)=0.2 + 0.2 = \mathbf{0.4}\\
p(B=b_3) &amp;= \sum_{a_i}p(A=a_i,B=b_3)=0.3 + 0.1 = \mathbf{0.4}\\
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Now we check independence:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
p(A=a_1,B=b_1) &amp;=0.1\neq p(A=a_1)p(B=b_1) = \mathbf{0.6}\times\mathbf{0.2}=0.12\\
p(A=a_1,B=b_2) &amp;=0.2\neq p(A=a_1)p(B=b_2) = \mathbf{0.6}\times\mathbf{0.4}=0.24\\
p(A=a_1,B=b_3) &amp;=0.3\neq p(A=a_1)p(B=b_3) = \mathbf{0.6}\times\mathbf{0.4}=0.24\\
p(A=a_2,B=b_1) &amp;=0.1\neq p(A=a_2)p(B=b_1) = \mathbf{0.4}\times\mathbf{0.2}=0.08\\
p(A=a_2,B=b_2) &amp;=0.2\neq p(A=a_2)p(B=b_2) = \mathbf{0.4}\times\mathbf{0.4}=0.16\\
p(A=a_2,B=b_3) &amp;=0.1\neq p(A=a_2)p(B=b_3) = \mathbf{0.4}\times\mathbf{0.4}=0.16\\
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
However, note that in all cases <span class="math notranslate nohighlight">\(p(A=a_i,B=b_j)\approx p(A=a_i)p(B=b_j)\)</span>.
</span>
<br></br>
<span style="color:#d94f0b">
<strong>b)</strong> Now, we can compute the conditional probabilities using the Bayes theorem: <span class="math notranslate nohighlight">\(p(A=a_i|B=b_j)=p(A=a_i,B=b_j)/p(B=b_j)\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|ccc}
                  &amp; B=b_1 &amp; B=b_2 &amp; B=b_3 \\
  \hline
  p(A=a_1|B=b_j)  &amp; \frac{0.1}{0.2}=0.5   &amp; \frac{0.2}{0.4}=0.5  &amp; \frac{0.3}{0.4}=0.75\\
  p(A=a_2|B=b_j)  &amp; \frac{0.1}{0.2}=0.5   &amp; \frac{0.2}{0.4}=0.5   &amp; \frac{0.1}{0.4}=0.25\\  
  \hline
                &amp; \sum = 1 &amp; \sum = 1 &amp; \sum=1\\
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
and <span class="math notranslate nohighlight">\(p(B=b_j|A=a_i)=p(A=a_i,B=b_j)/p(A=a_i)\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|ccc|c}
                  &amp; p(B=b_1|A=a_i) &amp; p(B=b_2|A=a_i) &amp; p(B=b_3|A=a_i) \\
  \hline
  A=a_1  &amp; \frac{0.1}{0.6}=0.17   &amp; \frac{0.2}{0.6}=0.33  &amp; \frac{0.3}{0.6}=0.5 &amp; \sum = 1\\
  A=a_2  &amp; \frac{0.1}{0.4}=0.25   &amp; \frac{0.2}{0.4}=0.5   &amp; \frac{0.1}{0.4}=0.25 &amp; \sum = 1\\  
  \hline
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Note that the conditional probabilities adds <span class="math notranslate nohighlight">\(1\)</span> wrt the “influenced” variable, i.e.
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\forall a_i: \sum_{b_j} p(A=a_i|B=b_j)= 1\;\text{and}\; 
\forall b_j: \sum_{a_i} p(B=b_j|A=a_i)= 1
\)</span>
</span>
<br></br></p>
</section>
<section id="entropy">
<h3><span class="section-number">2.5.2. </span>Entropy<a class="headerlink" href="#entropy" title="Permalink to this heading">#</a></h3>
<p>This is the <strong>first point</strong> in the subject where we talk about <span style="color:#f88146"><strong>Information Theory</strong></span>, the main auxiliary maths behind this course. In this regard, we refer you to the <a class="reference external" href="https://link.springer.com/book/10.1007/978-1-84882-297-9">author’s book on the subject</a>.</p>
<section id="definition-and-properties">
<h4><span class="section-number">2.5.2.1. </span>Definition and properties<a class="headerlink" href="#definition-and-properties" title="Permalink to this heading">#</a></h4>
<p>The above exercise reveals one esential property of DA: <span style="color:#f88146">we cannot converge without keeping the <strong>maximizing the entropy</strong></span>. But, what is entropy?</p>
<p><strong>Entropy</strong> is the ultimate measure of uncertainty defined by <a class="reference external" href="https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf">Shannon</a> as follows:</p>
<p>Given a discrete random variable <span class="math notranslate nohighlight">\(X\)</span>, with possible values <span class="math notranslate nohighlight">\(\{x_1,\ldots,x_n\}\)</span>, its <strong>entropy</strong> is given by:</p>
<div class="math notranslate nohighlight">
\[
H(X) = -\sum_{i=1}^n p(X=x_i)\log p(X=x_i)\;.
\]</div>
<p>Similarly, we can express entropy in terms of the probabilities of the <strong>discrete events</strong> <span class="math notranslate nohighlight">\(p_i=p(X=x_i)\)</span>, i.e.</p>
<div class="math notranslate nohighlight">
\[
H(p_1,p_2,\ldots,p_n)=-\sum_{i=1}^n p_i\log p_i\;.
\]</div>
<p>Then, we have the following <strong>properties</strong>:</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(H\)</span> is continuous, concave and non-negative in <span class="math notranslate nohighlight">\(p_i\)</span>.</p></li>
<li><p>If all the <span class="math notranslate nohighlight">\(p_i\)</span> are equally likely, i.e. <span class="math notranslate nohighlight">\(p_i=1/n\)</span>, then entropy is <strong>maximal</strong> for this <span class="math notranslate nohighlight">\(n\)</span> and equal to <span class="math notranslate nohighlight">\(\log n\)</span>. The larger <span class="math notranslate nohighlight">\(n\)</span> the larger the <strong>uncertainty</strong> of the equally likely events.</p></li>
<li><p>If we have <span class="math notranslate nohighlight">\(\log_2\)</span> entropy is measured in <strong>bits</strong>, whereas if it is <span class="math notranslate nohighlight">\(\ln\)</span> it is measured in  <strong>nats</strong>.</p></li>
<li><p>Since <span class="math notranslate nohighlight">\(E(f(x))=\sum_x x\cdot f(x)\)</span> is the <strong>expectation</strong> of <span class="math notranslate nohighlight">\(f(x)\)</span>, then entropy is the expectation of the logarithm.</p></li>
</ol>
<p><strong>Entropy of Bernouilli</strong>. An interesting example is the measure of the entropy of <span class="math notranslate nohighlight">\(X\sim \text{Bernouilli}(p)\)</span>.</p>
<p><span class="math notranslate nohighlight">\(X\)</span> has value <span class="math notranslate nohighlight">\(x=1\)</span> with probability <span class="math notranslate nohighlight">\(p(X=1)=p\)</span> and <span class="math notranslate nohighlight">\(x=0\)</span> with probability <span class="math notranslate nohighlight">\(p(X=0)=q=1-p\)</span>.
Then:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
H(X) &amp;= -\sum_{x}p(X=x)\log p(X=x)\\
     &amp;= -p(X=0)\log p(X=0) - p(X=1)\log p(X=1)\\
     &amp;= -p\log p - q\log q\\
     &amp;= -p\log p - (1-p)\log (1-p)\;.
\end{align}
\end{split}\]</div>
<p>Therefore, the maximal entropy (uncertainty) of a Bernouilli variable is when <span class="math notranslate nohighlight">\(p=q=1/2\)</span> (for instance the probability of a fair coin):</p>
<div class="math notranslate nohighlight">
\[
H(X) = -p\log p -p\log p = -2p\log p = -\log\frac{1}{2} = -(\log 1 - \log 2) = \log 2\;.
\]</div>
<p>which is <span class="math notranslate nohighlight">\(\log_2 2=1\)</span> bits as we can see in <a class="reference internal" href="#km-entropy-bern"><span class="std std-numref">Fig. 2.23</span></a>. Note that the function is concave wrt <span class="math notranslate nohighlight">\(p\)</span>. Minimal entropy is achieved at the two extreme points: <span class="math notranslate nohighlight">\(p=0\)</span> and <span class="math notranslate nohighlight">\(p=1\)</span>, where the <strong>uncertainty is minimal</strong> (completely biased coin).</p>
<figure class="align-center" id="km-entropy-bern">
<a class="reference internal image-reference" href="_images/KM-entropy-Bern-removebg-preview.png"><img alt="_images/KM-entropy-Bern-removebg-preview.png" src="_images/KM-entropy-Bern-removebg-preview.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.23 </span><span class="caption-text">Entropy of Bernouilli wrt <span class="math notranslate nohighlight">\(p\)</span>.</span><a class="headerlink" href="#km-entropy-bern" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="entropy-and-coding">
<h4><span class="section-number">2.5.2.2. </span>Entropy and Coding<a class="headerlink" href="#entropy-and-coding" title="Permalink to this heading">#</a></h4>
<p>The relationship between entropy and codelength is key to understand why <span style="color:#f88146">entropy measures information content</span>.</p>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Morse_code">Morse code</a> follows the principle of <em>assigning less number of bits to more frequent letters than to less frequent ones</em>. Herein, the bits are clear: <span class="math notranslate nohighlight">\(0\)</span> for the dits “.” and <span class="math notranslate nohighlight">\(1\)</span> for the
dash “.”. For instance, following the frequencies of letters in English, the shorter “codewords” are those for <span class="math notranslate nohighlight">\(E=.\)</span> and <span class="math notranslate nohighlight">\(T=-\)</span>. The longer ones are those for the digits <span class="math notranslate nohighlight">\(0-9\)</span> (five bits all of them). The table below shows those lengths and probabilities.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp;\begin{array}{|c|c|c|c|}
\hline
\text{Letter} &amp; \text{Morse code} &amp; \text{codelength} &amp; \text{Probability} \\
\hline
A &amp; .- &amp; 2 &amp; 0.06381 \\
B &amp; -... &amp; 4 &amp; 0.01166 \\
C &amp; -.-. &amp; 4 &amp; 0.02173 \\
D &amp; -.. &amp; 3 &amp; 0.03323 \\
E &amp; . &amp; 1 &amp; 0.09924 \\
F &amp; ..-. &amp; 4 &amp; 0.01741 \\
G &amp; --. &amp; 3 &amp; 0.01574 \\
H &amp; .... &amp; 4 &amp; 0.04761 \\
I &amp; .. &amp; 2 &amp; 0.05442 \\
J &amp; .--- &amp; 4 &amp; 0.00120 \\
K &amp; -.- &amp; 3 &amp; 0.00603 \\
L &amp; .-.. &amp; 4 &amp; 0.03145 \\
M &amp; -- &amp; 2 &amp; 0.01880 \\
N &amp; -. &amp; 2 &amp; 0.05273 \\
O &amp; --- &amp; 3 &amp; 0.05865 \\
P &amp; .--. &amp; 4 &amp; 0.01507 \\
Q &amp; --.- &amp; 4 &amp; 0.00074 \\
R &amp; .-. &amp; 3 &amp; 0.04677 \\
S &amp; ... &amp; 3 &amp; 0.04943 \\
T &amp; - &amp; 1 &amp; 0.07075 \\
U &amp; ..- &amp; 3 &amp; 0.02155 \\
V &amp; ...- &amp; 4 &amp; 0.00764 \\
W &amp; .-- &amp; 3 &amp; 0.01844 \\
X &amp; -..- &amp; 4 &amp; 0.00117 \\
Y &amp; -.-- &amp; 4 &amp; 0.01542 \\
Z &amp; --.. &amp; 4 &amp; 0.00058 \\
0 &amp; ----- &amp; 5 &amp; 0.01563 \\
1 &amp; .---- &amp; 5 &amp; 0.05469 \\
2 &amp; ..--- &amp; 5 &amp; 0.02344 \\
3 &amp; ...-- &amp; 5 &amp; 0.02344 \\
4 &amp; ....- &amp; 5 &amp; 0.02344 \\
5 &amp; ..... &amp; 5 &amp; 0.01563 \\
6 &amp; -.... &amp; 5 &amp; 0.01563 \\
7 &amp; --... &amp; 5 &amp; 0.01563 \\
8 &amp; ---.. &amp; 5 &amp; 0.01563 \\
9 &amp; ----. &amp; 5 &amp; 0.01563 \\
\hline
\end{array}
\end{aligned}
\end{split}\]</div>
<p>Note that, due to traditional reasons it is not always happening that shorter codes correspond to highest frequencies (probabilities) but this is the global trend.</p>
<p>Of course, each message should have a space ‘ ‘ between letters in order to be decoded properly. For instance: “……-.. .-.. —   .– — .-. .-.. -..” means H E L L O W O R L D in Morse.</p>
<p><strong>Codes and Trees</strong>. One interesting way of characterizing codes (binary codes in particular) is to try to put the symbols to code in a tree. See for instance <a class="reference internal" href="#morse-tree"><span class="std std-numref">Fig. 2.24</span></a>, where the root is marked as “#’. We point out the following:</p>
<ul class="simple">
<li><p><span style="color:#f88146"><strong>Decoding means</strong></span> navigating through the tree top-to-bottom, making decisions (dit or slash for binary codes), i.e. building a “path”, until the desired symbol is reached. Such a path is the “codeword”.</p></li>
<li><p><span style="color:#f88146"><strong>The codeword length</strong></span> <span class="math notranslate nohighlight">\(l_i\)</span> is the number of decision taken to decode it, i.e. the depth of the symbol in the tree.</p></li>
<li><p><span style="color:#f88146"><strong>A code is comma-like</strong></span> if all the symbols are placed at the leaves of the tree. This is clearly not the case of Morse.</p></li>
<li><p><span style="color:#f88146"><strong>A code is prefix-like</strong></span> if any symbol is preceeded by a unique sequence of other codes (the prefix). For instace, to decode “O” in Morse, we should decode “T” and “M”. Thus, the prefix of “O” is “TM”.</p></li>
</ul>
<p>In the Morse code few letters are placed at the leaves of tree. Notably, they are the ones with the largest codeword lengths. Herein, we follow the recipe that assigning less frequent letters to deeper levels of the tree. The purpose of such strategy is twofold: (a) saving storage space, and (b) fast decoding.</p>
<p><strong>Expected codelength</strong>. Suppose that we have <span class="math notranslate nohighlight">\(n\)</span> letters, each one with frequency <span class="math notranslate nohighlight">\(p_i\)</span> and codelenth <span class="math notranslate nohighlight">\(l_i\)</span>, <span class="math notranslate nohighlight">\(i=1,\ldots,n\)</span>. Then, the expected codelength is</p>
<div class="math notranslate nohighlight">
\[
E(l) = \sum_{i}l_i p_i = l_1p_1 + l_2p_2 + \ldots + l_np_n\;.
\]</div>
<p>For the Morse code, <span class="math notranslate nohighlight">\(E_{Morse}(l)=3.0794539323542267\)</span>. Now, the tree in <a class="reference internal" href="#morse-tree"><span class="std std-numref">Fig. 2.24</span></a> is built under the constraint of placing more probable letters in the top of the (binary) tree. In other words, we may assume that</p>
<div class="math notranslate nohighlight">
\[
p_i \approx \frac{1}{2^{l_i}}\;. 
\]</div>
<p>If so, <span class="math notranslate nohighlight">\(E(l)\approx H(p_1,p_2,\ldots,p_n)\)</span> since</p>
<div class="math notranslate nohighlight">
\[
\log_2 p_i \approx \log_2 \frac{1}{2^{l_i}} = \log_2 1 - \log_2 2^{l_i} = - \log_2 2^{l_i} = - l_i\;.
\]</div>
<p>Then</p>
<div class="math notranslate nohighlight">
\[
-p_i\log_2 p_i \approx \frac{1}{2^{l_i}}l_i = \frac{l_i}{2^{l_i}}\;.
\]</div>
<p>Roughly speaking, <span style="color:#f88146"><strong>the expected codelegth matches entropy</strong></span>!</p>
<p>More precisely, for comma-like codes we have <span class="math notranslate nohighlight">\(E(l)\le H(p_1,p_2,\ldots,p_n)\)</span>. Although Morse is not comma-like it satisfies this bound since <span class="math notranslate nohighlight">\(E_{Morse}(l) = 3.0794539323542267\le H_{Morse} = 4.713102340698242\)</span>.</p>
<figure class="align-center" id="morse-tree">
<a class="reference internal image-reference" href="_images/Morse-Photoroom.png"><img alt="_images/Morse-Photoroom.png" src="_images/Morse-Photoroom.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.24 </span><span class="caption-text">Decoding tree for the Morse code.</span><a class="headerlink" href="#morse-tree" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><strong>Huffman Codes</strong>. As an alternative code, herein we highlight a <span style="color:#f88146"><strong>prefix code</strong></span> (no code is the prefix of another). Prefix codes are easily decodable and, in addition, they allow us (by definition) to suppress the space ” ” between words (see the Table below).</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\begin{array}{|c|c|c|c|}
\hline
\text{Letter} &amp; \text{Huffman Code} &amp; \text{Length} &amp; \text{Probability} \\
\hline
A &amp; 1010 &amp; 4 &amp; 0.06381 \\
B &amp; 001110 &amp; 6 &amp; 0.01166 \\
C &amp; 111001 &amp; 6 &amp; 0.02173 \\
D &amp; 10111 &amp; 5 &amp; 0.03323 \\
E &amp; 000 &amp; 3 &amp; 0.09924 \\
F &amp; 110101 &amp; 6 &amp; 0.01741 \\
G &amp; 100111 &amp; 6 &amp; 0.01574 \\
H &amp; 11111 &amp; 5 &amp; 0.04761 \\
I &amp; 0101 &amp; 4 &amp; 0.05442 \\
J &amp; 1101001011 &amp; 10 &amp; 0.00120 \\
K &amp; 11010011 &amp; 8 &amp; 0.00603 \\
L &amp; 10110 &amp; 5 &amp; 0.03145 \\
M &amp; 110111 &amp; 6 &amp; 0.01880 \\
N &amp; 0100 &amp; 4 &amp; 0.05273 \\
O &amp; 0111 &amp; 4 &amp; 0.05865 \\
P &amp; 001111 &amp; 6 &amp; 0.01507 \\
Q &amp; 1101001001 &amp; 10 &amp; 0.00074 \\
R &amp; 11101 &amp; 5 &amp; 0.04677 \\
S &amp; 0010 &amp; 4 &amp; 0.04943 \\
T &amp; 1100 &amp; 4 &amp; 0.07075 \\
U &amp; 111000 &amp; 6 &amp; 0.02155 \\
V &amp; 1101000 &amp; 7 &amp; 0.00764 \\
W &amp; 110110 &amp; 6 &amp; 0.01844 \\
X &amp; 1101001010 &amp; 10 &amp; 0.00117 \\
Y &amp; 100000 &amp; 6 &amp; 0.01542 \\
Z &amp; 1101001000 &amp; 10 &amp; 0.00058 \\
0 &amp; 100001 &amp; 6 &amp; 0.01563 \\
1 &amp; 0110 &amp; 4 &amp; 0.05469 \\
2 &amp; 111100 &amp; 6 &amp; 0.02344 \\
3 &amp; 111101 &amp; 6 &amp; 0.02344 \\
4 &amp; 00110 &amp; 5 &amp; 0.02344 \\
5 &amp; 100011 &amp; 6 &amp; 0.01563 \\
6 &amp; 100010 &amp; 6 &amp; 0.01563 \\
7 &amp; 100110 &amp; 6 &amp; 0.01563 \\
8 &amp; 100100 &amp; 6 &amp; 0.01563 \\
9 &amp; 100101 &amp; 6 &amp; 0.01563 \\
\hline
\end{array}
\end{aligned}
\end{split}\]</div>
<p>For instance, the Huffman code for HELLOW WORLD is</p>
<div class="math notranslate nohighlight">
\[
1111100010110101100111\;1101100111111011011010111
\]</div>
<p>Concerning <span class="math notranslate nohighlight">\(E_{Huffman}(l)\)</span> and <span class="math notranslate nohighlight">\(H_{Huffman}=\)</span>, they are identical: <span class="math notranslate nohighlight">\(4.7\)</span>. See the encoding tree in <a class="reference internal" href="#huffman-tree"><span class="std std-numref">Fig. 2.25</span></a></p>
<figure class="align-center" id="huffman-tree">
<a class="reference internal image-reference" href="_images/Huffman-Photoroom.png"><img alt="_images/Huffman-Photoroom.png" src="_images/Huffman-Photoroom.png" style="width: 800px; height: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2.25 </span><span class="caption-text">Decoding tree for the Huffman code of the Morse frequencies.</span><a class="headerlink" href="#huffman-tree" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Finally, this code is not only useful for English but for any laguage such as Chinese.</p>
</section>
<section id="joint-vs-conditional-entropy">
<h4><span class="section-number">2.5.2.3. </span>Joint vs Conditional entropy<a class="headerlink" href="#joint-vs-conditional-entropy" title="Permalink to this heading">#</a></h4>
<p>Entropy is defined for any (discrete) probability function, and in particular for the <strong>joint probability</strong>. Thus, if <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are two discrete variables with respective values <span class="math notranslate nohighlight">\(a_1,\ldots, a_m\)</span> and <span class="math notranslate nohighlight">\(b_1,\ldots,b_n\)</span> and does exists the probability <span class="math notranslate nohighlight">\(p(A,B)\)</span>, the <span style="color:#f88146"><strong>joint entropy</strong></span> <span class="math notranslate nohighlight">\(H(A,B)\)</span> is defined as follows:</p>
<div class="math notranslate nohighlight">
\[
H(A,B) = -\sum_{a_i}\sum_{b_j}p(A=a_i,B=b_j)\log p(A=a_i,B=b_j)\;.
\]</div>
<p>Remember that the Bayes theorem leads to <span class="math notranslate nohighlight">\(p(A,B)=p(A|B)p(B)=p(B|A)p(A)\)</span>.
As a result, we may define entropies for <span class="math notranslate nohighlight">\(p(A|B)\)</span> and <span class="math notranslate nohighlight">\(p(B|A)\)</span>, i.e. <span style="color:#f88146"><strong>conditional entropies</strong></span>.</p>
<p>Remember that <em>entropy is an expectation</em>, then</p>
<div class="math notranslate nohighlight">
\[
H(A|B=b_j) = -\sum_{a_i}p(A=a_i|B=b_j)\log p(A=a_i|B=b_j)\;,
\]</div>
<p>is the <span style="color:#f88146"><strong>entropy of the conditional expectation</strong> of <span class="math notranslate nohighlight">\(A\)</span> wrt <span class="math notranslate nohighlight">\(B=b_j\)</span></span>. Now, if we average this quantity wrt all values  <span class="math notranslate nohighlight">\(b_j\)</span>, we have that the <em>conditional entropy</em> is given by following weigthed sum:</p>
<div class="math notranslate nohighlight">
\[
H(A|B) = \sum_{b_j}p(B=b_j)\cdot H(A|B=b_j)\;,
\]</div>
<p>and similarly for <span class="math notranslate nohighlight">\(H(B|A)\)</span>. Actually we have several <strong>properties</strong> linking conditional entropies and joint entropies:</p>
<ol class="arabic simple">
<li><p><strong>Zero-value</strong>: <span class="math notranslate nohighlight">\(H(A|B)=0\)</span> if the value of <span class="math notranslate nohighlight">\(A\)</span> is <em>completely determined</em> by <span class="math notranslate nohighlight">\(B\)</span>. In other words, <span class="math notranslate nohighlight">\(H(A|B)\)</span> measures how much uncertainty adds <span class="math notranslate nohighlight">\(B\)</span> to <span class="math notranslate nohighlight">\(A\)</span>. Then, if <span class="math notranslate nohighlight">\(p(A|B)=1\)</span> it is expected that knowing <span class="math notranslate nohighlight">\(B\)</span> is the same as knowing <span class="math notranslate nohighlight">\(A\)</span> itself.</p></li>
<li><p><strong>Independence</strong>: <span class="math notranslate nohighlight">\(H(A|B)=H(A)\)</span> and <span class="math notranslate nohighlight">\(H(B|A)=H(B)\)</span> iff <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are <em>independent</em>, as it happens with <span class="math notranslate nohighlight">\(p(A|B)=p(A)\)</span> and <span class="math notranslate nohighlight">\(p(B|A)=p(A)\)</span>.</p></li>
<li><p><strong>Chain rule</strong>: the conditional entropies can be derived from the joint entropy <span class="math notranslate nohighlight">\(H(A,B)\)</span> by subtracting the entropy of the conditioning variable:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
H(A|B) = H(A,B)-H(B)\;\;\text{and}\;\; H(B|A) = H(A,B)-H(A)\;.
\]</div>
<p><br></br>
<span style="color:#d94f0b">
<strong>Exercise</strong>. Given the discrete random variales <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>, in the previous exercise: <strong>a)</strong> determine the joint entropy and <strong>b)</strong> the conditional entropies. <strong>c)</strong> Interpret what is the uncertainty added or removed by each variable wrt to the other and the uncertainty removed from the joint entropy. <strong>d)</strong> Are <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> independent attending to their entropies?
</span>
<br></br>
<span style="color:#d94f0b">
<strong>a)</strong> First all, for the joint entropy we need the joint distribution:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|ccc}
         &amp; B=b_1 &amp; B=b_2 &amp; B=b_3 \\
  \hline
  A=a_1  &amp; 0.1   &amp; 0.2   &amp; 0.3\\
  A=a_2  &amp; 0.1   &amp; 0.2   &amp; 0.1\\  
  \hline
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
H(A,B) &amp;= -\sum_{a_i}\sum_{b_j}p(A=a_i,B=b_j)\log p(A=a_i,B=b_j)\\
       &amp;= -[3(0.1\log 0.1) + 2(0.2\log 0.2) + 0.3\log 0.3]\\
       &amp;= \mathbf{1.695}\;\text{nats}\;.
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Note that the maximum entropy (in this case with <span class="math notranslate nohighlight">\(m\cdot n=6\)</span> events) is given when
all events are equiprobable, i.e. <span class="math notranslate nohighlight">\(p(A=a_i,B=b_j)=\frac{1}{m\cdot n}=\frac{1}{2\cdot 3}=\frac{1}{6}\)</span>, and it is <span class="math notranslate nohighlight">\(H_{max}(A,B)=\log n = \log 6\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
H_{max}(A,B) &amp;= -\sum_{a_i}\sum_{b_j}\frac{1}{m\cdot n}\log \frac{1}{m\cdot n}\\
       &amp;= -6\cdot \frac{1}{6}\log\frac{1}{6}\\
       &amp;= -\log\frac{1}{6}\\
       &amp;= -(\log 1 - \log 6)\\
       &amp;= \log 6 = 1.791\;\text{nats}\;.
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Then <span class="math notranslate nohighlight">\(H(A,B)=1.695\)</span> is pretty close to <span class="math notranslate nohighlight">\(H_{max}(A,B)=1.791\)</span>.
</span>
<br></br>
<span style="color:#d94f0b">
<strong>b1)</strong> For <span class="math notranslate nohighlight">\(H(A|B)\)</span> we need the conditional distribution <span class="math notranslate nohighlight">\(p(A|B)\)</span>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|ccc}
                  &amp; B=b_1 &amp; B=b_2 &amp; B=b_3 \\
  \hline
  p(A=a_1|B=b_j)  &amp; \frac{0.1}{0.2}=0.5   &amp; \frac{0.2}{0.4}=0.5  &amp; \frac{0.3}{0.4}=0.75\\
  p(A=a_2|B=b_j)  &amp; \frac{0.1}{0.2}=0.5   &amp; \frac{0.2}{0.4}=0.5   &amp; \frac{0.1}{0.4}=0.25\\  
  \hline
                &amp; \sum = 1 &amp; \sum = 1 &amp; \sum=1\\
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Then, attending to the definition <span class="math notranslate nohighlight">\(H(A|B)=\sum_{b_j}p(B=b_j)H(A|B=b_j)\)</span>, we have:
</span>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
H(A|B=b_1) &amp;=  -\sum_{a_i}p(A=a_i|B=b_1)\log p(A=a_i|B=b_1)\\
           &amp;=  -(0.5\log 0.5 + 0.5\log 0.5) = 0.693\\
H(A|B=b_2) &amp;=  -\sum_{a_i}p(A=a_i|B=b_2)\log p(A=a_i|B=b_2)\\
           &amp;=  -(0.5\log 0.5 + 0.5\log 0.5) = 0.693\\
H(A|B=b_3) &amp;=  -\sum_{a_i}p(A=a_i|B=b_3)\log p(A=a_i|B=b_3)\\
           &amp;=  -(0.75\log 0.75 + 0.25\log 0.25) = 0.562\\
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Then, <span class="math notranslate nohighlight">\(H(A|B)\)</span> is given by a weighted average, where we need the marginals <span class="math notranslate nohighlight">\(p(B=b_j)=[0.2\;0.4\;0.4]\)</span> (see the corresponding exercise):
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
H(A|B) &amp;= \sum_{b_j}p(B=b_j)H(A|B=b_j)\\
       &amp;= p(B=b_1)H(A|B=b_1) + p(B=b_2)H(A|B=b_2) + p(B=b_3)H(A|B=b_3)\\
       &amp;= 0.2\cdot H(A|B=b_1) + 0.4\cdot H(A|B=b_2) + 0.4\cdot H(A|B=b_3)\\
       &amp;= 0.2\cdot 0.693 + 0.4\cdot 0.693 + 0.4\cdot 0.562\\
       &amp;= \mathbf{0.640}\;.
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<strong>b2)</strong> For <span class="math notranslate nohighlight">\(H(B|A)\)</span> we need the conditional distribution <span class="math notranslate nohighlight">\(p(B|A)\)</span>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{aligned}
\begin{array}{c|ccc|c}
                  &amp; p(B=b_1|A=a_i) &amp; p(B=b_2|A=a_i) &amp; p(B=b_3|A=a_i) \\
  \hline
  A=a_1  &amp; \frac{0.1}{0.6}=0.17   &amp; \frac{0.2}{0.6}=0.33  &amp; \frac{0.3}{0.6}=0.5 &amp; \sum = 1\\
  A=a_2  &amp; \frac{0.1}{0.4}=0.25   &amp; \frac{0.2}{0.4}=0.5   &amp; \frac{0.1}{0.4}=0.25 &amp; \sum = 1\\  
  \hline
\end{array}
\end{aligned}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Then, attending to the definition <span class="math notranslate nohighlight">\(H(B|A)=\sum_{a_i}p(A=a_i)H(B|A=a_i)\)</span>, we have:
</span>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
H(B|A=a_1) &amp;=  -\sum_{b_j}p(B=b_j|A=a_1)\log p(B=b_j|A=a_1)\\
           &amp;=  -(0.17\log 0.17 + 0.33\log 0.33 + 0.5\log 0.5) = 1.013\\
H(B|A=a_2) &amp;=  -\sum_{b_j}p(B=b_j|A=a_2)\log p(B=b_j|A=a_2)\\
           &amp;=  -(0.25\log 0.25 + 0.5\log 0.5 + 0.25\log 0.25) = 1.039\\
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Then, <span class="math notranslate nohighlight">\(H(B|A)\)</span> is given by a weighted average, where we need the marginals <span class="math notranslate nohighlight">\(p(A=a_i)=[0.6\;0.4]\)</span> (see the corresponding exercise):
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
H(B|A) &amp;= \sum_{a_i}p(A=a_i)H(B|B=a_i)\\
       &amp;= p(A=a_1)H(B|A=a_1) + p(A=a_2)H(B|A=a_2)\\
       &amp;= 0.6\cdot H(B|A=a_1) + 0.4\cdot H(B|A=a_2)\\
       &amp;= 0.6\cdot 1.013 + 0.4\cdot 1.039 \\
       &amp;= \mathbf{1.023}\;.
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<strong>c)</strong> As a result <span class="math notranslate nohighlight">\(H(B|A)=\mathbf{1.023}&gt;H(A|B)=\mathbf{0.640}\)</span>. This means that <strong><span class="math notranslate nohighlight">\(B\)</span> holds more information about <span class="math notranslate nohighlight">\(A\)</span> than <span class="math notranslate nohighlight">\(A\)</span> holds about <span class="math notranslate nohighlight">\(B\)</span></strong>.
<br></br>
Finally, let us compute the individual entropies <span class="math notranslate nohighlight">\(H(A)\)</span> and <span class="math notranslate nohighlight">\(H(B)\)</span>:
</span>
<br></br>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
\begin{align}
H(A) &amp; = -\sum_{a_i}p(A=a_i)\log p(A=a_i)\\
       &amp; = -(0.6\log 0.6 + 0.4\log 0.4)\\
       &amp; = \mathbf{0.673}\;.\\
H(B) &amp; = -\sum_{b_j}p(B=b_j)\log p(B=b_j)\\
       &amp; = -(0.2\log 0.2 + 0.4\log 0.4 + 0.4\log 0.4)\\
       &amp; = \mathbf{1.054}\;.\\
\end{align}
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
Since <span class="math notranslate nohighlight">\(H(A|B)=H(A,B)-H(B)\)</span> and <span class="math notranslate nohighlight">\(H(B|A)=H(A,B)-H(A)\)</span> and <span class="math notranslate nohighlight">\(H(B)&gt;H(A)\)</span> (<span class="math notranslate nohighlight">\(B\)</span> is more uncertain than <span class="math notranslate nohighlight">\(A\)</span>), then <span class="math notranslate nohighlight">\(H(B)\)</span> reduces more the uncertainty of <span class="math notranslate nohighlight">\(H(A,B)\)</span> than <span class="math notranslate nohighlight">\(H(A)\)</span>. This explains why <span class="math notranslate nohighlight">\(H(A|B)\ll H(B|A)\)</span>.
<br><br>
Let us check the calculus:
</span>
<span style="color:#d94f0b">
<span class="math notranslate nohighlight">\(
H(A|B) = \mathbf{0.640} = 1.695 - 1.054\;\;\text{and}\;\; H(B|A) = \mathbf{1.023} = 1.695 - 0.673\;.
\)</span>
</span>
<br></br>
<span style="color:#d94f0b">
<strong>d)</strong> Since <span class="math notranslate nohighlight">\(H(A|B)=0.640\approx H(A)= 0.673\)</span> and <span class="math notranslate nohighlight">\(H(B|A)=1.023\approx H(B)=1.054\)</span>, we conclude that <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are <em>close to be independent, although they are not</em>. This is consistent with the previous exercise on marginals.
<br></br>
<span style="color:#d94f0b">
Then, in this exercise we have illustrated how to compute the conditional entropies either directly or through the individual entropies and the joint entropy. However, the key of this exercixse is to <strong>interpret correctly what a conditional entropy is</strong>: <em>a quantification of how much information has one variable about the other</em>.
</span></p>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="topic1.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">1. </span>NP-Complete Problems</p>
      </div>
    </a>
    <a class="right-next"
       href="practice_1_1.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3. </span>Introduction to the practical part of TAB2026</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-common-subgraph">2.1. Maximum Common Subgraph</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-matching">2.2. Graph Matching</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#assignments-and-matchings">2.2.1. Assignments and Matchings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rectangle-rule-cost-function">2.2.2. Rectangle rule: Cost Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#integer-constraints-qap">2.2.3. Integer Constraints: QAP</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulated-annealing">2.3. Simulated Annealing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approximating-qap-with-sa">2.3.1. Approximating QAP with SA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation-of-sa">2.3.2. Interpretation of SA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gibbs-sampling">2.3.3. Gibbs Sampling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-of-sa">2.3.4. Limitations of SA</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#softmax-for-graph-matching">2.4. SoftMax for Graph Matching</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#softmaxing">2.4.1. SoftMaxing</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#continuation-methods">2.4.1.1. Continuation Methods</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#softmax-operator">2.4.1.2. SoftMax operator</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#graduated-assignment">2.4.2. Graduated Assignment</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-assignment">2.4.2.1. Linear Assignment</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#softassign">2.4.2.2. SoftAssign</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">2.4.2.3. Overview</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#including-attributes">2.4.2.4. Including attributes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#cleanup">2.4.2.5. Cleanup</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#appendix">2.5. Appendix</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#independence">2.5.1. Independence</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy">2.5.2. Entropy</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#definition-and-properties">2.5.2.1. Definition and properties</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy-and-coding">2.5.2.2. Entropy and Coding</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#joint-vs-conditional-entropy">2.5.2.3. Joint vs Conditional entropy</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Francisco Javier Escolano Ruiz
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>